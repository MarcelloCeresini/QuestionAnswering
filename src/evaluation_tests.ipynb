{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0kEBtGKqXdI"
      },
      "source": [
        "# Predictions and evaluation notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkNeJu-iqbEy"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTBhw524fjXD"
      },
      "outputs": [],
      "source": [
        "# PRIVATE CELL\n",
        "git_token = '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'\n",
        "username = 'MarcelloCeresini'\n",
        "repository = 'QuestionAnswering'\n",
        "\n",
        "# COLAB ONLY CELLS\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    !pip3 install transformers\n",
        "    !nvidia-smi             # Check which GPU has been chosen for us\n",
        "    !rm -rf logs\n",
        "    !git clone https://{git_token}@github.com/{username}/{repository}\n",
        "    %cd {repository}\n",
        "    %ls\n",
        "except:\n",
        "    IN_COLAB = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynFVwoEagLYg"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive/')\n",
        "    %cd /content/QuestionAnswering/src"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9SJg92piy3k"
      },
      "source": [
        "## Model definition for NER attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrMG3pgpi13Z"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import layers\n",
        "from transformers import TFDistilBertModel\n",
        "from transformers.models.distilbert.modeling_tf_distilbert import TFMultiHeadSelfAttention as MHSA\n",
        "\n",
        "CHOSEN_ENHANCED_LAYER = 0\n",
        "CHOSEN_OUTPUT_STATES_IDX = [3, 4, 5, 6]\n",
        "\n",
        "class TFInjectMultiHeadSelfAttention(MHSA):\n",
        "\n",
        "    def load_NER_attention(self, NER_attention):\n",
        "        self.NER_attention = NER_attention\n",
        "\n",
        "    def call(self, query, key, value, mask, head_mask, output_attentions, training=False):\n",
        "        # key = key*tf.reshape(self.NER_attention, [self.NER_attention.shape[0], self.NER_attention.shape[1], 1])\n",
        "        key = key * tf.expand_dims(self.NER_attention, axis=-1)\n",
        "        return super().call(query, key, value, mask, head_mask, output_attentions, training=training)\n",
        "\n",
        "class QuestionAnsweringModel(keras.Model):\n",
        "\n",
        "    def __init__(self, transformer_model: TFDistilBertModel) -> None:\n",
        "        super(QuestionAnsweringModel, self).__init__()\n",
        "\n",
        "        self.transformer_model = transformer_model\n",
        "        # Apply layer change to first attention block\n",
        "        self.transformer_model.layers[0].transformer.layer[CHOSEN_ENHANCED_LAYER].attention = \\\n",
        "            TFInjectMultiHeadSelfAttention(transformer_model.config)\n",
        "        \n",
        "        # Add all remaining layers\n",
        "        self.dense_S = layers.Dense(1)\n",
        "        self.dense_E = layers.Dense(1)\n",
        "        self.flatten = layers.Flatten()\n",
        "        self.softmax_S = layers.Softmax(name='out_S')\n",
        "        self.softmax_E = layers.Softmax(name='out_E')\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        input_ids = inputs[\"input_ids\"]\n",
        "        attention_mask = inputs[\"attention_mask\"]\n",
        "        NER_attention = inputs[\"NER_attention\"]\n",
        "\n",
        "        # Load the NER tensor into the custom layer\n",
        "        self.transformer_model.layers[0].transformer.layer[0].attention.load_NER_attention(NER_attention)\n",
        "\n",
        "        out = self.transformer_model(\n",
        "            {\n",
        "                \"input_ids\": input_ids,\n",
        "                \"attention_mask\": attention_mask,\n",
        "            }\n",
        "        )\n",
        "\n",
        "        hidden_states = out.hidden_states\n",
        "        chosen_states_idx = CHOSEN_OUTPUT_STATES_IDX\n",
        "\n",
        "        chosen_hidden_states = tf.concat([hidden_states[i] for i in chosen_states_idx], axis=2)\n",
        "\n",
        "        out_S = self.dense_S(chosen_hidden_states) # dot product between token representation and start vector\n",
        "        out_S = self.flatten(out_S)\n",
        "        out_S = self.softmax_S(out_S)\n",
        "\n",
        "        out_E = self.dense_E(chosen_hidden_states) # dot product between token representation and end vector\n",
        "        out_E = self.flatten(out_E)\n",
        "        out_E = self.softmax_E(out_E)\n",
        "\n",
        "        return out_S, out_E"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKPJMUQxjLBS"
      },
      "source": [
        "## Prediction function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgRetBMOqqDP"
      },
      "source": [
        "In a single function we prepare the model, load the best weights available for it and evaluate the predictions using SQuAD's official script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqjZ-pZhgYNH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "from typing import List\n",
        "\n",
        "from config import Config\n",
        "import utils\n",
        "\n",
        "def predict_and_evaluate(DATASET_PATH:str, \n",
        "                         BEST_WEIGHTS_PATH:str, \n",
        "                         PATH_TO_PREDICTIONS_JSON:str,\n",
        "                         hidden_state_list:List[int]=[3,4,5,6],\n",
        "                         use_NER_attention=False, NER_value=0,\n",
        "                         bert=False):\n",
        "    '''\n",
        "    Uses the standard model to predict the answers to the dataset provided in \n",
        "    `DATASET_PATH` using the selected weights (`BEST_WEIGHTS_PATH`), \n",
        "    saves the predictions into `PATH_TO_PREDICTIONS_JSON` and executes SQuAD's\n",
        "    evaluation script to get the exact match accuracy and F1 score.\n",
        "    '''\n",
        "    config = Config(bert=bert)\n",
        "    # Read dataset (JSON file)\n",
        "    data = utils.read_question_set(DATASET_PATH)\n",
        "    # Process questions\n",
        "    dataset = utils.create_dataset_from_generator(data, config, for_training=False,\n",
        "        use_NER_attention=use_NER_attention, NER_value=NER_value)\n",
        "    # Generate the original dataset that contains the original context and token-char mapping\n",
        "    original_dataset = utils.create_original_dataset(data, config)\n",
        "    original_dataset = original_dataset.batch(config.BATCH_SIZE)\n",
        "    print(\"Number of samples: \", len(dataset))\n",
        "    dataset = dataset.batch(config.BATCH_SIZE)\n",
        "    # Load model\n",
        "    if not use_NER_attention:\n",
        "        model = config.create_standard_model(hidden_state_list=hidden_state_list)\n",
        "    else:\n",
        "        model = QuestionAnsweringModel(config.get_transformer())\n",
        "        # A subclassed model needs to be called at least once before loading the weights, \n",
        "        # because it needs to create the graph\n",
        "        for sample in dataset.take(1):\n",
        "            model(sample[0])\n",
        "    # Load best model weights\n",
        "    model.load_weights(BEST_WEIGHTS_PATH)\n",
        "    # Predict the answers to the questions in the dataset\n",
        "    predictions = utils.compute_predictions(dataset, original_dataset, model)\n",
        "    # Create a prediction file formatted like the one that is expected\n",
        "    with open(PATH_TO_PREDICTIONS_JSON, 'w') as f:\n",
        "        json.dump(predictions, f)\n",
        "    \n",
        "    !python eval/evaluate.py $DATASET_PATH $PATH_TO_PREDICTIONS_JSON"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WReGVo4rrdGW"
      },
      "source": [
        "## Evaluations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgXY_7tmrgPC"
      },
      "source": [
        "### Normal model (TPU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sYhr9krrkwu"
      },
      "source": [
        "#### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCg2proMqKzE",
        "outputId": "41de7d1e-b004-4e2f-a46f-13f613df2245"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'vocab_transform', 'activation_13', 'vocab_projector']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "1409it [09:24,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 48.70645662303084,\n",
            "  \"f1\": 69.03455794280707,\n",
            "  \"total\": 22535,\n",
            "  \"HasAns_exact\": 48.70645662303084,\n",
            "  \"HasAns_f1\": 69.03455794280707,\n",
            "  \"HasAns_total\": 22535\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/validation_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/normal_100_tpu_h5_cval/training_normal_tpu_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/normal_predictions_val_tpu_CORRECT.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqriFCwTroS2"
      },
      "source": [
        "#### Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1fjfIbHqBMD",
        "outputId": "91bfcf95-48c8-4964-8b6a-bd93f7f8110d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  10570\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 48/48 [00:06<00:00,  7.42it/s]\n",
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'vocab_transform', 'activation_13', 'vocab_projector']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "661it [04:19,  2.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 61.173131504257334,\n",
            "  \"f1\": 75.52867201553052,\n",
            "  \"total\": 10570,\n",
            "  \"HasAns_exact\": 61.173131504257334,\n",
            "  \"HasAns_f1\": 75.52867201553052,\n",
            "  \"HasAns_total\": 10570\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/normal_100_tpu_h5_cval/training_normal_tpu_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/normal_predictions_test_tpu_CORRECT.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4GWqGQ1nnzE"
      },
      "source": [
        "### Separate layer models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gAtNNxQnslz"
      },
      "source": [
        "#### Layer 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7E3kzXEnnzF"
      },
      "source": [
        "##### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-jmMQ1bnnzF",
        "outputId": "8588f5a4-9e39-4df0-84cc-24e768c09204"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  22535\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 111/111 [00:13<00:00,  8.04it/s]\n",
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'vocab_transform', 'activation_13', 'vocab_projector']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "1409it [09:22,  2.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 48.320390503660974,\n",
            "  \"f1\": 68.38944666755968,\n",
            "  \"total\": 22535,\n",
            "  \"HasAns_exact\": 48.320390503660974,\n",
            "  \"HasAns_f1\": 68.38944666755968,\n",
            "  \"HasAns_total\": 22535\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/validation_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/separate_100_tpu_h5_cval/layer_6/tpu_epoch_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/layer_6_val_CORRECT.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[6])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jn2BVQ9dnnzG"
      },
      "source": [
        "##### Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kd-hRCtFnnzG",
        "outputId": "380a8cba-65fc-4f0f-96d2-56e5047be089"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  10570\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 48/48 [00:06<00:00,  7.35it/s]\n",
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'vocab_transform', 'activation_13', 'vocab_projector']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "661it [04:24,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 60.74739829706717,\n",
            "  \"f1\": 75.1497476516914,\n",
            "  \"total\": 10570,\n",
            "  \"HasAns_exact\": 60.74739829706717,\n",
            "  \"HasAns_f1\": 75.1497476516914,\n",
            "  \"HasAns_total\": 10570\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/separate_100_tpu_h5_cval/layer_6/tpu_epoch_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/layer_6_test_CORRECT.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[6])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3ZeKs-Yoaa9"
      },
      "source": [
        "#### Layer 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0UQ32Bcoaa-"
      },
      "source": [
        "##### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUUa2_uHoaa-"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/validation_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/separate_100_tpu_h5_cval/layer_5/tpu_epoch_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/layer_5_val_CORRECT.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u92hV76qoaa-"
      },
      "source": [
        "##### Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsV5VHDnoaa-"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/separate_100_tpu_h5_cval/layer_5/tpu_epoch_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/layer_5_test_CORRECT.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4rO9PYdoghi"
      },
      "source": [
        "#### Layer 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEYZ5-U4oghi"
      },
      "source": [
        "##### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlrgtMQHoghi"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/validation_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/separate_100_tpu_h5_cval/layer_4/tpu_epoch_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/layer_4_val_CORRECT.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqTYtR5Hoghj"
      },
      "source": [
        "##### Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kGeIvZdoghj"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/separate_100_tpu_h5_cval/layer_4/tpu_epoch_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/layer_4_test_CORRECT.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwSjGZFRolDy"
      },
      "source": [
        "#### Layer 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldaooUcuolDz"
      },
      "source": [
        "##### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42wlRpR7olDz"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/validation_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/separate_100_tpu_h5_cval/layer_3/tpu_epoch_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/layer_3_val_CORRECT.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73FzQAzqolDz"
      },
      "source": [
        "##### Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkW10iHIolD0"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/separate_100_tpu_h5_cval/layer_3/tpu_epoch_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/layer_3_test_CORRECT.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDg1v4n0ooSb"
      },
      "source": [
        "#### Layer 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3662A70ooSc"
      },
      "source": [
        "##### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RobLL1DPooSd"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/validation_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/separate_100_tpu_h5_cval/layer_2/tpu_epoch_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/layer_2_val_CORRECT.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "layrsPlTooSd"
      },
      "source": [
        "##### Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJ8BETkfooSd"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/separate_100_tpu_h5_cval/layer_2/tpu_epoch_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/layer_2_test_CORRECT.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4hmZlbForhE"
      },
      "source": [
        "#### Layer 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZOeAAIOorhG"
      },
      "source": [
        "##### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRBVRdUrorhG"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/validation_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/separate_100_tpu_h5_cval/layer_1/tpu_epoch_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/layer_1_val_CORRECT.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGPQ2OLuorhG"
      },
      "source": [
        "##### Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fcc3NqJCorhG"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/separate_100_tpu_h5_cval/layer_1/tpu_epoch_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/layer_1_test_CORRECT.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s97CK93_S-ul"
      },
      "source": [
        "### Bert model (TPU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhqw6Hd2S-ul"
      },
      "source": [
        "#### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVpJfrPeS-um"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = \"/content/drive/MyDrive/NLP/data/validation_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/NLP/weights/training_BERT_tpu_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/NLP/data/bert_predictions_val_tpu_CORRECT.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[9,10,11,12], bert=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEp-FxXCS-un"
      },
      "source": [
        "#### Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VhiB5HuES-un"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = \"/content/drive/MyDrive/NLP/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/NLP/weights/training_BERT_tpu_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/NLP/data/bert_predictions_test_tpu_CORRECT.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[9,10,11,12], bert=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6pxgAUvmygM"
      },
      "source": [
        "### Ensemble DistilBert + Bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAqBvzv8mygN"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "\n",
        "def compute_ensemble_predictions(dataset: tf.data.Dataset,\n",
        "                                 original_dataset: tf.data.Dataset,\n",
        "                                 model: List):\n",
        "    '''\n",
        "    Computes predictions given the dataset, the used configuration parameters and model\n",
        "\n",
        "    Inputs:\n",
        "    - dataset: a `tf.data.Dataset` on which we will compute predictions.\n",
        "    - original_dataset: a `tf.data.Dataset` which contains the original context\n",
        "        and initial/starting characters for each token.\n",
        "    - model: a `keras.Model` that computes the predictions.\n",
        "    '''\n",
        "    predictions = {}\n",
        "    # For each sample we can extract from the dataset (it can be a single element or \n",
        "    # a batch)\n",
        "    for sample, original_sample in tqdm(zip(dataset, original_dataset), total=len(dataset)):\n",
        "        # We let the model predict the probability tensors given the input features\n",
        "        contexts = original_sample[\"context\"].numpy()\n",
        "        offsets = original_sample[\"offset_mapping\"].numpy()\n",
        "\n",
        "        features = sample[0]\n",
        "        pstartv_bert, pendv_bert = model[0].predict(features)\n",
        "        features.pop(\"token_type_ids\")\n",
        "        pstartv_distil, pendv_distil = model[1].predict(features)\n",
        "\n",
        "        # We sum the two probability distributions\n",
        "        pstartv = pstartv_bert + pstartv_distil\n",
        "        pendv = pendv_bert + pendv_distil\n",
        "        \n",
        "        # We obtain the span from the probabilities\n",
        "        predicted_limits = utils.start_end_token_from_probabilities(\n",
        "            pstartv, pendv\n",
        "        )\n",
        "        # Then we decode the answer's tokens \n",
        "        question_ids = [x.decode('utf-8') for x in sample[1].numpy()]\n",
        "\n",
        "        # Finaally, we produce the output dictionary for the batch\n",
        "        for i in range(len(input_ids)):\n",
        "            question_id = question_ids[i]\n",
        "            predicted_limit = predicted_limits[i]\n",
        "            context = contexts[i]\n",
        "            offset = offsets[i]\n",
        "            # Compute the predictions using the token characters \n",
        "            # from the original dataset\n",
        "            predictions[question_id] = context.decode()[\n",
        "                offset[predicted_limit[0], 0] \n",
        "                : \n",
        "                offset[predicted_limit[1], 1]\n",
        "            ]\n",
        "    \n",
        "    return predictions\n",
        "\n",
        "def predict_and_evaluate_ensemble(DATASET_PATH:str,\n",
        "                         BEST_WEIGHTS_PATH:List, \n",
        "                         PATH_TO_PREDICTIONS_JSON:str,\n",
        "                         hidden_state_list:List=[[3,4,5,6], [9,10,11,12]]):\n",
        "    '''\n",
        "    Uses the standard model to predict the answers to the dataset provided in \n",
        "    `DATASET_PATH` using the selected weights (`BEST_WEIGHTS_PATH`), \n",
        "    saves the predictions into `PATH_TO_PREDICTIONS_JSON` and executes SQuAD's\n",
        "    evaluation script to get the exact match accuracy and F1 score.\n",
        "    '''\n",
        "    config = Config()\n",
        "    # Read dataset (JSON file)\n",
        "    data = utils.read_question_set(DATASET_PATH)\n",
        "    # Process questions\n",
        "    dataset = utils.create_dataset_from_generator(data, config, token_type_ids=True, for_training=False)\n",
        "    print(\"Number of samples: \", len(dataset))\n",
        "    dataset = dataset.batch(config.BATCH_SIZE)\n",
        "\n",
        "    # Create the original dataset with the same order as the processed one\n",
        "    original_dataset = utils.create_original_dataset(data, config)\n",
        "    original_dataset = original_dataset.batch(config.BATCH_SIZE)\n",
        "\n",
        "    # Load models\n",
        "    distilbert_model = config.create_model(False, hidden_state_list=hidden_state_list[0])\n",
        "    bert_model = config.create_model(True, hidden_state_list=hidden_state_list[1])\n",
        "\n",
        "    # Load best model weights\n",
        "    distilbert_model.load_weights(BEST_WEIGHTS_PATH[0])\n",
        "    bert_model.load_weights(BEST_WEIGHTS_PATH[1])\n",
        "\n",
        "    # Predict the answers to the questions in the dataset\n",
        "    predictions = compute_ensemble_predictions(dataset, original_dataset, [bert_model, distilbert_model])\n",
        "\n",
        "    # Create a prediction file formatted like the one that is expected\n",
        "    with open(PATH_TO_PREDICTIONS_JSON, 'w') as f:\n",
        "        json.dump(predictions, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-toJc8JS-uo"
      },
      "source": [
        "#### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8EJ_-yeS-uo"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = \"/content/drive/MyDrive/NLP/data/validation_set.json\"\n",
        "BEST_WEIGHTS_PATH_BERT = \"/content/drive/MyDrive/NLP/weights/training_BERT_tpu_last.h5\"\n",
        "BEST_WEIGHTS_PATH_DISTILBERT = \"/content/drive/MyDrive/NLP/weights/training_normal_tpu_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/NLP/data/ensemble_predictions_val_tpu_CORRECT.txt'\n",
        "\n",
        "predict_and_evaluate_ensemble(DATASET_PATH=DATASET_PATH, \n",
        "                              BEST_WEIGHTS_PATH=[BEST_WEIGHTS_PATH_DISTILBERT, BEST_WEIGHTS_PATH_BERT], \n",
        "                              PATH_TO_PREDICTIONS_JSON=PATH_TO_PREDICTIONS_JSON)\n",
        "!python /content/eval/evaluate.py $DATASET_PATH $PATH_TO_PREDICTIONS_JSON"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVzU9-FrS-up"
      },
      "source": [
        "#### Test set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tN29t54YS-up"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = \"/content/drive/MyDrive/NLP/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH_BERT= \"/content/drive/MyDrive/NLP/weights/training_BERT_tpu_last.h5\"\n",
        "BEST_WEIGHTS_PATH_DISTILBERT = \"/content/drive/MyDrive/NLP/weights/training_normal_tpu_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/NLP/data/ensemble_predictions_test_tpu_CORRECT.txt'\n",
        "\n",
        "predict_and_evaluate_ensemble(DATASET_PATH=DATASET_PATH, BEST_WEIGHTS_PATH=[BEST_WEIGHTS_PATH_DISTILBERT, BEST_WEIGHTS_PATH_BERT], PATH_TO_PREDICTIONS_JSON=PATH_TO_PREDICTIONS_JSON)\n",
        "!python /content/eval/evaluate.py $DATASET_PATH $PATH_TO_PREDICTIONS_JSON"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgn_zB2PeAB_"
      },
      "source": [
        "### NER model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FYdupE5ejpe"
      },
      "source": [
        "#### NER weight offset = 0.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G25k_J80d7Cy"
      },
      "source": [
        "##### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1limPz-Kd7C6",
        "outputId": "e2c661d5-7e0d-48a5-b1b3-2692276a463f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  22535\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_transform', 'vocab_layer_norm', 'activation_13', 'vocab_projector']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 353/353 [30:21<00:00,  5.16s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 40.29731528733082,\n",
            "  \"f1\": 61.10515720895817,\n",
            "  \"total\": 22535,\n",
            "  \"HasAns_exact\": 40.29731528733082,\n",
            "  \"HasAns_f1\": 61.10515720895817,\n",
            "  \"HasAns_total\": 22535\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/validation_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/NER_100_tpu_h5_cval/hyperparameter_0,2/training_NER_02_tpu_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/NER_02_predictions_val.txt'\n",
        "NER_VALUE = 0.2\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, use_NER_attention=True, NER_value=NER_VALUE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCqlIhmSd7C6"
      },
      "source": [
        "##### Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEV6GLQKd7C7",
        "outputId": "f93cff8d-ecb4-4e1a-e720-d6f57064c21b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  10570\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_transform', 'vocab_layer_norm', 'activation_13', 'vocab_projector']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 166/166 [13:53<00:00,  5.02s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 51.36234626300851,\n",
            "  \"f1\": 68.03648925049636,\n",
            "  \"total\": 10570,\n",
            "  \"HasAns_exact\": 51.36234626300851,\n",
            "  \"HasAns_f1\": 68.03648925049636,\n",
            "  \"HasAns_total\": 10570\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/NER_100_tpu_h5_cval/hyperparameter_0,2/training_NER_02_tpu_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/NER_02_predictions_test.txt'\n",
        "NER_VALUE = 0.2\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, use_NER_attention=True, NER_value=NER_VALUE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx_5kiCWyleq"
      },
      "source": [
        "#### NER weight offset = 0.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xn3kUTl0yle0"
      },
      "source": [
        "##### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrISe7URyle0",
        "outputId": "8c332092-6edd-4a34-f734-951f771408d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  22535\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_transform', 'vocab_layer_norm', 'activation_13', 'vocab_projector']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 353/353 [30:21<00:00,  5.16s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 40.35944086975815,\n",
            "  \"f1\": 61.296511079528514,\n",
            "  \"total\": 22535,\n",
            "  \"HasAns_exact\": 40.35944086975815,\n",
            "  \"HasAns_f1\": 61.296511079528514,\n",
            "  \"HasAns_total\": 22535\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/validation_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/NER_100_tpu_h5_cval/hyperparameter_0.4/training_NER_04_tpu_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/NER_04_predictions_val.txt'\n",
        "NER_VALUE = 0.4\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, use_NER_attention=True, NER_value=NER_VALUE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_P2BWwoByle1"
      },
      "source": [
        "##### Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeiPTdlnyle1",
        "outputId": "e32a5267-3623-4b46-97be-6469b0cbd108"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  10570\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_transform', 'vocab_layer_norm', 'activation_13', 'vocab_projector']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 166/166 [14:21<00:00,  5.19s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 51.863765373699145,\n",
            "  \"f1\": 68.43574692147928,\n",
            "  \"total\": 10570,\n",
            "  \"HasAns_exact\": 51.863765373699145,\n",
            "  \"HasAns_f1\": 68.43574692147928,\n",
            "  \"HasAns_total\": 10570\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/NER_100_tpu_h5_cval/hyperparameter_0.4/training_NER_04_tpu_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/NER_04_predictions_test.txt'\n",
        "NER_VALUE = 0.4\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, use_NER_attention=True, NER_value=NER_VALUE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LamJUSbV3eS"
      },
      "source": [
        "#### NER weight offset = 0.6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n49I8u_0V3ee"
      },
      "source": [
        "##### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330,
          "referenced_widgets": [
            "2e535c91d80a43578bbb831dab804059",
            "13e2fa4f8a6e4d90a4e6e0114921073d",
            "2dfa36dbd85f469fa474c2fd30b15f54",
            "1844736d7ebb4f719cad5056eb10cb76",
            "ca5d6e40a21f4067a0acc9eaf6545955",
            "fb08161720de491b8b5be799d32f921a",
            "f8f1a60cca254c3d8e2251ed7449830c",
            "656a38b4e0ba4d2e9e8ae32dd17c6205",
            "d176af6bc2bc4dd7bd9b9f706261478c",
            "1ab29e8c869f47d883473a8dfb538f1c",
            "249915abc198448e9676c8b2a5040642"
          ]
        },
        "id": "cqKRAdjvV3ee",
        "outputId": "62398957-8d00-45ff-da84-b3cc880f4eb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  22535\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e535c91d80a43578bbb831dab804059",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/347M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_projector', 'activation_13', 'vocab_transform', 'vocab_layer_norm']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 353/353 [24:21<00:00,  4.14s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 40.32837807854449,\n",
            "  \"f1\": 61.11215226289375,\n",
            "  \"total\": 22535,\n",
            "  \"HasAns_exact\": 40.32837807854449,\n",
            "  \"HasAns_f1\": 61.11215226289375,\n",
            "  \"HasAns_total\": 22535\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/validation_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/NER_100_tpu_h5_cval/hyperparameter_0,6/training_NER_06_tpu_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/NER_06_predictions_val.txt'\n",
        "NER_VALUE = 0.6\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, use_NER_attention=True, NER_value=NER_VALUE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtCPZXdWV3ef"
      },
      "source": [
        "##### Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DINvLkyYV3ef",
        "outputId": "08be2a95-916e-4686-9318-b96c3da0cb6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  10570\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_projector', 'activation_13', 'vocab_transform', 'vocab_layer_norm']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 166/166 [11:21<00:00,  4.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 51.57048249763481,\n",
            "  \"f1\": 68.12658908682066,\n",
            "  \"total\": 10570,\n",
            "  \"HasAns_exact\": 51.57048249763481,\n",
            "  \"HasAns_f1\": 68.12658908682066,\n",
            "  \"HasAns_total\": 10570\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/NER_100_tpu_h5_cval/hyperparameter_0,6/training_NER_06_tpu_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/NER_06_predictions_test.txt'\n",
        "NER_VALUE = 0.6\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, use_NER_attention=True, NER_value=NER_VALUE)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "NLP_Project_evaluation_tests.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "13e2fa4f8a6e4d90a4e6e0114921073d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1844736d7ebb4f719cad5056eb10cb76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d176af6bc2bc4dd7bd9b9f706261478c",
            "max": 363423424,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_656a38b4e0ba4d2e9e8ae32dd17c6205",
            "value": 363423424
          }
        },
        "1ab29e8c869f47d883473a8dfb538f1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "249915abc198448e9676c8b2a5040642": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2dfa36dbd85f469fa474c2fd30b15f54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8f1a60cca254c3d8e2251ed7449830c",
            "placeholder": "​",
            "style": "IPY_MODEL_fb08161720de491b8b5be799d32f921a",
            "value": "Downloading: 100%"
          }
        },
        "2e535c91d80a43578bbb831dab804059": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2dfa36dbd85f469fa474c2fd30b15f54",
              "IPY_MODEL_1844736d7ebb4f719cad5056eb10cb76",
              "IPY_MODEL_ca5d6e40a21f4067a0acc9eaf6545955"
            ],
            "layout": "IPY_MODEL_13e2fa4f8a6e4d90a4e6e0114921073d"
          }
        },
        "656a38b4e0ba4d2e9e8ae32dd17c6205": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca5d6e40a21f4067a0acc9eaf6545955": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_249915abc198448e9676c8b2a5040642",
            "placeholder": "​",
            "style": "IPY_MODEL_1ab29e8c869f47d883473a8dfb538f1c",
            "value": " 347M/347M [00:11&lt;00:00, 31.8MB/s]"
          }
        },
        "d176af6bc2bc4dd7bd9b9f706261478c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8f1a60cca254c3d8e2251ed7449830c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb08161720de491b8b5be799d32f921a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}