{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Project_evaluation_tests.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Predictions and evaluation notebook"
      ],
      "metadata": {
        "id": "T0kEBtGKqXdI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "SkNeJu-iqbEy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTBhw524fjXD"
      },
      "outputs": [],
      "source": [
        "# PRIVATE CELL\n",
        "git_token = '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'\n",
        "username = 'MarcelloCeresini'\n",
        "repository = 'QuestionAnswering'\n",
        "\n",
        "# COLAB ONLY CELLS\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    !pip3 install transformers\n",
        "    !nvidia-smi             # Check which GPU has been chosen for us\n",
        "    !rm -rf logs\n",
        "    # !git clone https://{git_token}@github.com/{username}/{repository}\n",
        "    !git clone -b enhanced_refactor https://{git_token}@github.com/{username}/{repository}\n",
        "    %cd {repository}\n",
        "    %ls\n",
        "except:\n",
        "    IN_COLAB = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive/')\n",
        "    %cd /content/QuestionAnswering/src"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynFVwoEagLYg",
        "outputId": "1c6df9fd-3865-46aa-e6a2-b269bf3acf37"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a single function we prepare the model, load the best weights available for it and evaluate the predictions using SQuAD's official script."
      ],
      "metadata": {
        "id": "zgRetBMOqqDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "from config import Config\n",
        "import utils\n",
        "\n",
        "def predict_and_evaluate(DATASET_PATH:str, \n",
        "                         BEST_WEIGHTS_PATH:str, \n",
        "                         PATH_TO_PREDICTIONS_JSON:str):\n",
        "    '''\n",
        "    Uses the standard model to predict the answers to the dataset provided in \n",
        "    `DATASET_PATH` using the selected weights (`BEST_WEIGHTS_PATH`), \n",
        "    saves the predictions into `PATH_TO_PREDICTIONS_JSON` and executes SQuAD's\n",
        "    evaluation script to get the exact match accuracy and F1 score.\n",
        "    '''\n",
        "    config = Config()\n",
        "    # Read dataset (JSON file)\n",
        "    data = utils.read_question_set(DATASET_PATH)\n",
        "    # Process questions\n",
        "    dataset = utils.create_dataset_and_ids(data, config, for_training=False)\n",
        "    print(\"Number of samples: \", len(dataset))\n",
        "    dataset = dataset.batch(config.BATCH_SIZE)\n",
        "    # Load model\n",
        "    model = config.create_standard_model(hidden_state_list=[3,4,5,6])\n",
        "    # Load best model weights\n",
        "    #   TODO: We have no weights yet\n",
        "    model.load_weights(BEST_WEIGHTS_PATH)\n",
        "    # Predict the answers to the questions in the dataset\n",
        "    predictions = utils.compute_predictions(dataset, config, model)\n",
        "    # Create a prediction file formatted like the one that is expected\n",
        "    with open(PATH_TO_PREDICTIONS_JSON, 'w') as f:\n",
        "        json.dump(predictions, f)\n",
        "    \n",
        "    !python eval/evaluate.py $DATASET_PATH $PATH_TO_PREDICTIONS_JSON"
      ],
      "metadata": {
        "id": "aqjZ-pZhgYNH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluations"
      ],
      "metadata": {
        "id": "WReGVo4rrdGW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normal model (TPU)"
      ],
      "metadata": {
        "id": "OgXY_7tmrgPC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training set"
      ],
      "metadata": {
        "id": "6sYhr9krrkwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/training_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/normal_tpu/normal.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/normal_predictions_train.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCg2proMqKzE",
        "outputId": "738ad33a-e62a-48ee-d3d0-cc74050e8061"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples:  87599\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['activation_13', 'vocab_transform', 'vocab_projector', 'vocab_layer_norm']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 1369/1369 [35:45<00:00,  1.57s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"exact\": 49.3475952921837,\n",
            "  \"f1\": 69.28686360166398,\n",
            "  \"total\": 87599,\n",
            "  \"HasAns_exact\": 49.3475952921837,\n",
            "  \"HasAns_f1\": 69.28686360166398,\n",
            "  \"HasAns_total\": 87599\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Validation set"
      ],
      "metadata": {
        "id": "mqriFCwTroS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/normal_tpu/normal.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/normal_predictions_val.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1fjfIbHqBMD",
        "outputId": "38485c47-87cd-4a77-d086-19a453fd1629"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples:  10570\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['activation_13', 'vocab_transform', 'vocab_projector', 'vocab_layer_norm']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 166/166 [04:21<00:00,  1.58s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"exact\": 54.361400189214756,\n",
            "  \"f1\": 70.55402423742173,\n",
            "  \"total\": 10570,\n",
            "  \"HasAns_exact\": 54.361400189214756,\n",
            "  \"HasAns_f1\": 70.55402423742173,\n",
            "  \"HasAns_total\": 10570\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normal model (GPU)"
      ],
      "metadata": {
        "id": "1T5RFXTHshH7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training set"
      ],
      "metadata": {
        "id": "u7QNRhQLsl9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/training_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/old_weights_no_tpu/normal/cp-0007.ckpt\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/normal_predictions_train_gpu.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThrwfFO1srpd",
        "outputId": "664910a0-d538-4f7f-f19d-de876f1d2935"
      },
      "execution_count": 18,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  87599\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['activation_13', 'vocab_transform', 'vocab_projector', 'vocab_layer_norm']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 1369/1369 [36:21<00:00,  1.59s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"exact\": 47.333873674357015,\n",
            "  \"f1\": 67.3805008929827,\n",
            "  \"total\": 87599,\n",
            "  \"HasAns_exact\": 47.333873674357015,\n",
            "  \"HasAns_f1\": 67.3805008929827,\n",
            "  \"HasAns_total\": 87599\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Validation set"
      ],
      "metadata": {
        "id": "nc6e2dUbsm5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/old_weights_no_tpu/normal/cp-0007.ckpt\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/normal_predictions_val_gpu.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bXJx5XWslVw",
        "outputId": "1f188734-af64-40d7-cf51-818f8c3ceecf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples:  10570\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['activation_13', 'vocab_transform', 'vocab_projector', 'vocab_layer_norm']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 166/166 [04:23<00:00,  1.59s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"exact\": 53.78429517502365,\n",
            "  \"f1\": 70.23643758487442,\n",
            "  \"total\": 10570,\n",
            "  \"HasAns_exact\": 53.78429517502365,\n",
            "  \"HasAns_f1\": 70.23643758487442,\n",
            "  \"HasAns_total\": 10570\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}