{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0kEBtGKqXdI"
      },
      "source": [
        "# Predictions and evaluation notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkNeJu-iqbEy"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTBhw524fjXD"
      },
      "outputs": [],
      "source": [
        "# PRIVATE CELL\n",
        "git_token = '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'\n",
        "username = 'MarcelloCeresini'\n",
        "repository = 'QuestionAnswering'\n",
        "\n",
        "# COLAB ONLY CELLS\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    !pip3 install transformers\n",
        "    !nvidia-smi             # Check which GPU has been chosen for us\n",
        "    !rm -rf logs\n",
        "    !git clone https://{git_token}@github.com/{username}/{repository}\n",
        "    %cd {repository}\n",
        "    %ls\n",
        "except:\n",
        "    IN_COLAB = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynFVwoEagLYg"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive/')\n",
        "    %cd /content/QuestionAnswering/src"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9SJg92piy3k"
      },
      "source": [
        "## Model definition for NER attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jrMG3pgpi13Z"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import layers\n",
        "from transformers import TFDistilBertModel\n",
        "from transformers.models.distilbert.modeling_tf_distilbert import TFMultiHeadSelfAttention as MHSA\n",
        "\n",
        "CHOSEN_ENHANCED_LAYER = 0\n",
        "CHOSEN_OUTPUT_STATES_IDX = [3, 4, 5, 6]\n",
        "\n",
        "class TFInjectMultiHeadSelfAttention(MHSA):\n",
        "\n",
        "    def load_NER_attention(self, NER_attention):\n",
        "        self.NER_attention = NER_attention\n",
        "\n",
        "    def call(self, query, key, value, mask, head_mask, output_attentions, training=False):\n",
        "        # key = key*tf.reshape(self.NER_attention, [self.NER_attention.shape[0], self.NER_attention.shape[1], 1])\n",
        "        key = key * tf.expand_dims(self.NER_attention, axis=-1)\n",
        "        return super().call(query, key, value, mask, head_mask, output_attentions, training=training)\n",
        "\n",
        "class QuestionAnsweringModel(keras.Model):\n",
        "\n",
        "    def __init__(self, transformer_model: TFDistilBertModel) -> None:\n",
        "        super(QuestionAnsweringModel, self).__init__()\n",
        "\n",
        "        self.transformer_model = transformer_model\n",
        "        # Apply layer change to first attention block\n",
        "        self.transformer_model.layers[0].transformer.layer[CHOSEN_ENHANCED_LAYER].attention = \\\n",
        "            TFInjectMultiHeadSelfAttention(transformer_model.config)\n",
        "        \n",
        "        # Add all remaining layers\n",
        "        self.dense_S = layers.Dense(1)\n",
        "        self.dense_E = layers.Dense(1)\n",
        "        self.flatten = layers.Flatten()\n",
        "        self.softmax_S = layers.Softmax(name='out_S')\n",
        "        self.softmax_E = layers.Softmax(name='out_E')\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        input_ids = inputs[\"input_ids\"]\n",
        "        attention_mask = inputs[\"attention_mask\"]\n",
        "        NER_attention = inputs[\"NER_attention\"]\n",
        "\n",
        "        # Load the NER tensor into the custom layer\n",
        "        self.transformer_model.layers[0].transformer.layer[0].attention.load_NER_attention(NER_attention)\n",
        "\n",
        "        out = self.transformer_model(\n",
        "            {\n",
        "                \"input_ids\": input_ids,\n",
        "                \"attention_mask\": attention_mask,\n",
        "            }\n",
        "        )\n",
        "\n",
        "        hidden_states = out.hidden_states\n",
        "        chosen_states_idx = CHOSEN_OUTPUT_STATES_IDX\n",
        "\n",
        "        chosen_hidden_states = tf.concat([hidden_states[i] for i in chosen_states_idx], axis=2)\n",
        "\n",
        "        out_S = self.dense_S(chosen_hidden_states) # dot product between token representation and start vector\n",
        "        out_S = self.flatten(out_S)\n",
        "        out_S = self.softmax_S(out_S)\n",
        "\n",
        "        out_E = self.dense_E(chosen_hidden_states) # dot product between token representation and end vector\n",
        "        out_E = self.flatten(out_E)\n",
        "        out_E = self.softmax_E(out_E)\n",
        "\n",
        "        return out_S, out_E"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKPJMUQxjLBS"
      },
      "source": [
        "## Prediction function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgRetBMOqqDP"
      },
      "source": [
        "In a single function we prepare the model, load the best weights available for it and evaluate the predictions using SQuAD's official script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aqjZ-pZhgYNH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "from typing import List\n",
        "\n",
        "from config import Config\n",
        "import utils\n",
        "\n",
        "def predict_and_evaluate(DATASET_PATH:str, \n",
        "                         BEST_WEIGHTS_PATH:str, \n",
        "                         PATH_TO_PREDICTIONS_JSON:str,\n",
        "                         hidden_state_list:List[int]=[3,4,5,6],\n",
        "                         use_NER_attention=False, NER_value=0,\n",
        "                         bert=False):\n",
        "    '''\n",
        "    Uses the standard model to predict the answers to the dataset provided in \n",
        "    `DATASET_PATH` using the selected weights (`BEST_WEIGHTS_PATH`), \n",
        "    saves the predictions into `PATH_TO_PREDICTIONS_JSON` and executes SQuAD's\n",
        "    evaluation script to get the exact match accuracy and F1 score.\n",
        "    '''\n",
        "    config = Config(bert=bert)\n",
        "    # Read dataset (JSON file)\n",
        "    data = utils.read_question_set(DATASET_PATH)\n",
        "    # Process questions\n",
        "    dataset = utils.create_dataset_from_generator(data, config, for_training=False,\n",
        "        use_NER_attention=use_NER_attention, NER_value=NER_value)\n",
        "    # Generate the original dataset that contains the original context and token-char mapping\n",
        "    original_dataset = utils.create_original_dataset(data, config)\n",
        "    original_dataset = original_dataset.batch(config.BATCH_SIZE)\n",
        "    print(\"Number of samples: \", len(dataset))\n",
        "    dataset = dataset.batch(config.BATCH_SIZE)\n",
        "    # Load model\n",
        "    if not use_NER_attention:\n",
        "        model = config.create_standard_model(hidden_state_list=hidden_state_list)\n",
        "    else:\n",
        "        model = QuestionAnsweringModel(config.get_transformer())\n",
        "        # A subclassed model needs to be called at least once before loading the weights, \n",
        "        # because it needs to create the graph\n",
        "        for sample in dataset.take(1):\n",
        "            model(sample[0])\n",
        "    # Load best model weights\n",
        "    model.load_weights(BEST_WEIGHTS_PATH)\n",
        "    # Predict the answers to the questions in the dataset\n",
        "    predictions = utils.compute_predictions(dataset, original_dataset, model)\n",
        "    # Create a prediction file formatted like the one that is expected\n",
        "    with open(PATH_TO_PREDICTIONS_JSON, 'w') as f:\n",
        "        json.dump(predictions, f)\n",
        "    \n",
        "    !python eval/evaluate.py $DATASET_PATH $PATH_TO_PREDICTIONS_JSON"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WReGVo4rrdGW"
      },
      "source": [
        "## Evaluations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgXY_7tmrgPC"
      },
      "source": [
        "### Normal model (TPU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sYhr9krrkwu"
      },
      "source": [
        "#### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358,
          "referenced_widgets": [
            "7ddbea4d33f046d7bc89a1a181899326",
            "520c17764caa4202a7f1dda5d7bad3f1",
            "ac9963c870624211b6c8df3742ac6a68",
            "d30fc3e008c1496a8b49b9071ac99ee2",
            "639763a70ca9440bb54b56a5a5b1b355",
            "6c11ad18312d44faa523d910846e383e",
            "9d8c2ac4cab945bda2237f67043f9229",
            "ca107472622147949253da2524a8d67e",
            "452f0c2a0dd94326be3d65688565b468",
            "980ea8daab1b494fb9fcc18218671f0d",
            "6d907e2ab1b444b494f93da785669951"
          ]
        },
        "id": "WCg2proMqKzE",
        "outputId": "be0d1e07-4ecb-4597-ed89-f61b28b6be69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  22535\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ddbea4d33f046d7bc89a1a181899326",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/347M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_transform', 'activation_13', 'vocab_layer_norm', 'vocab_projector']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 353/353 [16:21<00:00,  2.78s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 42.57821167073441,\n",
            "  \"f1\": 63.47665599138955,\n",
            "  \"total\": 22535,\n",
            "  \"HasAns_exact\": 42.57821167073441,\n",
            "  \"HasAns_f1\": 63.47665599138955,\n",
            "  \"HasAns_total\": 22535\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/validation_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/normal_100_tpu_h5_cval/training_normal_tpu_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/normal_predictions_val_tpu.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqriFCwTroS2"
      },
      "source": [
        "#### Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1fjfIbHqBMD",
        "outputId": "c025ea48-c56f-4677-c0a0-15489143980d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  10570\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_transform', 'activation_13', 'vocab_layer_norm', 'vocab_projector']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 166/166 [07:21<00:00,  2.66s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 54.13434247871334,\n",
            "  \"f1\": 70.4218316349117,\n",
            "  \"total\": 10570,\n",
            "  \"HasAns_exact\": 54.13434247871334,\n",
            "  \"HasAns_f1\": 70.4218316349117,\n",
            "  \"HasAns_total\": 10570\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/normal_100_tpu_h5_cval/training_normal_tpu_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/normal_predictions_test_tpu.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T5RFXTHshH7"
      },
      "source": [
        "### Normal model (GPU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7QNRhQLsl9v"
      },
      "source": [
        "#### Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThrwfFO1srpd",
        "outputId": "06c951fe-4eee-4ade-f208-16f873bdb2d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  10570\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_transform', 'activation_13', 'vocab_layer_norm', 'vocab_projector']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 166/166 [07:23<00:00,  2.67s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 53.78429517502365,\n",
            "  \"f1\": 70.23643758487442,\n",
            "  \"total\": 10570,\n",
            "  \"HasAns_exact\": 53.78429517502365,\n",
            "  \"HasAns_f1\": 70.23643758487442,\n",
            "  \"HasAns_total\": 10570\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/old_weights_no_tpu/normal/cp-0007.ckpt\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/normal_predictions_test_gpu.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4GWqGQ1nnzE"
      },
      "source": [
        "### Separate layer models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gAtNNxQnslz"
      },
      "source": [
        "#### Layer 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7E3kzXEnnzF"
      },
      "source": [
        "##### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-jmMQ1bnnzF",
        "outputId": "c1a3c355-32e7-48b6-cd66-d873b95e0aa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  22535\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_transform', 'activation_13', 'vocab_layer_norm', 'vocab_projector']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 353/353 [15:37<00:00,  2.65s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 42.30752163301531,\n",
            "  \"f1\": 62.873386169232035,\n",
            "  \"total\": 22535,\n",
            "  \"HasAns_exact\": 42.30752163301531,\n",
            "  \"HasAns_f1\": 62.873386169232035,\n",
            "  \"HasAns_total\": 22535\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/validation_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/separate_100_tpu_h5_cval/layer_6/tpu_epoch_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/layer_6_val.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[6])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jn2BVQ9dnnzG"
      },
      "source": [
        "##### Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kd-hRCtFnnzG",
        "outputId": "b4c9d8c3-0683-461e-cf27-c3d7fd5e3890"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  10570\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_transform', 'activation_13', 'vocab_layer_norm', 'vocab_projector']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 166/166 [08:21<00:00,  3.02s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 53.841059602649004,\n",
            "  \"f1\": 70.01180303541746,\n",
            "  \"total\": 10570,\n",
            "  \"HasAns_exact\": 53.841059602649004,\n",
            "  \"HasAns_f1\": 70.01180303541746,\n",
            "  \"HasAns_total\": 10570\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/separate_100_tpu_h5_cval/layer_6/tpu_epoch_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/layer_6_test.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[6])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3ZeKs-Yoaa9"
      },
      "source": [
        "#### Layer 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0UQ32Bcoaa-"
      },
      "source": [
        "##### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358,
          "referenced_widgets": [
            "a63ab28efefa492d816d2460194237dc",
            "926c8df4997a4dc0892d386f9004874b",
            "eff0d59633284437a7ad2d1d67a1aa1e",
            "67c4ffe8b3c2499891676db8f0559c7a",
            "815a6a9f258346ff8d69931b95c67726",
            "b0a72cf014324114a3dbf8492e6f3483",
            "77d7737d961342428e8ab8183d0c9d7f",
            "934d71264297462fa40f2991da6f0b99",
            "fb184be9e5c34eebb3311262ea36e49e",
            "8ea5d2b38582420d97816d2b5fef2561",
            "1c4b6d8d1df1492c8a9aef137340b906"
          ]
        },
        "id": "DUUa2_uHoaa-",
        "outputId": "c9e03890-26aa-44d9-f4d3-83b22d8ac52a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  22535\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a63ab28efefa492d816d2460194237dc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/347M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'vocab_transform', 'vocab_projector', 'activation_13']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 353/353 [08:14<00:00,  1.40s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 41.74839139116929,\n",
            "  \"f1\": 62.411157409621886,\n",
            "  \"total\": 22535,\n",
            "  \"HasAns_exact\": 41.74839139116929,\n",
            "  \"HasAns_f1\": 62.411157409621886,\n",
            "  \"HasAns_total\": 22535\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/validation_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/separate_100_tpu_h5_cval/layer_5/tpu_epoch_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/layer_5_val.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u92hV76qoaa-"
      },
      "source": [
        "##### Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsV5VHDnoaa-",
        "outputId": "249ffc61-95fe-4bfd-8d6c-ae55fd17f904"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  10570\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'vocab_transform', 'vocab_projector', 'activation_13']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 166/166 [04:21<00:00,  1.58s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 53.39640491958373,\n",
            "  \"f1\": 69.51986803264565,\n",
            "  \"total\": 10570,\n",
            "  \"HasAns_exact\": 53.39640491958373,\n",
            "  \"HasAns_f1\": 69.51986803264565,\n",
            "  \"HasAns_total\": 10570\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/separate_100_tpu_h5_cval/layer_5/tpu_epoch_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/layer_5_test.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4rO9PYdoghi"
      },
      "source": [
        "#### Layer 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEYZ5-U4oghi"
      },
      "source": [
        "##### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlrgtMQHoghi",
        "outputId": "b6f5727e-f1a6-445f-a0da-2be773e6dd14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  22535\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'vocab_transform', 'vocab_projector', 'activation_13']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 353/353 [07:17<00:00,  1.24s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 40.74994453072998,\n",
            "  \"f1\": 60.74684044239788,\n",
            "  \"total\": 22535,\n",
            "  \"HasAns_exact\": 40.74994453072998,\n",
            "  \"HasAns_f1\": 60.74684044239788,\n",
            "  \"HasAns_total\": 22535\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/validation_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/separate_100_tpu_h5_cval/layer_4/tpu_epoch_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/layer_4_val.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqTYtR5Hoghj"
      },
      "source": [
        "##### Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kGeIvZdoghj",
        "outputId": "b282fc3a-2820-43a0-ef48-f659de6b21e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  10570\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'vocab_transform', 'vocab_projector', 'activation_13']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 166/166 [03:27<00:00,  1.25s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 51.116367076631974,\n",
            "  \"f1\": 67.53716270010537,\n",
            "  \"total\": 10570,\n",
            "  \"HasAns_exact\": 51.116367076631974,\n",
            "  \"HasAns_f1\": 67.53716270010537,\n",
            "  \"HasAns_total\": 10570\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/separate_100_tpu_h5_cval/layer_4/tpu_epoch_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/layer_4_test.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwSjGZFRolDy"
      },
      "source": [
        "#### Layer 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldaooUcuolDz"
      },
      "source": [
        "##### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42wlRpR7olDz",
        "outputId": "11e51748-e3c2-4855-dd4d-cd3aa5eadf30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  22535\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'vocab_transform', 'vocab_projector', 'activation_13']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 353/353 [05:34<00:00,  1.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 36.2059019303306,\n",
            "  \"f1\": 56.05652193236517,\n",
            "  \"total\": 22535,\n",
            "  \"HasAns_exact\": 36.2059019303306,\n",
            "  \"HasAns_f1\": 56.05652193236517,\n",
            "  \"HasAns_total\": 22535\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/validation_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/separate_100_tpu_h5_cval/layer_3/tpu_epoch_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/layer_3_val.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73FzQAzqolDz"
      },
      "source": [
        "##### Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkW10iHIolD0",
        "outputId": "6c26b653-279c-457e-89cb-75e7dd25f2db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  10570\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'vocab_transform', 'vocab_projector', 'activation_13']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 166/166 [02:40<00:00,  1.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 45.96972563859981,\n",
            "  \"f1\": 62.36077645143444,\n",
            "  \"total\": 10570,\n",
            "  \"HasAns_exact\": 45.96972563859981,\n",
            "  \"HasAns_f1\": 62.36077645143444,\n",
            "  \"HasAns_total\": 10570\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/separate_100_tpu_h5_cval/layer_3/tpu_epoch_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/layer_3_test.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDg1v4n0ooSb"
      },
      "source": [
        "#### Layer 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3662A70ooSc"
      },
      "source": [
        "##### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RobLL1DPooSd",
        "outputId": "1b8bd724-4d8d-4101-a6f9-ff2be92351f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  22535\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'vocab_transform', 'vocab_projector', 'activation_13']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 353/353 [04:31<00:00,  1.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 28.697581539826935,\n",
            "  \"f1\": 47.20514090463173,\n",
            "  \"total\": 22535,\n",
            "  \"HasAns_exact\": 28.697581539826935,\n",
            "  \"HasAns_f1\": 47.20514090463173,\n",
            "  \"HasAns_total\": 22535\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/validation_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/separate_100_tpu_h5_cval/layer_2/tpu_epoch_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/layer_2_val.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "layrsPlTooSd"
      },
      "source": [
        "##### Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJ8BETkfooSd",
        "outputId": "19f169f4-ab0b-4a83-f4ec-0ad491c3ca1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  10570\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'vocab_transform', 'vocab_projector', 'activation_13']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 166/166 [02:21<00:00,  1.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 35.052034058656574,\n",
            "  \"f1\": 51.60085646289401,\n",
            "  \"total\": 10570,\n",
            "  \"HasAns_exact\": 35.052034058656574,\n",
            "  \"HasAns_f1\": 51.60085646289401,\n",
            "  \"HasAns_total\": 10570\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/separate_100_tpu_h5_cval/layer_2/tpu_epoch_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/layer_2_test.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4hmZlbForhE"
      },
      "source": [
        "#### Layer 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZOeAAIOorhG"
      },
      "source": [
        "##### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRBVRdUrorhG",
        "outputId": "2057f03b-3c24-436b-d3ff-a6f811aa5fdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  22535\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'vocab_transform', 'vocab_projector', 'activation_13']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 353/353 [03:21<00:00,  1.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 8.00088750832039,\n",
            "  \"f1\": 18.539525957828342,\n",
            "  \"total\": 22535,\n",
            "  \"HasAns_exact\": 8.00088750832039,\n",
            "  \"HasAns_f1\": 18.539525957828342,\n",
            "  \"HasAns_total\": 22535\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/validation_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/separate_100_tpu_h5_cval/layer_1/tpu_epoch_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/layer_1_val.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGPQ2OLuorhG"
      },
      "source": [
        "##### Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fcc3NqJCorhG",
        "outputId": "4caeefcc-bbc1-4c47-e46d-08b7c3f844f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  10570\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'vocab_transform', 'vocab_projector', 'activation_13']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 166/166 [01:28<00:00,  1.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 9.12961210974456,\n",
            "  \"f1\": 19.420668617291476,\n",
            "  \"total\": 10570,\n",
            "  \"HasAns_exact\": 9.12961210974456,\n",
            "  \"HasAns_f1\": 19.420668617291476,\n",
            "  \"HasAns_total\": 10570\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/separate_100_tpu_h5_cval/layer_1/tpu_epoch_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/layer_1_test.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s97CK93_S-ul"
      },
      "source": [
        "### Bert model (TPU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhqw6Hd2S-ul"
      },
      "source": [
        "#### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVpJfrPeS-um",
        "outputId": "a214901d-e6e1-4e0f-b81d-93e744a90c4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  22535\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "100%|██████████| 353/353 [23:48<00:00,  4.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 44.54848014200133,\n",
            "  \"f1\": 65.65412241408059,\n",
            "  \"total\": 22535,\n",
            "  \"HasAns_exact\": 44.54848014200133,\n",
            "  \"HasAns_f1\": 65.65412241408059,\n",
            "  \"HasAns_total\": 22535\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"../data/validation_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"../weights/training_BERT_tpu_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '../data/bert_predictions_val_tpu.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[9,10,11,12], bert=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEp-FxXCS-un"
      },
      "source": [
        "#### Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhiB5HuES-un",
        "outputId": "a0cc4830-3e81-4dc2-d16e-fa8d2ef9232a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  10570\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "100%|██████████| 166/166 [14:37<00:00,  5.29s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 57.086092715231786,\n",
            "  \"f1\": 73.19355280319321,\n",
            "  \"total\": 10570,\n",
            "  \"HasAns_exact\": 57.086092715231786,\n",
            "  \"HasAns_f1\": 73.19355280319321,\n",
            "  \"HasAns_total\": 10570\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/drive/MyDrive/NLP/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/NLP/weights/training_BERT_tpu_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/NLP/data/bert_predictions_test_tpu.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[9,10,11,12], bert=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6pxgAUvmygM"
      },
      "source": [
        "### Ensemble DistilBert + Bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAqBvzv8mygN"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "\n",
        "def compute_ensemble_predictions(dataset: tf.data.Dataset,\n",
        "                                 model: List):\n",
        "    '''\n",
        "    Computes predictions given the dataset, the used configuration parameters and model\n",
        "\n",
        "    Inputs:\n",
        "    - dataset: a `tf.data.Dataset` on which we will compute predictions.\n",
        "    - model: a `keras.Model` that computes the predictions.\n",
        "    '''\n",
        "    predictions = {}\n",
        "    # For each sample we can extract from the dataset (it can be a single element or \n",
        "    # a batch)\n",
        "    for sample in tqdm(dataset):\n",
        "        # We let the model predict the probability tensors given the input features\n",
        "        features = sample[0]\n",
        "        pstartv_bert, pendv_bert = model[0].predict(features)\n",
        "        features.pop(\"token_type_ids\")\n",
        "        pstartv_distil, pendv_distil = model[1].predict(features)\n",
        "\n",
        "        pstartv = pstartv_bert + pstartv_distil\n",
        "        pendv = pendv_bert + pendv_distil\n",
        "        \n",
        "        # We obtain the span from the probabilities\n",
        "        predicted_limits = utils.start_end_token_from_probabilities(\n",
        "            pstartv, pendv\n",
        "        )\n",
        "        # Then we decode the answer's tokens \n",
        "        question_ids = [x.decode('utf-8') for x in sample[1].numpy()]\n",
        "\n",
        "        # Finaally, we produce the output dictionary for the batch\n",
        "        input_ids = features[\"input_ids\"]\n",
        "        for i in range(len(input_ids)):\n",
        "            input_id = input_ids[i]\n",
        "            question_id = question_ids[i]\n",
        "            predicted_limit = predicted_limits[i]\n",
        "            # In the output dictionary, the key is given by the question ID,\n",
        "            # while the answer is provided as decoded text.\n",
        "            predictions[question_id] = config.tokenizer.decode(\n",
        "                input_id[\n",
        "                    predicted_limit[0]:predicted_limit[1]+1\n",
        "                ], skip_special_tokens=True\n",
        "            )\n",
        "    \n",
        "    return predictions\n",
        "\n",
        "def predict_and_evaluate_ensemble(DATASET_PATH:str,\n",
        "                         BEST_WEIGHTS_PATH:List, \n",
        "                         PATH_TO_PREDICTIONS_JSON:str,\n",
        "                         hidden_state_list:List=[[3,4,5,6], [9,10,11,12]]):\n",
        "    '''\n",
        "    Uses the standard model to predict the answers to the dataset provided in \n",
        "    `DATASET_PATH` using the selected weights (`BEST_WEIGHTS_PATH`), \n",
        "    saves the predictions into `PATH_TO_PREDICTIONS_JSON` and executes SQuAD's\n",
        "    evaluation script to get the exact match accuracy and F1 score.\n",
        "    '''\n",
        "    config = Config()\n",
        "    # Read dataset (JSON file)\n",
        "    data = utils.read_question_set(DATASET_PATH)\n",
        "    # Process questions\n",
        "    dataset = utils.create_dataset_from_generator(data, config, token_type_ids=True, for_training=False)\n",
        "    print(\"Number of samples: \", len(dataset))\n",
        "    dataset = dataset.batch(config.BATCH_SIZE)\n",
        "\n",
        "    # Load models\n",
        "    distilbert_model = config.create_model(False, hidden_state_list=hidden_state_list[0])\n",
        "    bert_model = config.create_model(True, hidden_state_list=hidden_state_list[1])\n",
        "\n",
        "    # Load best model weights\n",
        "    distilbert_model.load_weights(BEST_WEIGHTS_PATH[0])\n",
        "    bert_model.load_weights(BEST_WEIGHTS_PATH[1])\n",
        "\n",
        "    # Predict the answers to the questions in the dataset\n",
        "    predictions = compute_ensemble_predictions(dataset, [bert_model, distilbert_model])\n",
        "\n",
        "    # Create a prediction file formatted like the one that is expected\n",
        "    with open(PATH_TO_PREDICTIONS_JSON, 'w') as f:\n",
        "        json.dump(predictions, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-toJc8JS-uo"
      },
      "source": [
        "#### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8EJ_-yeS-uo",
        "outputId": "dfd2b33b-ef78-404e-858c-497de6cf6705"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 44.8502329709341,\n",
            "  \"f1\": 65.5578733295942,\n",
            "  \"total\": 22535,\n",
            "  \"HasAns_exact\": 44.8502329709341,\n",
            "  \"HasAns_f1\": 65.5578733295942,\n",
            "  \"HasAns_total\": 22535\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/drive/MyDrive/NLP/data/validation_set.json\"\n",
        "BEST_WEIGHTS_PATH_BERT = \"/content/drive/MyDrive/NLP/weights/training_BERT_tpu_last.h5\"\n",
        "BEST_WEIGHTS_PATH_DISTILBERT = \"/content/drive/MyDrive/NLP/weights/training_normal_tpu_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/NLP/data/ensemble_predictions_val_tpu.txt'\n",
        "\n",
        "predict_and_evaluate_ensemble(DATASET_PATH=DATASET_PATH, \n",
        "                              BEST_WEIGHTS_PATH=[BEST_WEIGHTS_PATH_DISTILBERT, BEST_WEIGHTS_PATH_BERT], \n",
        "                              PATH_TO_PREDICTIONS_JSON=PATH_TO_PREDICTIONS_JSON)\n",
        "!python /content/eval/evaluate.py $DATASET_PATH $PATH_TO_PREDICTIONS_JSON"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVzU9-FrS-up"
      },
      "source": [
        "#### Test set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tN29t54YS-up",
        "outputId": "9199b13d-044e-4ffb-8aed-6be88de9f8d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 56.9914853358562,\n",
            "  \"f1\": 72.94816595843261,\n",
            "  \"total\": 10570,\n",
            "  \"HasAns_exact\": 56.9914853358562,\n",
            "  \"HasAns_f1\": 72.94816595843261,\n",
            "  \"HasAns_total\": 10570\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/drive/MyDrive/NLP/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH_BERT= \"/content/drive/MyDrive/NLP/weights/training_BERT_tpu_last.h5\"\n",
        "BEST_WEIGHTS_PATH_DISTILBERT = \"/content/drive/MyDrive/NLP/weights/training_normal_tpu_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/NLP/data/ensemble_predictions_test_tpu.txt'\n",
        "\n",
        "predict_and_evaluate_ensemble(DATASET_PATH=DATASET_PATH, BEST_WEIGHTS_PATH=[BEST_WEIGHTS_PATH_DISTILBERT, BEST_WEIGHTS_PATH_BERT], PATH_TO_PREDICTIONS_JSON=PATH_TO_PREDICTIONS_JSON)\n",
        "!python /content/eval/evaluate.py $DATASET_PATH $PATH_TO_PREDICTIONS_JSON"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgn_zB2PeAB_"
      },
      "source": [
        "### NER model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FYdupE5ejpe"
      },
      "source": [
        "#### NER weight offset = 0.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G25k_J80d7Cy"
      },
      "source": [
        "##### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1limPz-Kd7C6",
        "outputId": "e2c661d5-7e0d-48a5-b1b3-2692276a463f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  22535\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_transform', 'vocab_layer_norm', 'activation_13', 'vocab_projector']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 353/353 [30:21<00:00,  5.16s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 40.29731528733082,\n",
            "  \"f1\": 61.10515720895817,\n",
            "  \"total\": 22535,\n",
            "  \"HasAns_exact\": 40.29731528733082,\n",
            "  \"HasAns_f1\": 61.10515720895817,\n",
            "  \"HasAns_total\": 22535\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/validation_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/NER_100_tpu_h5_cval/hyperparameter_0,2/training_NER_02_tpu_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/NER_02_predictions_val.txt'\n",
        "NER_VALUE = 0.2\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, use_NER_attention=True, NER_value=NER_VALUE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCqlIhmSd7C6"
      },
      "source": [
        "##### Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEV6GLQKd7C7",
        "outputId": "f93cff8d-ecb4-4e1a-e720-d6f57064c21b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  10570\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_transform', 'vocab_layer_norm', 'activation_13', 'vocab_projector']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 166/166 [13:53<00:00,  5.02s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 51.36234626300851,\n",
            "  \"f1\": 68.03648925049636,\n",
            "  \"total\": 10570,\n",
            "  \"HasAns_exact\": 51.36234626300851,\n",
            "  \"HasAns_f1\": 68.03648925049636,\n",
            "  \"HasAns_total\": 10570\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/NER_100_tpu_h5_cval/hyperparameter_0,2/training_NER_02_tpu_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/NER_02_predictions_test.txt'\n",
        "NER_VALUE = 0.2\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, use_NER_attention=True, NER_value=NER_VALUE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx_5kiCWyleq"
      },
      "source": [
        "#### NER weight offset = 0.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xn3kUTl0yle0"
      },
      "source": [
        "##### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrISe7URyle0",
        "outputId": "8c332092-6edd-4a34-f734-951f771408d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  22535\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_transform', 'vocab_layer_norm', 'activation_13', 'vocab_projector']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 353/353 [30:21<00:00,  5.16s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 40.35944086975815,\n",
            "  \"f1\": 61.296511079528514,\n",
            "  \"total\": 22535,\n",
            "  \"HasAns_exact\": 40.35944086975815,\n",
            "  \"HasAns_f1\": 61.296511079528514,\n",
            "  \"HasAns_total\": 22535\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/validation_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/NER_100_tpu_h5_cval/hyperparameter_0.4/training_NER_04_tpu_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/NER_04_predictions_val.txt'\n",
        "NER_VALUE = 0.4\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, use_NER_attention=True, NER_value=NER_VALUE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_P2BWwoByle1"
      },
      "source": [
        "##### Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeiPTdlnyle1",
        "outputId": "e32a5267-3623-4b46-97be-6469b0cbd108"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  10570\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_transform', 'vocab_layer_norm', 'activation_13', 'vocab_projector']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 166/166 [14:21<00:00,  5.19s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 51.863765373699145,\n",
            "  \"f1\": 68.43574692147928,\n",
            "  \"total\": 10570,\n",
            "  \"HasAns_exact\": 51.863765373699145,\n",
            "  \"HasAns_f1\": 68.43574692147928,\n",
            "  \"HasAns_total\": 10570\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/NER_100_tpu_h5_cval/hyperparameter_0.4/training_NER_04_tpu_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/NER_04_predictions_test.txt'\n",
        "NER_VALUE = 0.4\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, use_NER_attention=True, NER_value=NER_VALUE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LamJUSbV3eS"
      },
      "source": [
        "#### NER weight offset = 0.6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n49I8u_0V3ee"
      },
      "source": [
        "##### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330,
          "referenced_widgets": [
            "2e535c91d80a43578bbb831dab804059",
            "13e2fa4f8a6e4d90a4e6e0114921073d",
            "2dfa36dbd85f469fa474c2fd30b15f54",
            "1844736d7ebb4f719cad5056eb10cb76",
            "ca5d6e40a21f4067a0acc9eaf6545955",
            "fb08161720de491b8b5be799d32f921a",
            "f8f1a60cca254c3d8e2251ed7449830c",
            "656a38b4e0ba4d2e9e8ae32dd17c6205",
            "d176af6bc2bc4dd7bd9b9f706261478c",
            "1ab29e8c869f47d883473a8dfb538f1c",
            "249915abc198448e9676c8b2a5040642"
          ]
        },
        "id": "cqKRAdjvV3ee",
        "outputId": "62398957-8d00-45ff-da84-b3cc880f4eb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  22535\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e535c91d80a43578bbb831dab804059",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/347M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_projector', 'activation_13', 'vocab_transform', 'vocab_layer_norm']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 353/353 [24:21<00:00,  4.14s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 40.32837807854449,\n",
            "  \"f1\": 61.11215226289375,\n",
            "  \"total\": 22535,\n",
            "  \"HasAns_exact\": 40.32837807854449,\n",
            "  \"HasAns_f1\": 61.11215226289375,\n",
            "  \"HasAns_total\": 22535\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/validation_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/NER_100_tpu_h5_cval/hyperparameter_0,6/training_NER_06_tpu_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/NER_06_predictions_val.txt'\n",
        "NER_VALUE = 0.6\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, use_NER_attention=True, NER_value=NER_VALUE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtCPZXdWV3ef"
      },
      "source": [
        "##### Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DINvLkyYV3ef",
        "outputId": "08be2a95-916e-4686-9318-b96c3da0cb6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  10570\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_projector', 'activation_13', 'vocab_transform', 'vocab_layer_norm']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 166/166 [11:21<00:00,  4.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 51.57048249763481,\n",
            "  \"f1\": 68.12658908682066,\n",
            "  \"total\": 10570,\n",
            "  \"HasAns_exact\": 51.57048249763481,\n",
            "  \"HasAns_f1\": 68.12658908682066,\n",
            "  \"HasAns_total\": 10570\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/NER_100_tpu_h5_cval/hyperparameter_0,6/training_NER_06_tpu_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/NER_06_predictions_test.txt'\n",
        "NER_VALUE = 0.6\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, use_NER_attention=True, NER_value=NER_VALUE)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "NLP_Project_evaluation_tests.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "13e2fa4f8a6e4d90a4e6e0114921073d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1844736d7ebb4f719cad5056eb10cb76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d176af6bc2bc4dd7bd9b9f706261478c",
            "max": 363423424,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_656a38b4e0ba4d2e9e8ae32dd17c6205",
            "value": 363423424
          }
        },
        "1ab29e8c869f47d883473a8dfb538f1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c4b6d8d1df1492c8a9aef137340b906": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "249915abc198448e9676c8b2a5040642": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2dfa36dbd85f469fa474c2fd30b15f54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8f1a60cca254c3d8e2251ed7449830c",
            "placeholder": "​",
            "style": "IPY_MODEL_fb08161720de491b8b5be799d32f921a",
            "value": "Downloading: 100%"
          }
        },
        "2e535c91d80a43578bbb831dab804059": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2dfa36dbd85f469fa474c2fd30b15f54",
              "IPY_MODEL_1844736d7ebb4f719cad5056eb10cb76",
              "IPY_MODEL_ca5d6e40a21f4067a0acc9eaf6545955"
            ],
            "layout": "IPY_MODEL_13e2fa4f8a6e4d90a4e6e0114921073d"
          }
        },
        "452f0c2a0dd94326be3d65688565b468": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "520c17764caa4202a7f1dda5d7bad3f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "639763a70ca9440bb54b56a5a5b1b355": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d907e2ab1b444b494f93da785669951",
            "placeholder": "​",
            "style": "IPY_MODEL_980ea8daab1b494fb9fcc18218671f0d",
            "value": " 347M/347M [00:10&lt;00:00, 36.8MB/s]"
          }
        },
        "656a38b4e0ba4d2e9e8ae32dd17c6205": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67c4ffe8b3c2499891676db8f0559c7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb184be9e5c34eebb3311262ea36e49e",
            "max": 363423424,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_934d71264297462fa40f2991da6f0b99",
            "value": 363423424
          }
        },
        "6c11ad18312d44faa523d910846e383e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d907e2ab1b444b494f93da785669951": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77d7737d961342428e8ab8183d0c9d7f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ddbea4d33f046d7bc89a1a181899326": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac9963c870624211b6c8df3742ac6a68",
              "IPY_MODEL_d30fc3e008c1496a8b49b9071ac99ee2",
              "IPY_MODEL_639763a70ca9440bb54b56a5a5b1b355"
            ],
            "layout": "IPY_MODEL_520c17764caa4202a7f1dda5d7bad3f1"
          }
        },
        "815a6a9f258346ff8d69931b95c67726": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c4b6d8d1df1492c8a9aef137340b906",
            "placeholder": "​",
            "style": "IPY_MODEL_8ea5d2b38582420d97816d2b5fef2561",
            "value": " 347M/347M [00:06&lt;00:00, 52.3MB/s]"
          }
        },
        "8ea5d2b38582420d97816d2b5fef2561": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "926c8df4997a4dc0892d386f9004874b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "934d71264297462fa40f2991da6f0b99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "980ea8daab1b494fb9fcc18218671f0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d8c2ac4cab945bda2237f67043f9229": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a63ab28efefa492d816d2460194237dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eff0d59633284437a7ad2d1d67a1aa1e",
              "IPY_MODEL_67c4ffe8b3c2499891676db8f0559c7a",
              "IPY_MODEL_815a6a9f258346ff8d69931b95c67726"
            ],
            "layout": "IPY_MODEL_926c8df4997a4dc0892d386f9004874b"
          }
        },
        "ac9963c870624211b6c8df3742ac6a68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d8c2ac4cab945bda2237f67043f9229",
            "placeholder": "​",
            "style": "IPY_MODEL_6c11ad18312d44faa523d910846e383e",
            "value": "Downloading: 100%"
          }
        },
        "b0a72cf014324114a3dbf8492e6f3483": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca107472622147949253da2524a8d67e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca5d6e40a21f4067a0acc9eaf6545955": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_249915abc198448e9676c8b2a5040642",
            "placeholder": "​",
            "style": "IPY_MODEL_1ab29e8c869f47d883473a8dfb538f1c",
            "value": " 347M/347M [00:11&lt;00:00, 31.8MB/s]"
          }
        },
        "d176af6bc2bc4dd7bd9b9f706261478c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d30fc3e008c1496a8b49b9071ac99ee2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_452f0c2a0dd94326be3d65688565b468",
            "max": 363423424,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca107472622147949253da2524a8d67e",
            "value": 363423424
          }
        },
        "eff0d59633284437a7ad2d1d67a1aa1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77d7737d961342428e8ab8183d0c9d7f",
            "placeholder": "​",
            "style": "IPY_MODEL_b0a72cf014324114a3dbf8492e6f3483",
            "value": "Downloading: 100%"
          }
        },
        "f8f1a60cca254c3d8e2251ed7449830c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb08161720de491b8b5be799d32f921a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb184be9e5c34eebb3311262ea36e49e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
