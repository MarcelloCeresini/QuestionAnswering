{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0kEBtGKqXdI"
      },
      "source": [
        "# Predictions and evaluation notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkNeJu-iqbEy"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTBhw524fjXD"
      },
      "outputs": [],
      "source": [
        "# PRIVATE CELL\n",
        "git_token = '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'\n",
        "username = 'MarcelloCeresini'\n",
        "repository = 'QuestionAnswering'\n",
        "\n",
        "# COLAB ONLY CELLS\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    !pip3 install transformers\n",
        "    !nvidia-smi             # Check which GPU has been chosen for us\n",
        "    !rm -rf logs\n",
        "    !git clone https://{git_token}@github.com/{username}/{repository}\n",
        "    %cd {repository}\n",
        "    %ls\n",
        "except:\n",
        "    IN_COLAB = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynFVwoEagLYg"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive/')\n",
        "    %cd /content/QuestionAnswering/src"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9SJg92piy3k"
      },
      "source": [
        "## Model definition for NER attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jrMG3pgpi13Z"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import layers\n",
        "from transformers import TFDistilBertModel\n",
        "from transformers.models.distilbert.modeling_tf_distilbert import TFMultiHeadSelfAttention as MHSA\n",
        "\n",
        "CHOSEN_ENHANCED_LAYER = 0\n",
        "CHOSEN_OUTPUT_STATES_IDX = [3, 4, 5, 6]\n",
        "\n",
        "class TFInjectMultiHeadSelfAttention(MHSA):\n",
        "\n",
        "    def load_NER_attention(self, NER_attention):\n",
        "        self.NER_attention = NER_attention\n",
        "\n",
        "    def call(self, query, key, value, mask, head_mask, output_attentions, training=False):\n",
        "        # key = key*tf.reshape(self.NER_attention, [self.NER_attention.shape[0], self.NER_attention.shape[1], 1])\n",
        "        key = key * tf.expand_dims(self.NER_attention, axis=-1)\n",
        "        return super().call(query, key, value, mask, head_mask, output_attentions, training=training)\n",
        "\n",
        "class QuestionAnsweringModel(keras.Model):\n",
        "\n",
        "    def __init__(self, transformer_model: TFDistilBertModel) -> None:\n",
        "        super(QuestionAnsweringModel, self).__init__()\n",
        "\n",
        "        self.transformer_model = transformer_model\n",
        "        # Apply layer change to first attention block\n",
        "        self.transformer_model.layers[0].transformer.layer[CHOSEN_ENHANCED_LAYER].attention = \\\n",
        "            TFInjectMultiHeadSelfAttention(transformer_model.config)\n",
        "        \n",
        "        # Add all remaining layers\n",
        "        self.dense_S = layers.Dense(1)\n",
        "        self.dense_E = layers.Dense(1)\n",
        "        self.flatten = layers.Flatten()\n",
        "        self.softmax_S = layers.Softmax(name='out_S')\n",
        "        self.softmax_E = layers.Softmax(name='out_E')\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        input_ids = inputs[\"input_ids\"]\n",
        "        attention_mask = inputs[\"attention_mask\"]\n",
        "        NER_attention = inputs[\"NER_attention\"]\n",
        "\n",
        "        # Load the NER tensor into the custom layer\n",
        "        self.transformer_model.layers[0].transformer.layer[0].attention.load_NER_attention(NER_attention)\n",
        "\n",
        "        out = self.transformer_model(\n",
        "            {\n",
        "                \"input_ids\": input_ids,\n",
        "                \"attention_mask\": attention_mask,\n",
        "            }\n",
        "        )\n",
        "\n",
        "        hidden_states = out.hidden_states\n",
        "        chosen_states_idx = CHOSEN_OUTPUT_STATES_IDX\n",
        "\n",
        "        chosen_hidden_states = tf.concat([hidden_states[i] for i in chosen_states_idx], axis=2)\n",
        "\n",
        "        out_S = self.dense_S(chosen_hidden_states) # dot product between token representation and start vector\n",
        "        out_S = self.flatten(out_S)\n",
        "        out_S = self.softmax_S(out_S)\n",
        "\n",
        "        out_E = self.dense_E(chosen_hidden_states) # dot product between token representation and end vector\n",
        "        out_E = self.flatten(out_E)\n",
        "        out_E = self.softmax_E(out_E)\n",
        "\n",
        "        return out_S, out_E"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKPJMUQxjLBS"
      },
      "source": [
        "## Prediction function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgRetBMOqqDP"
      },
      "source": [
        "In a single function we prepare the model, load the best weights available for it and evaluate the predictions using SQuAD's official script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aqjZ-pZhgYNH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "from typing import List\n",
        "\n",
        "from config import Config\n",
        "import utils\n",
        "\n",
        "def predict_and_evaluate(DATASET_PATH:str, \n",
        "                         BEST_WEIGHTS_PATH:str, \n",
        "                         PATH_TO_PREDICTIONS_JSON:str,\n",
        "                         hidden_state_list:List[int]=[3,4,5,6],\n",
        "                         use_NER_attention=False, NER_value=0,\n",
        "                         bert=False):\n",
        "    '''\n",
        "    Uses the standard model to predict the answers to the dataset provided in \n",
        "    `DATASET_PATH` using the selected weights (`BEST_WEIGHTS_PATH`), \n",
        "    saves the predictions into `PATH_TO_PREDICTIONS_JSON` and executes SQuAD's\n",
        "    evaluation script to get the exact match accuracy and F1 score.\n",
        "    '''\n",
        "    config = Config(bert=bert)\n",
        "    # Read dataset (JSON file)\n",
        "    data = utils.read_question_set(DATASET_PATH)\n",
        "    # Process questions\n",
        "    dataset = utils.create_dataset_from_generator(data, config, for_training=False,\n",
        "        use_NER_attention=use_NER_attention, NER_value=NER_value)\n",
        "    # Generate the original dataset that contains the original context and token-char mapping\n",
        "    original_dataset = utils.create_original_dataset(data, config)\n",
        "    original_dataset = original_dataset.batch(config.BATCH_SIZE)\n",
        "    print(\"Number of samples: \", len(dataset))\n",
        "    dataset = dataset.batch(config.BATCH_SIZE)\n",
        "    # Load model\n",
        "    if not use_NER_attention:\n",
        "        model = config.create_standard_model(hidden_state_list=hidden_state_list)\n",
        "    else:\n",
        "        model = QuestionAnsweringModel(config.get_transformer())\n",
        "        # A subclassed model needs to be called at least once before loading the weights, \n",
        "        # because it needs to create the graph\n",
        "        for sample in dataset.take(1):\n",
        "            model(sample[0])\n",
        "    # Load best model weights\n",
        "    model.load_weights(BEST_WEIGHTS_PATH)\n",
        "    # Predict the answers to the questions in the dataset\n",
        "    predictions = utils.compute_predictions(dataset, original_dataset, model)\n",
        "    # Create a prediction file formatted like the one that is expected\n",
        "    with open(PATH_TO_PREDICTIONS_JSON, 'w') as f:\n",
        "        json.dump(predictions, f)\n",
        "    \n",
        "    !python eval/evaluate.py $DATASET_PATH $PATH_TO_PREDICTIONS_JSON"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WReGVo4rrdGW"
      },
      "source": [
        "## Evaluations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgXY_7tmrgPC"
      },
      "source": [
        "### Normal model (TPU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sYhr9krrkwu"
      },
      "source": [
        "#### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCg2proMqKzE",
        "outputId": "41de7d1e-b004-4e2f-a46f-13f613df2245"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'vocab_transform', 'activation_13', 'vocab_projector']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "1409it [09:24,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 48.70645662303084,\n",
            "  \"f1\": 69.03455794280707,\n",
            "  \"total\": 22535,\n",
            "  \"HasAns_exact\": 48.70645662303084,\n",
            "  \"HasAns_f1\": 69.03455794280707,\n",
            "  \"HasAns_total\": 22535\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/validation_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/normal_100_tpu_h5_cval/training_normal_tpu_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/normal_predictions_val_tpu_CORRECT.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqriFCwTroS2"
      },
      "source": [
        "#### Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1fjfIbHqBMD",
        "outputId": "91bfcf95-48c8-4964-8b6a-bd93f7f8110d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  10570\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 48/48 [00:06<00:00,  7.42it/s]\n",
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'vocab_transform', 'activation_13', 'vocab_projector']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "661it [04:19,  2.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 61.173131504257334,\n",
            "  \"f1\": 75.52867201553052,\n",
            "  \"total\": 10570,\n",
            "  \"HasAns_exact\": 61.173131504257334,\n",
            "  \"HasAns_f1\": 75.52867201553052,\n",
            "  \"HasAns_total\": 10570\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/normal_100_tpu_h5_cval/training_normal_tpu_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/normal_predictions_test_tpu_CORRECT.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4GWqGQ1nnzE"
      },
      "source": [
        "### Separate layer models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gAtNNxQnslz"
      },
      "source": [
        "#### Layer 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7E3kzXEnnzF"
      },
      "source": [
        "##### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-jmMQ1bnnzF",
        "outputId": "8588f5a4-9e39-4df0-84cc-24e768c09204"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  22535\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 111/111 [00:13<00:00,  8.04it/s]\n",
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'vocab_transform', 'activation_13', 'vocab_projector']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "1409it [09:22,  2.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 48.320390503660974,\n",
            "  \"f1\": 68.38944666755968,\n",
            "  \"total\": 22535,\n",
            "  \"HasAns_exact\": 48.320390503660974,\n",
            "  \"HasAns_f1\": 68.38944666755968,\n",
            "  \"HasAns_total\": 22535\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/validation_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/separate_100_tpu_h5_cval/layer_6/tpu_epoch_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/layer_6_val_CORRECT.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[6])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jn2BVQ9dnnzG"
      },
      "source": [
        "##### Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kd-hRCtFnnzG",
        "outputId": "380a8cba-65fc-4f0f-96d2-56e5047be089"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  10570\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 48/48 [00:06<00:00,  7.35it/s]\n",
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'vocab_transform', 'activation_13', 'vocab_projector']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "661it [04:24,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 60.74739829706717,\n",
            "  \"f1\": 75.1497476516914,\n",
            "  \"total\": 10570,\n",
            "  \"HasAns_exact\": 60.74739829706717,\n",
            "  \"HasAns_f1\": 75.1497476516914,\n",
            "  \"HasAns_total\": 10570\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/separate_100_tpu_h5_cval/layer_6/tpu_epoch_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/layer_6_test_CORRECT.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[6])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3ZeKs-Yoaa9"
      },
      "source": [
        "#### Layer 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0UQ32Bcoaa-"
      },
      "source": [
        "##### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DUUa2_uHoaa-",
        "outputId": "dfe1a45b-f719-44f0-8f03-ec27142f2acc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346,
          "referenced_widgets": [
            "dbe95263736c48ab811ef90d7d61ce30",
            "4be0372521104282b5fda52bf1ceb49d",
            "b6c94940f57a442e90abfe9f8e6292cc",
            "ab8d6d3b3fd140edbc4dd5f83c8ee9f1",
            "c6f1fc380f874d799ffadb46e8050e3f",
            "2f2ca07077ae48c88fe78a4820c26830",
            "3ed74c9abaf94b92a4fbbf45c34d9e9b",
            "cc6b5a57d3734cc49805435831c6de56",
            "a6e3055734e5491d920a8c06a3441994",
            "a340c0abc3d34160a4fe772e5394da97",
            "724737c274f144f9b0eb323e1f6edf74"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 111/111 [00:15<00:00,  6.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples:  22535\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dbe95263736c48ab811ef90d7d61ce30",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/347M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'vocab_projector', 'activation_13', 'vocab_transform']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 1409/1409 [14:26<00:00,  1.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"exact\": 47.8411360106501,\n",
            "  \"f1\": 67.92389418729441,\n",
            "  \"total\": 22535,\n",
            "  \"HasAns_exact\": 47.8411360106501,\n",
            "  \"HasAns_f1\": 67.92389418729441,\n",
            "  \"HasAns_total\": 22535\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/validation_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/separate_100_tpu_h5_cval/layer_5/tpu_epoch_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/layer_5_val_CORRECT.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u92hV76qoaa-"
      },
      "source": [
        "##### Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KsV5VHDnoaa-",
        "outputId": "232b96a4-6ced-49ad-d685-3f7d7516f194",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 48/48 [00:07<00:00,  6.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples:  10570\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'vocab_projector', 'activation_13', 'vocab_transform']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 661/661 [06:51<00:00,  1.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"exact\": 60.23651844843898,\n",
            "  \"f1\": 74.57716815141067,\n",
            "  \"total\": 10570,\n",
            "  \"HasAns_exact\": 60.23651844843898,\n",
            "  \"HasAns_f1\": 74.57716815141067,\n",
            "  \"HasAns_total\": 10570\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/separate_100_tpu_h5_cval/layer_5/tpu_epoch_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/layer_5_test_CORRECT.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4rO9PYdoghi"
      },
      "source": [
        "#### Layer 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEYZ5-U4oghi"
      },
      "source": [
        "##### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hlrgtMQHoghi",
        "outputId": "0de8b394-f1c5-43a4-b88d-5f6afdeb3f52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 111/111 [00:16<00:00,  6.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples:  22535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'vocab_projector', 'activation_13', 'vocab_transform']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 1409/1409 [12:06<00:00,  1.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"exact\": 46.78943865098735,\n",
            "  \"f1\": 66.21026117006551,\n",
            "  \"total\": 22535,\n",
            "  \"HasAns_exact\": 46.78943865098735,\n",
            "  \"HasAns_f1\": 66.21026117006551,\n",
            "  \"HasAns_total\": 22535\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/validation_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/separate_100_tpu_h5_cval/layer_4/tpu_epoch_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/layer_4_val_CORRECT.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqTYtR5Hoghj"
      },
      "source": [
        "##### Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-kGeIvZdoghj",
        "outputId": "6e479102-02a0-4399-f5db-4449056f8cd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 48/48 [00:08<00:00,  5.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples:  10570\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'vocab_projector', 'activation_13', 'vocab_transform']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 661/661 [05:42<00:00,  1.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"exact\": 57.59697256385998,\n",
            "  \"f1\": 72.40476885312422,\n",
            "  \"total\": 10570,\n",
            "  \"HasAns_exact\": 57.59697256385998,\n",
            "  \"HasAns_f1\": 72.40476885312422,\n",
            "  \"HasAns_total\": 10570\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/separate_100_tpu_h5_cval/layer_4/tpu_epoch_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/layer_4_test_CORRECT.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwSjGZFRolDy"
      },
      "source": [
        "#### Layer 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldaooUcuolDz"
      },
      "source": [
        "##### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "42wlRpR7olDz",
        "outputId": "115fe9b1-ab95-46df-a5e4-7d874f034c03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 111/111 [00:16<00:00,  6.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples:  22535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'vocab_projector', 'activation_13', 'vocab_transform']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 1409/1409 [09:48<00:00,  2.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"exact\": 41.54426447747947,\n",
            "  \"f1\": 61.10454005294163,\n",
            "  \"total\": 22535,\n",
            "  \"HasAns_exact\": 41.54426447747947,\n",
            "  \"HasAns_f1\": 61.10454005294163,\n",
            "  \"HasAns_total\": 22535\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/validation_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/separate_100_tpu_h5_cval/layer_3/tpu_epoch_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/layer_3_val_CORRECT.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73FzQAzqolDz"
      },
      "source": [
        "##### Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RkW10iHIolD0",
        "outputId": "8ded3ba6-2e1d-401a-ee56-34ecdc06a5b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 48/48 [00:08<00:00,  5.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples:  10570\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'vocab_projector', 'activation_13', 'vocab_transform']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 661/661 [04:37<00:00,  2.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"exact\": 51.81646168401135,\n",
            "  \"f1\": 66.88629030679493,\n",
            "  \"total\": 10570,\n",
            "  \"HasAns_exact\": 51.81646168401135,\n",
            "  \"HasAns_f1\": 66.88629030679493,\n",
            "  \"HasAns_total\": 10570\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/separate_100_tpu_h5_cval/layer_3/tpu_epoch_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/layer_3_test_CORRECT.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDg1v4n0ooSb"
      },
      "source": [
        "#### Layer 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3662A70ooSc"
      },
      "source": [
        "##### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RobLL1DPooSd",
        "outputId": "e0aca6d5-9cb6-4d6e-e441-1204b821e641",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 111/111 [00:17<00:00,  6.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples:  22535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'vocab_projector', 'activation_13', 'vocab_transform']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 1409/1409 [07:52<00:00,  2.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"exact\": 33.12624805857555,\n",
            "  \"f1\": 51.57614379132821,\n",
            "  \"total\": 22535,\n",
            "  \"HasAns_exact\": 33.12624805857555,\n",
            "  \"HasAns_f1\": 51.57614379132821,\n",
            "  \"HasAns_total\": 22535\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/validation_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/separate_100_tpu_h5_cval/layer_2/tpu_epoch_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/layer_2_val_CORRECT.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "layrsPlTooSd"
      },
      "source": [
        "##### Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SJ8BETkfooSd",
        "outputId": "83b7948d-a4ad-4ee4-ebed-65b5765de882",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 48/48 [00:08<00:00,  5.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples:  10570\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'vocab_projector', 'activation_13', 'vocab_transform']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 661/661 [03:40<00:00,  2.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"exact\": 39.71617786187323,\n",
            "  \"f1\": 55.37620955911666,\n",
            "  \"total\": 10570,\n",
            "  \"HasAns_exact\": 39.71617786187323,\n",
            "  \"HasAns_f1\": 55.37620955911666,\n",
            "  \"HasAns_total\": 10570\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/separate_100_tpu_h5_cval/layer_2/tpu_epoch_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/layer_2_test_CORRECT.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4hmZlbForhE"
      },
      "source": [
        "#### Layer 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZOeAAIOorhG"
      },
      "source": [
        "##### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HRBVRdUrorhG",
        "outputId": "4c6a8654-f5fa-4178-b796-dc1c6f4c4b73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 111/111 [00:16<00:00,  6.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples:  22535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'vocab_projector', 'activation_13', 'vocab_transform']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 1409/1409 [05:48<00:00,  4.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"exact\": 9.496339028178388,\n",
            "  \"f1\": 20.43760797464446,\n",
            "  \"total\": 22535,\n",
            "  \"HasAns_exact\": 9.496339028178388,\n",
            "  \"HasAns_f1\": 20.43760797464446,\n",
            "  \"HasAns_total\": 22535\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/validation_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/separate_100_tpu_h5_cval/layer_1/tpu_epoch_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/layer_1_val_CORRECT.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGPQ2OLuorhG"
      },
      "source": [
        "##### Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Fcc3NqJCorhG",
        "outputId": "e9acd6fc-f3db-417a-f3cb-dfe752276637",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 48/48 [00:08<00:00,  5.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples:  10570\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'vocab_projector', 'activation_13', 'vocab_transform']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 661/661 [02:43<00:00,  4.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"exact\": 10.491958372753075,\n",
            "  \"f1\": 20.898479815610294,\n",
            "  \"total\": 10570,\n",
            "  \"HasAns_exact\": 10.491958372753075,\n",
            "  \"HasAns_f1\": 20.898479815610294,\n",
            "  \"HasAns_total\": 10570\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/separate_100_tpu_h5_cval/layer_1/tpu_epoch_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/layer_1_test_CORRECT.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s97CK93_S-ul"
      },
      "source": [
        "### Bert model (TPU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhqw6Hd2S-ul"
      },
      "source": [
        "#### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jVpJfrPeS-um",
        "outputId": "82768ca5-8211-4d57-95c4-a9d7102a973f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346,
          "referenced_widgets": [
            "df676c6d310040dba4af7270d42746fb",
            "c12fbfe2b3fd4539a5fb36e40b14b43d",
            "d2a34da384a24e20bdd35adfde0af042",
            "0744a3ae81864889af7aa8d0872e553b",
            "01d1971e1646477aa2dc2b1ece0983dd",
            "3b9bb77fb6ad4e5a98b8b12f97c72dc1",
            "820d026616e94bf0a82357b230454117",
            "f22668f2e0f94803ac864be8b3afb817",
            "2c3867e508f4417b839d282d089d11ce",
            "ca87a65403e74c5287322229bd88f79a",
            "db6e45ccc1c94f69b0db9494553327fa"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 111/111 [00:20<00:00,  5.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples:  22535\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df676c6d310040dba4af7270d42746fb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/511M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "100%|██████████| 1409/1409 [31:07<00:00,  1.33s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"exact\": 51.12935433769692,\n",
            "  \"f1\": 71.45761788040576,\n",
            "  \"total\": 22535,\n",
            "  \"HasAns_exact\": 51.12935433769692,\n",
            "  \"HasAns_f1\": 71.45761788040576,\n",
            "  \"HasAns_total\": 22535\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/validation_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/normal_BERT_100_tpu_h5_cval/training_BERT_tpu_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/bert_predictions_val_tpu_CORRECT.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[9,10,11,12], bert=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEp-FxXCS-un"
      },
      "source": [
        "#### Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "VhiB5HuES-un",
        "outputId": "8a85015b-9a65-4743-e799-4beeb834415a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 48/48 [00:08<00:00,  5.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples:  10570\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "100%|██████████| 661/661 [14:39<00:00,  1.33s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"exact\": 64.33301797540209,\n",
            "  \"f1\": 78.58992810021775,\n",
            "  \"total\": 10570,\n",
            "  \"HasAns_exact\": 64.33301797540209,\n",
            "  \"HasAns_f1\": 78.58992810021775,\n",
            "  \"HasAns_total\": 10570\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/normal_BERT_100_tpu_h5_cval/training_BERT_tpu_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/bert_predictions_test_tpu_CORRECT.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, hidden_state_list=[9,10,11,12], bert=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6pxgAUvmygM"
      },
      "source": [
        "### Ensemble DistilBert + Bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "wAqBvzv8mygN"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "\n",
        "def compute_ensemble_predictions(dataset: tf.data.Dataset,\n",
        "                                 original_dataset: tf.data.Dataset,\n",
        "                                 model: List):\n",
        "    '''\n",
        "    Computes predictions given the dataset, the used configuration parameters and model\n",
        "\n",
        "    Inputs:\n",
        "    - dataset: a `tf.data.Dataset` on which we will compute predictions.\n",
        "    - original_dataset: a `tf.data.Dataset` which contains the original context\n",
        "        and initial/starting characters for each token.\n",
        "    - model: a `keras.Model` that computes the predictions.\n",
        "    '''\n",
        "    predictions = {}\n",
        "    # For each sample we can extract from the dataset (it can be a single element or \n",
        "    # a batch)\n",
        "    for sample, original_sample in tqdm(zip(dataset, original_dataset), total=len(dataset)):\n",
        "        # We let the model predict the probability tensors given the input features\n",
        "        contexts = original_sample[\"context\"].numpy()\n",
        "        offsets = original_sample[\"offset_mapping\"].numpy()\n",
        "\n",
        "        features = sample[0]\n",
        "        pstartv_bert, pendv_bert = model[0].predict(features)\n",
        "        features.pop(\"token_type_ids\")\n",
        "        pstartv_distil, pendv_distil = model[1].predict(features)\n",
        "\n",
        "        # We sum the two probability distributions\n",
        "        pstartv = pstartv_bert + pstartv_distil\n",
        "        pendv = pendv_bert + pendv_distil\n",
        "        \n",
        "        # We obtain the span from the probabilities\n",
        "        predicted_limits = utils.start_end_token_from_probabilities(\n",
        "            pstartv, pendv\n",
        "        )\n",
        "        # Then we decode the answer's tokens \n",
        "        question_ids = [x.decode('utf-8') for x in sample[1].numpy()]\n",
        "\n",
        "        input_ids = features[\"input_ids\"]\n",
        "        # Finally, we produce the output dictionary for the batch\n",
        "        for i in range(len(input_ids)):\n",
        "            question_id = question_ids[i]\n",
        "            predicted_limit = predicted_limits[i]\n",
        "            context = contexts[i]\n",
        "            offset = offsets[i]\n",
        "            # Compute the predictions using the token characters \n",
        "            # from the original dataset\n",
        "            predictions[question_id] = context.decode()[\n",
        "                offset[predicted_limit[0], 0] \n",
        "                : \n",
        "                offset[predicted_limit[1], 1]\n",
        "            ]\n",
        "    \n",
        "    return predictions\n",
        "\n",
        "def predict_and_evaluate_ensemble(DATASET_PATH:str,\n",
        "                         BEST_WEIGHTS_PATH:List, \n",
        "                         PATH_TO_PREDICTIONS_JSON:str,\n",
        "                         hidden_state_list:List=[[3,4,5,6], [9,10,11,12]]):\n",
        "    '''\n",
        "    Uses the standard model to predict the answers to the dataset provided in \n",
        "    `DATASET_PATH` using the selected weights (`BEST_WEIGHTS_PATH`), \n",
        "    saves the predictions into `PATH_TO_PREDICTIONS_JSON` and executes SQuAD's\n",
        "    evaluation script to get the exact match accuracy and F1 score.\n",
        "    '''\n",
        "    config = Config()\n",
        "    # Read dataset (JSON file)\n",
        "    data = utils.read_question_set(DATASET_PATH)\n",
        "    # Process questions\n",
        "    dataset = utils.create_dataset_from_generator(data, config, token_type_ids=True, for_training=False)\n",
        "    print(\"Number of samples: \", len(dataset))\n",
        "    dataset = dataset.batch(config.BATCH_SIZE)\n",
        "\n",
        "    # Create the original dataset with the same order as the processed one\n",
        "    original_dataset = utils.create_original_dataset(data, config)\n",
        "    original_dataset = original_dataset.batch(config.BATCH_SIZE)\n",
        "\n",
        "    # Load models\n",
        "    distilbert_model = config.create_model(False, hidden_state_list=hidden_state_list[0])\n",
        "    bert_model = config.create_model(True, hidden_state_list=hidden_state_list[1])\n",
        "\n",
        "    # Load best model weights\n",
        "    distilbert_model.load_weights(BEST_WEIGHTS_PATH[0])\n",
        "    bert_model.load_weights(BEST_WEIGHTS_PATH[1])\n",
        "\n",
        "    # Predict the answers to the questions in the dataset\n",
        "    predictions = compute_ensemble_predictions(dataset, original_dataset, [bert_model, distilbert_model])\n",
        "\n",
        "    # Create a prediction file formatted like the one that is expected\n",
        "    with open(PATH_TO_PREDICTIONS_JSON, 'w') as f:\n",
        "        json.dump(predictions, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-toJc8JS-uo"
      },
      "source": [
        "#### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8EJ_-yeS-uo"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = \"/content/drive/MyDrive/NLP/data/validation_set.json\"\n",
        "BEST_WEIGHTS_PATH_BERT = \"/content/drive/MyDrive/NLP/weights/training_BERT_tpu_last.h5\"\n",
        "BEST_WEIGHTS_PATH_DISTILBERT = \"/content/drive/MyDrive/NLP/weights/training_normal_tpu_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/NLP/data/ensemble_predictions_val_tpu_CORRECT.txt'\n",
        "\n",
        "predict_and_evaluate_ensemble(DATASET_PATH=DATASET_PATH, \n",
        "                              BEST_WEIGHTS_PATH=[BEST_WEIGHTS_PATH_DISTILBERT, BEST_WEIGHTS_PATH_BERT], \n",
        "                              PATH_TO_PREDICTIONS_JSON=PATH_TO_PREDICTIONS_JSON)\n",
        "!python /content/eval/evaluate.py $DATASET_PATH $PATH_TO_PREDICTIONS_JSON"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVzU9-FrS-up"
      },
      "source": [
        "#### Test set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tN29t54YS-up"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = \"/content/drive/MyDrive/NLP/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH_BERT= \"/content/drive/MyDrive/NLP/weights/training_BERT_tpu_last.h5\"\n",
        "BEST_WEIGHTS_PATH_DISTILBERT = \"/content/drive/MyDrive/NLP/weights/training_normal_tpu_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/NLP/data/ensemble_predictions_test_tpu_CORRECT.txt'\n",
        "\n",
        "predict_and_evaluate_ensemble(DATASET_PATH=DATASET_PATH, \n",
        "                              BEST_WEIGHTS_PATH=[BEST_WEIGHTS_PATH_DISTILBERT, BEST_WEIGHTS_PATH_BERT], \n",
        "                              PATH_TO_PREDICTIONS_JSON=PATH_TO_PREDICTIONS_JSON)\n",
        "!python /content/eval/evaluate.py $DATASET_PATH $PATH_TO_PREDICTIONS_JSON"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgn_zB2PeAB_"
      },
      "source": [
        "### NER model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FYdupE5ejpe"
      },
      "source": [
        "#### NER weight offset = 0.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G25k_J80d7Cy"
      },
      "source": [
        "##### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1limPz-Kd7C6",
        "outputId": "e2c661d5-7e0d-48a5-b1b3-2692276a463f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  22535\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_transform', 'vocab_layer_norm', 'activation_13', 'vocab_projector']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 353/353 [30:21<00:00,  5.16s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 40.29731528733082,\n",
            "  \"f1\": 61.10515720895817,\n",
            "  \"total\": 22535,\n",
            "  \"HasAns_exact\": 40.29731528733082,\n",
            "  \"HasAns_f1\": 61.10515720895817,\n",
            "  \"HasAns_total\": 22535\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/validation_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/NER_100_tpu_h5_cval/hyperparameter_0,2/training_NER_02_tpu_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/NER_02_predictions_val.txt'\n",
        "NER_VALUE = 0.2\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, use_NER_attention=True, NER_value=NER_VALUE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCqlIhmSd7C6"
      },
      "source": [
        "##### Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEV6GLQKd7C7",
        "outputId": "f93cff8d-ecb4-4e1a-e720-d6f57064c21b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  10570\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_transform', 'vocab_layer_norm', 'activation_13', 'vocab_projector']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 166/166 [13:53<00:00,  5.02s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 51.36234626300851,\n",
            "  \"f1\": 68.03648925049636,\n",
            "  \"total\": 10570,\n",
            "  \"HasAns_exact\": 51.36234626300851,\n",
            "  \"HasAns_f1\": 68.03648925049636,\n",
            "  \"HasAns_total\": 10570\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/NER_100_tpu_h5_cval/hyperparameter_0,2/training_NER_02_tpu_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/NER_02_predictions_test.txt'\n",
        "NER_VALUE = 0.2\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, use_NER_attention=True, NER_value=NER_VALUE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx_5kiCWyleq"
      },
      "source": [
        "#### NER weight offset = 0.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xn3kUTl0yle0"
      },
      "source": [
        "##### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrISe7URyle0",
        "outputId": "8c332092-6edd-4a34-f734-951f771408d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  22535\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_transform', 'vocab_layer_norm', 'activation_13', 'vocab_projector']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 353/353 [30:21<00:00,  5.16s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 40.35944086975815,\n",
            "  \"f1\": 61.296511079528514,\n",
            "  \"total\": 22535,\n",
            "  \"HasAns_exact\": 40.35944086975815,\n",
            "  \"HasAns_f1\": 61.296511079528514,\n",
            "  \"HasAns_total\": 22535\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/validation_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/NER_100_tpu_h5_cval/hyperparameter_0.4/training_NER_04_tpu_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/NER_04_predictions_val.txt'\n",
        "NER_VALUE = 0.4\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, use_NER_attention=True, NER_value=NER_VALUE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_P2BWwoByle1"
      },
      "source": [
        "##### Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeiPTdlnyle1",
        "outputId": "e32a5267-3623-4b46-97be-6469b0cbd108"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  10570\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_transform', 'vocab_layer_norm', 'activation_13', 'vocab_projector']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 166/166 [14:21<00:00,  5.19s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 51.863765373699145,\n",
            "  \"f1\": 68.43574692147928,\n",
            "  \"total\": 10570,\n",
            "  \"HasAns_exact\": 51.863765373699145,\n",
            "  \"HasAns_f1\": 68.43574692147928,\n",
            "  \"HasAns_total\": 10570\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/NER_100_tpu_h5_cval/hyperparameter_0.4/training_NER_04_tpu_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/NER_04_predictions_test.txt'\n",
        "NER_VALUE = 0.4\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, use_NER_attention=True, NER_value=NER_VALUE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LamJUSbV3eS"
      },
      "source": [
        "#### NER weight offset = 0.6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n49I8u_0V3ee"
      },
      "source": [
        "##### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330,
          "referenced_widgets": [
            "2e535c91d80a43578bbb831dab804059",
            "13e2fa4f8a6e4d90a4e6e0114921073d",
            "2dfa36dbd85f469fa474c2fd30b15f54",
            "1844736d7ebb4f719cad5056eb10cb76",
            "ca5d6e40a21f4067a0acc9eaf6545955",
            "fb08161720de491b8b5be799d32f921a",
            "f8f1a60cca254c3d8e2251ed7449830c",
            "656a38b4e0ba4d2e9e8ae32dd17c6205",
            "d176af6bc2bc4dd7bd9b9f706261478c",
            "1ab29e8c869f47d883473a8dfb538f1c",
            "249915abc198448e9676c8b2a5040642"
          ]
        },
        "id": "cqKRAdjvV3ee",
        "outputId": "62398957-8d00-45ff-da84-b3cc880f4eb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  22535\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e535c91d80a43578bbb831dab804059",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/347M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_projector', 'activation_13', 'vocab_transform', 'vocab_layer_norm']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 353/353 [24:21<00:00,  4.14s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 40.32837807854449,\n",
            "  \"f1\": 61.11215226289375,\n",
            "  \"total\": 22535,\n",
            "  \"HasAns_exact\": 40.32837807854449,\n",
            "  \"HasAns_f1\": 61.11215226289375,\n",
            "  \"HasAns_total\": 22535\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/validation_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/NER_100_tpu_h5_cval/hyperparameter_0,6/training_NER_06_tpu_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/NER_06_predictions_val.txt'\n",
        "NER_VALUE = 0.6\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, use_NER_attention=True, NER_value=NER_VALUE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtCPZXdWV3ef"
      },
      "source": [
        "##### Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DINvLkyYV3ef",
        "outputId": "08be2a95-916e-4686-9318-b96c3da0cb6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples:  10570\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_projector', 'activation_13', 'vocab_transform', 'vocab_layer_norm']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 166/166 [11:21<00:00,  4.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"exact\": 51.57048249763481,\n",
            "  \"f1\": 68.12658908682066,\n",
            "  \"total\": 10570,\n",
            "  \"HasAns_exact\": 51.57048249763481,\n",
            "  \"HasAns_f1\": 68.12658908682066,\n",
            "  \"HasAns_total\": 10570\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/NER_100_tpu_h5_cval/hyperparameter_0,6/training_NER_06_tpu_last.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/NER_06_predictions_test.txt'\n",
        "NER_VALUE = 0.6\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON, use_NER_attention=True, NER_value=NER_VALUE)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "NLP_Project_evaluation_tests.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "13e2fa4f8a6e4d90a4e6e0114921073d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1844736d7ebb4f719cad5056eb10cb76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d176af6bc2bc4dd7bd9b9f706261478c",
            "max": 363423424,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_656a38b4e0ba4d2e9e8ae32dd17c6205",
            "value": 363423424
          }
        },
        "1ab29e8c869f47d883473a8dfb538f1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "249915abc198448e9676c8b2a5040642": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2dfa36dbd85f469fa474c2fd30b15f54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8f1a60cca254c3d8e2251ed7449830c",
            "placeholder": "​",
            "style": "IPY_MODEL_fb08161720de491b8b5be799d32f921a",
            "value": "Downloading: 100%"
          }
        },
        "2e535c91d80a43578bbb831dab804059": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2dfa36dbd85f469fa474c2fd30b15f54",
              "IPY_MODEL_1844736d7ebb4f719cad5056eb10cb76",
              "IPY_MODEL_ca5d6e40a21f4067a0acc9eaf6545955"
            ],
            "layout": "IPY_MODEL_13e2fa4f8a6e4d90a4e6e0114921073d"
          }
        },
        "656a38b4e0ba4d2e9e8ae32dd17c6205": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca5d6e40a21f4067a0acc9eaf6545955": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_249915abc198448e9676c8b2a5040642",
            "placeholder": "​",
            "style": "IPY_MODEL_1ab29e8c869f47d883473a8dfb538f1c",
            "value": " 347M/347M [00:11&lt;00:00, 31.8MB/s]"
          }
        },
        "d176af6bc2bc4dd7bd9b9f706261478c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8f1a60cca254c3d8e2251ed7449830c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb08161720de491b8b5be799d32f921a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbe95263736c48ab811ef90d7d61ce30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4be0372521104282b5fda52bf1ceb49d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b6c94940f57a442e90abfe9f8e6292cc",
              "IPY_MODEL_ab8d6d3b3fd140edbc4dd5f83c8ee9f1",
              "IPY_MODEL_c6f1fc380f874d799ffadb46e8050e3f"
            ]
          }
        },
        "4be0372521104282b5fda52bf1ceb49d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b6c94940f57a442e90abfe9f8e6292cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2f2ca07077ae48c88fe78a4820c26830",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3ed74c9abaf94b92a4fbbf45c34d9e9b"
          }
        },
        "ab8d6d3b3fd140edbc4dd5f83c8ee9f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cc6b5a57d3734cc49805435831c6de56",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 363423424,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 363423424,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a6e3055734e5491d920a8c06a3441994"
          }
        },
        "c6f1fc380f874d799ffadb46e8050e3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a340c0abc3d34160a4fe772e5394da97",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 347M/347M [00:10&lt;00:00, 37.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_724737c274f144f9b0eb323e1f6edf74"
          }
        },
        "2f2ca07077ae48c88fe78a4820c26830": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3ed74c9abaf94b92a4fbbf45c34d9e9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cc6b5a57d3734cc49805435831c6de56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a6e3055734e5491d920a8c06a3441994": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a340c0abc3d34160a4fe772e5394da97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "724737c274f144f9b0eb323e1f6edf74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df676c6d310040dba4af7270d42746fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c12fbfe2b3fd4539a5fb36e40b14b43d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d2a34da384a24e20bdd35adfde0af042",
              "IPY_MODEL_0744a3ae81864889af7aa8d0872e553b",
              "IPY_MODEL_01d1971e1646477aa2dc2b1ece0983dd"
            ]
          }
        },
        "c12fbfe2b3fd4539a5fb36e40b14b43d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d2a34da384a24e20bdd35adfde0af042": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3b9bb77fb6ad4e5a98b8b12f97c72dc1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_820d026616e94bf0a82357b230454117"
          }
        },
        "0744a3ae81864889af7aa8d0872e553b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f22668f2e0f94803ac864be8b3afb817",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 536063208,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 536063208,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c3867e508f4417b839d282d089d11ce"
          }
        },
        "01d1971e1646477aa2dc2b1ece0983dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ca87a65403e74c5287322229bd88f79a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 511M/511M [00:15&lt;00:00, 33.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_db6e45ccc1c94f69b0db9494553327fa"
          }
        },
        "3b9bb77fb6ad4e5a98b8b12f97c72dc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "820d026616e94bf0a82357b230454117": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f22668f2e0f94803ac864be8b3afb817": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c3867e508f4417b839d282d089d11ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca87a65403e74c5287322229bd88f79a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "db6e45ccc1c94f69b0db9494553327fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}