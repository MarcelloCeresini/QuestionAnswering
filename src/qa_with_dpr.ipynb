{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pOJx6TXNCKAr",
        "outputId": "2a36622a-706e-400f-c5e2-7c3fa2bad884",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.21.1-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 33.9 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 59.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 11.9 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 56.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.21.1\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libomp5\n",
            "Suggested packages:\n",
            "  libomp-doc\n",
            "The following NEW packages will be installed:\n",
            "  libomp-dev libomp5\n",
            "0 upgraded, 2 newly installed, 0 to remove and 19 not upgraded.\n",
            "Need to get 239 kB of archives.\n",
            "After this operation, 804 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp-dev amd64 5.0.1-1 [5,088 B]\n",
            "Fetched 239 kB in 2s (128 kB/s)\n",
            "Selecting previously unselected package libomp5:amd64.\n",
            "(Reading database ... 155680 files and directories currently installed.)\n",
            "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp5:amd64 (5.0.1-1) ...\n",
            "Selecting previously unselected package libomp-dev.\n",
            "Preparing to unpack .../libomp-dev_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp-dev (5.0.1-1) ...\n",
            "Setting up libomp5:amd64 (5.0.1-1) ...\n",
            "Setting up libomp-dev (5.0.1-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.5) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting faiss\n",
            "  Downloading faiss-1.5.3-cp37-cp37m-manylinux1_x86_64.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 21.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from faiss) (1.21.6)\n",
            "Installing collected packages: faiss\n",
            "Successfully installed faiss-1.5.3\n",
            "Cloning into 'QuestionAnswering'...\n",
            "warning: redirecting to https://github.com/MarcelloCeresini/QuestionAnswering.git/\n",
            "remote: Enumerating objects: 1023, done.\u001b[K\n",
            "remote: Counting objects: 100% (193/193), done.\u001b[K\n",
            "remote: Compressing objects: 100% (144/144), done.\u001b[K\n",
            "remote: Total 1023 (delta 127), reused 71 (delta 47), pack-reused 830\u001b[K\n",
            "Receiving objects: 100% (1023/1023), 52.11 MiB | 17.62 MiB/s, done.\n",
            "Resolving deltas: 100% (624/624), done.\n",
            "/content/QuestionAnswering/src\n",
            "env: GOOGLE_APPLICATION_CREDENTIALS=/content/drive/MyDrive/Uni/Magistrale/NLP/Project/nlp-project-338723-0510aa0a4912.json\n"
          ]
        }
      ],
      "source": [
        "username = 'MarcelloCeresini'\n",
        "repository = 'QuestionAnswering'\n",
        "\n",
        "# COLAB ONLY CELLS\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    !pip3 install transformers\n",
        "    !apt install libomp-dev\n",
        "    !pip3 install faiss\n",
        "    !git clone https://www.github.com/{username}/{repository}.git\n",
        "    #from google.colab import drive\n",
        "    #drive.mount('/content/drive/')\n",
        "    %cd /content/QuestionAnswering/src\n",
        "    using_TPU = True    # If we are running this notebook on Colab, use a TPU\n",
        "    # Google cloud credentials\n",
        "    %env GOOGLE_APPLICATION_CREDENTIALS=/content/drive/MyDrive/Uni/Magistrale/NLP/Project/nlp-project-338723-0510aa0a4912.json\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    using_TPU = False   # If you're not on Colab you probably won't have access to a TPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pm45AN-fDEiv"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "wvk3m-FdCKA0",
        "outputId": "8afc7c1b-56f5-4e43-e654-1c37e79b1eaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from functools import partial\n",
        "tqdm = partial(tqdm, position=0, leave=True)\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from typing import List, Union, Dict, Tuple\n",
        "from transformers import BertTokenizerFast, DistilBertTokenizerFast, \\\n",
        "                         TFBertModel, TFDistilBertModel\n",
        "import datetime\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import utils\n",
        "import faiss\n",
        "from collections import deque\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "MAX_SEQ_LEN = 512\n",
        "BERT_DIMENSIONALITY = 768\n",
        "BATCH_SIZE = 8 if not using_TPU else 128\n",
        "\n",
        "np.random.seed(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)\n",
        "\n",
        "ROOT_PATH = os.path.dirname(os.getcwd())\n",
        "TRAINING_FILE = os.path.join(ROOT_PATH, 'data', 'training_set.json')\n",
        "VALIDATION_FILE = os.path.join(ROOT_PATH, 'data', 'validation_set.json')\n",
        "TEST_FILE = os.path.join(ROOT_PATH, 'data', 'dev_set.json')\n",
        "\n",
        "if using_TPU:\n",
        "    try: \n",
        "        resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "        tf.config.experimental_connect_to_cluster(resolver)\n",
        "        # This is the TPU initialization code that has to be at the beginning.\n",
        "        tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "        print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "        strategy = tf.distribute.TPUStrategy(resolver)\n",
        "    except:\n",
        "        print(\"TPUs are not available, setting flag 'using_TPU' to False.\")\n",
        "        using_TPU = False\n",
        "        print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "else:\n",
        "    print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ox3qwrcACKA4"
      },
      "source": [
        "# Question Answering with the DPR\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DtqzKMW6scF"
      },
      "source": [
        "We have trained the two Bert (`bert_p`, the paragraphs encoder and `bert_q`, the questions encoder) models to produce embeddings that are as similar as possible for matching question-paragraph pairs. \n",
        "\n",
        "Thanks to our training, when we use `bert_q` to encode our question, we will now be sure that questions and paragraphs will both be encoded in the same space and have a with the matching paragraph's encoding.\n",
        "\n",
        "We can now use `bert_p` to encode all of our paragraphs a-priori using the same method we have used before (taking the 768-d encoding at the `[CLS]` token). \n",
        "\n",
        "Then, we can define our final Question Answering model in this way:\n",
        "- It receives only a question's embedding as input.\n",
        "- It uses `bert_q` to create a representation of the question in the learnt 768-d space, that is in common with the paragraph representations.\n",
        "- We compute similarity scores between the representation of the question and all representations of paragraphs. Based on these scores, we select the top-k ($k=100$) paragraphs.\n",
        "- For each of the $k$ paragraphs, we must compute the probability of the paragraph being selected $P_{selected}(i)$, as well as the usual $P_{start, i}(s), P_{end, i}(t)$ for each of the $s$-th and $t$-th words of the $i$-th paragraph. To do that, we need the full encoding of the paragraph (the $512 \\times 768$ output of Bert), which will be denoted as $P_i$ in contrast to $\\hat{P}_i$ which is the 768-d encoding at the `[CLS]` token. We obtain the full encoding by passing the $k$ paragraphs through `bert_p`, which is set to non-trainable (otherwise the encoding of the `[CLS]` token would constantly change). \n",
        "- All probabilities are computed through dense layers:\n",
        "\\begin{gather}\n",
        "P_{start,i}(s) = softmax(P_i w_{start})_s\n",
        "\\\\\n",
        "P_{end,i}(t) = softmax(P_i w_{end})_t\n",
        "\\\\\n",
        "P_{selected}(i) = softmax(\\hat{P}_i^\\intercal w_{selected})_i\n",
        "\\\\\n",
        "\\end{gather}\n",
        "where $w_{start}$, $w_{end}$ and $w_{selected}$ are learnt vectors, while $\\hat{P}_i = [P_{1}^{[CLS]}, \\dots, P_k^{[CLS]}]$.\n",
        "- As final answer, we select the highest scoring start-end legal span from the highest-scoring paragraph.\n",
        "\n",
        "During training: For each question, we create a batch by sampling $m$ ($m=24$ in the paper) from the top-100 passages returned by the retrieval system (DPR, so by computing similarities with the pre-computed representations). The training objective is to maximize the marginal log-likelihood of all the correct answer spans in the positive passage (the answer string may appear multiple times in one passage), combined with the log-likelihood of the positive passage being selected. In the paper, a batch size of 16 was used.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-z63i9X7CKA7"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GU11Vd7CKA8"
      },
      "source": [
        "## Dataset Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXvBSQypCKA9"
      },
      "source": [
        "We load all data that was prepared into the `dense_passage_retriever` notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7cp4MBwvCKA-",
        "outputId": "643f119a-2203-4bd8-837d-0389e3e8ba5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive/')\n",
        "    checkpoint_dir = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/training_dpr/'\n",
        "    datasets_dir = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/datasets/dpr/'\n",
        "else:\n",
        "    # Create the folder where we'll save the weights of the model\n",
        "    checkpoint_dir = os.path.join(\"checkpoints\", \"training_dpr\")\n",
        "    datasets_dir = os.path.join(\"checkpoints\", \"training_dpr\", \"dataset\")\n",
        "\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "os.makedirs(datasets_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NNvPry74CKBB"
      },
      "outputs": [],
      "source": [
        "train_paragraphs_and_questions = utils.read_question_set(TRAINING_FILE)['data']\n",
        "val_paragraphs_and_questions = utils.read_question_set(VALIDATION_FILE)['data']\n",
        "test_paragraphs_and_questions = utils.read_question_set(TEST_FILE)['data']\n",
        "\n",
        "# Remove the validation set from the train set\n",
        "train_paragraphs_and_questions = [article for article in train_paragraphs_and_questions \\\n",
        "                                  if article not in val_paragraphs_and_questions]\n",
        "\n",
        "def get_questions_and_paragraphs(dataset):\n",
        "    questions = [{\n",
        "            'qas': qas,\n",
        "            'context_id': (i,j)    # We also track the question's original context and paragraph indices so to have a ground truth\n",
        "        }\n",
        "        for i in range(len(dataset))\n",
        "        for j, para in enumerate(dataset[i]['paragraphs'])\n",
        "        for qas in para['qas']\n",
        "    ]\n",
        "\n",
        "    paragraphs = [{\n",
        "            'context': para['context'],\n",
        "            'context_id': i\n",
        "        }\n",
        "        for i in range(len(dataset))\n",
        "        for para in dataset[i]['paragraphs']\n",
        "    ]\n",
        "\n",
        "    return questions, paragraphs\n",
        "\n",
        "train_questions, train_paragraphs = get_questions_and_paragraphs(train_paragraphs_and_questions)\n",
        "val_questions, val_paragraphs = get_questions_and_paragraphs(val_paragraphs_and_questions)\n",
        "test_questions, test_paragraphs = get_questions_and_paragraphs(test_paragraphs_and_questions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VA_XJ_1FCKBC",
        "outputId": "2d9d5260-1e46-4af0-fe45-2c99037d0c3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading train_768 dataset from GCS (gs://volpepe-nlp-project-squad-datasets/train_768.proto).\n",
            "Loading val_768 dataset from GCS (gs://volpepe-nlp-project-squad-datasets/val_768.proto).\n"
          ]
        }
      ],
      "source": [
        "def decode_fn(record_bytes):\n",
        "    # Reads one element from the dataset (as bytes) and decodes it in a tf.data Dataset element.\n",
        "    example = tf.io.parse_single_example(\n",
        "      # Data\n",
        "      record_bytes,\n",
        "      # Schema\n",
        "      {\"question__input_ids\": tf.io.FixedLenFeature(shape=(MAX_SEQ_LEN,), dtype=tf.int64),\n",
        "       \"question__attention_mask\": tf.io.FixedLenFeature(shape=(MAX_SEQ_LEN,), dtype=tf.int64),\n",
        "       \"question__index\": tf.io.FixedLenFeature(shape=(), dtype=tf.int64),\n",
        "       \"answer__out_s\": tf.io.FixedLenFeature(shape=(MAX_SEQ_LEN,), dtype=tf.int64),\n",
        "       \"answer__out_e\": tf.io.FixedLenFeature(shape=(MAX_SEQ_LEN,), dtype=tf.int64),\n",
        "       \"paragraph__input_ids\": tf.io.FixedLenFeature(shape=(MAX_SEQ_LEN,), dtype=tf.int64),\n",
        "       \"paragraph__attention_mask\": tf.io.FixedLenFeature(shape=(MAX_SEQ_LEN,), dtype=tf.int64),\n",
        "       \"hard_paragraph__input_ids\": tf.io.FixedLenFeature(shape=(MAX_SEQ_LEN,), dtype=tf.int64),\n",
        "       \"hard_paragraph__attention_mask\": tf.io.FixedLenFeature(shape=(MAX_SEQ_LEN,), dtype=tf.int64),\n",
        "       \"paragraph__tokens_s\": tf.io.FixedLenFeature(shape=(MAX_SEQ_LEN,), dtype=tf.int64),\n",
        "       \"paragraph__tokens_e\": tf.io.FixedLenFeature(shape=(MAX_SEQ_LEN,), dtype=tf.int64),\n",
        "       \"context__index\": tf.io.FixedLenFeature(shape=(), dtype=tf.int64),\n",
        "       \"paragraph__index\": tf.io.FixedLenFeature(shape=(), dtype=tf.int64)})\n",
        "    return {\n",
        "      \"questions\": {'input_ids': example['question__input_ids'],\n",
        "                    'attention_mask': example['question__attention_mask'],\n",
        "                    'index': example['question__index']},\n",
        "      \"answers\":   {'out_s': example['answer__out_s'],\n",
        "                    'out_e': example['answer__out_e']},\n",
        "      \"paragraphs\":{'input_ids': example['paragraph__input_ids'],\n",
        "                    'attention_mask': example['paragraph__attention_mask'],\n",
        "                    'tokens_s': example['paragraph__tokens_s'],\n",
        "                    'tokens_e': example['paragraph__tokens_e']},\n",
        "      \"hard_paragraphs\": {'input_ids': example['hard_paragraph__input_ids'],\n",
        "                          'attention_mask': example['hard_paragraph__attention_mask']},\n",
        "      \"context_ids\": (example['context__index'], example['paragraph__index'])\n",
        "    }\n",
        "\n",
        "def load_tf_dataset_from_cloud(questions, fn, batch_size=BATCH_SIZE):\n",
        "    # Prepare strings\n",
        "    filename = f'{fn}_{BERT_DIMENSIONALITY}.proto'\n",
        "    fn_type = filename.split(os.sep)[-1].replace('.proto','')\n",
        "    dst_name = fn_type + '.proto'\n",
        "    bucket_name = 'volpepe-nlp-project-squad-datasets'\n",
        "    gcs_filename = f'gs://{bucket_name}/{dst_name}'\n",
        "    print(f\"Loading {fn_type} dataset from GCS ({gcs_filename}).\")\n",
        "    # Return it as processed dataset\n",
        "    dataset = tf.data.TFRecordDataset([gcs_filename]).map(decode_fn)\n",
        "    dataset = dataset.apply(tf.data.experimental.assert_cardinality(len(questions)))\n",
        "    dataset = dataset.shuffle(5000, reshuffle_each_iteration=True)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.cache()\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "dataset_train = load_tf_dataset_from_cloud(train_questions, os.path.join(datasets_dir, 'train'))\n",
        "dataset_val = load_tf_dataset_from_cloud(val_questions, os.path.join(datasets_dir, 'val'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_pSG2Y5CKBE"
      },
      "source": [
        "## Model loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "498HGSpRCKBF",
        "outputId": "79c59933-43cc-4336-806a-b81c4d6fa8d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "499774584a42420fa6c90c0272352269",
            "8d16d761751c474f90265b2abb657356",
            "564263977cc549548340b16564b07f24",
            "716b067107b3430b958a552c9e841585",
            "f53b30f62ff34d7a9fd8cd308fe3feac",
            "cdd1599a67c6449db4b135aefffc666d",
            "718d4125937e43d8816c157964e141eb",
            "f4b053ec158f40749985bf3a12f44fe0",
            "740166cceef04af7bc13633e248c258b",
            "ae1425950d974937aef7c5d5fba5dd92",
            "85573b898be3491da10466c1a5221215",
            "3dfda2c30d3146b4a5e375799752bf91",
            "8fafebcff95e4ff2abf17b967a93ca57",
            "077a6b40d911430682f8054c04ecb277",
            "4b0e7db773534e228e638961982fef18",
            "decbe4d74d2346229536dfed40e7fca8",
            "5c62d9ff39f847fe8ed3e1809295be05",
            "2c7fcc1bab67468289ef83236d87d0a9",
            "217af8f08170470a92770fb6bad3e3b3",
            "5167ef976c3a4c1fb087e6b2adc6f49f",
            "d08b5b2168554fdbb008101acf3bd382",
            "812e1b35867a4336adea94b012639889",
            "9d406963504e4b7b8f28647ef48d5079",
            "a73d0f56bf4b4c4b8d6b241852a405c0",
            "773b328fabb04948887ed8ec46d4f30d",
            "cab759daebdf4dcab33276ab0d6e7362",
            "47727ca7448e4afa8e0df786f681e135",
            "60e23af1fd724237a939eed260c80700",
            "5ad7951170e44318885698fc49461f77",
            "8e340216a8af45f48e145eea1601117d",
            "d444dabeeb5547d1b8a04ec19cadaef8",
            "5199194388d94209a38714b927472cf9",
            "cd5a98e3b2824afe90dcb18bab98e4b5",
            "c61a401378b7493b9905434f6e83ef56",
            "4733b5aaf9e2411c93aa208353901311",
            "b13306fe6d204416bc1844dce531c48c",
            "08d9864e1dbd428687b931f7e28c414e",
            "4bd4b04481a3415dacdd0dc165e4f007",
            "84dcf6e0a02640d3ae3106135c488f72",
            "f5b72206db5145b4b540c294cae16c0b",
            "089a1f3576634245b06d3b8cd036da1e",
            "585e75aac58543b48036d556fe07a7f2",
            "4ee7d442e10548208dbdee3177ea3585",
            "bf2a62f3d3a54174985903544134c43d"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "499774584a42420fa6c90c0272352269"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading vocab.txt:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3dfda2c30d3146b4a5e375799752bf91"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tokenizer.json:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d406963504e4b7b8f28647ef48d5079"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c61a401378b7493b9905434f6e83ef56"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokenizer_distilbert = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "\n",
        "class ReducedDistilBertModel(keras.Model):\n",
        "    def __init__(self, distilbert_model):\n",
        "        super(ReducedDistilBertModel, self).__init__()\n",
        "        self.distilbert_model = distilbert_model\n",
        "        self.reduction_layer = keras.layers.Dense(BERT_DIMENSIONALITY, \n",
        "                                                  activation='gelu')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        hidden_state = self.distilbert_model(inputs).last_hidden_state\n",
        "        # We introduce a dense layer that simply reduces the dimensionality of the model's output.\n",
        "        # It's not used if the output dimensionality is the same of the Bert model\n",
        "        return self.reduction_layer(hidden_state) if BERT_DIMENSIONALITY != 768 else hidden_state\n",
        "\n",
        "\n",
        "class DenseEncoder(layers.Layer):\n",
        "    def __init__(self, model_q, model_p):\n",
        "        super().__init__()\n",
        "        self.model_q = model_q  # Dense encoder for questions\n",
        "        self.model_p = model_p  # Dense encoder for paragraphs\n",
        "    \n",
        "    def call(self, inputs, training=False):\n",
        "        # Encode the questions in the batch\n",
        "        # Take the first token as representation of each question\n",
        "        q_repr = self.model_q({\n",
        "            'input_ids': inputs['questions']['input_ids'],\n",
        "            'attention_mask': inputs['questions']['attention_mask']\n",
        "        })[:,0,:]\n",
        "        # If we are training, we also return the representation of the paragraphs\n",
        "        # and of the hard paragraph\n",
        "        if training:\n",
        "            # Encode the batch of paragraphs\n",
        "            p_repr = self.model_p({\n",
        "                'input_ids': inputs['paragraphs']['input_ids'],\n",
        "                'attention_mask': inputs['paragraphs']['attention_mask']\n",
        "            })[:,0,:]\n",
        "            # We also encode the batch of hard paragraphs separately. \n",
        "            p_hard_repr = self.model_p({\n",
        "                'input_ids': inputs['hard_paragraphs']['input_ids'],\n",
        "                'attention_mask': inputs['hard_paragraphs']['attention_mask']\n",
        "            })[:,0,:]\n",
        "            return q_repr, p_repr, p_hard_repr\n",
        "        else:\n",
        "            return q_repr\n",
        "\n",
        "\n",
        "class DeepQPEncoder(keras.Model):\n",
        "    def __init__(self, model_q, model_p):\n",
        "        super().__init__()\n",
        "        self.enc = DenseEncoder(model_q, model_p)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        if training:\n",
        "            # For training we return the similarity matrix\n",
        "            repr_q, repr_p, repr_hard_p = self.enc(inputs, training=training)\n",
        "            S = tf.tensordot(repr_q, tf.transpose(repr_p), axes=1)\n",
        "            # We append the hard scores\n",
        "            hard_scores = tf.gather(\n",
        "                # Get the elements on the diagonal of the 8x8 matrix of \n",
        "                # scores between questions and hard paragraphs\n",
        "                tf.tensordot(repr_q, tf.transpose(repr_hard_p), axes=1), \n",
        "                    tf.expand_dims(\n",
        "                        tf.range(tf.shape(inputs['questions']['input_ids'])[0]), \n",
        "                        axis=1), \n",
        "                    batch_dims=1\n",
        "            )\n",
        "            S = tf.concat([S, hard_scores], axis=1)\n",
        "            return S\n",
        "        else:\n",
        "            # In other cases, we return the representation of the question(s)\n",
        "            repr_q = self.enc(inputs, training=training)            \n",
        "            return repr_q\n",
        "\n",
        "    def train_step(self, data):\n",
        "        x = data\n",
        "        # y = [0, ..., batch_size-1]\n",
        "        y = tf.range(tf.shape(x['questions']['input_ids'])[0])\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Obtain similarities\n",
        "            S = self(x, training=True)\n",
        "            # Obtain loss value\n",
        "            loss = self.compiled_loss(y, S)\n",
        "        # Construct gradients and apply them through the optimizer\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "        # Update and return metrics (specifically the one for the loss value).\n",
        "        self.compiled_metrics.update_state(y, S)\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    def test_step(self, data):\n",
        "        x = data\n",
        "        # y = [0, ..., batch_size-1]\n",
        "        y = tf.range(tf.shape(x['questions']['input_ids'])[0])\n",
        "        S = self(x, training=True) # We are not really training, but we have to obtain S\n",
        "        self.compiled_loss(y, S)\n",
        "        self.compiled_metrics.update_state(y, S)\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "\n",
        "def create_dpr(sample, freeze_layers_up_to=5):\n",
        "    print(\"Creating BERT models...\")\n",
        "    model_q, model_p =  TFDistilBertModel.from_pretrained('distilbert-base-uncased'), \\\n",
        "                        TFDistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "    # Freeze layers \n",
        "    for i in range(freeze_layers_up_to): # layers 0 to variable are frozen, successive layers learn\n",
        "        model_q.distilbert.transformer.layer[i].trainable = False\n",
        "        model_p.distilbert.transformer.layer[i].trainable = False\n",
        "\n",
        "    model_q, model_p = ReducedDistilBertModel(model_q), ReducedDistilBertModel(model_p)\n",
        "\n",
        "    print(\"Creating Deep Encoder...\")\n",
        "    model = DeepQPEncoder(model_q, model_p)\n",
        "\n",
        "    print(\"Compiling...\")\n",
        "    # Compile the model and loss\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=3e-6),\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[keras.metrics.SparseCategoricalAccuracy()]\n",
        "    )\n",
        "\n",
        "    print(\"Testing on some data...\")\n",
        "    # Pass one batch of data to build the model\n",
        "    model(sample)\n",
        "\n",
        "    # Return the model\n",
        "    print(\"Model created!\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hdPO7wQjCKBH",
        "outputId": "949746bf-ea14-4598-db75-d5d76542c157",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330,
          "referenced_widgets": [
            "b669fc1fdb2d46be8e36873af2effc8c",
            "867a387a09bb472eb76f479e14c7aee5",
            "1a21ea5c7e0b4a6d92a6493d85b7b3f6",
            "8f01a1ead72f452f8e5fb6a9c2387a21",
            "24330ad68e7d4f41851136dc97e4f5cf",
            "aef7955f08a2439d8298bea0c83decf3",
            "292939448b704499a20d074d40e6c9dc",
            "e544d4b5720b43a4a46112058242b1d1",
            "189ce92c11cf49c994f7b38250d4e791",
            "43253fcb174f4af28c6c4f6061b40043",
            "408c3c629da84625bd35f5b752e65cba"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating BERT models...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tf_model.h5:   0%|          | 0.00/347M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b669fc1fdb2d46be8e36873af2effc8c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['activation_13', 'vocab_transform', 'vocab_projector', 'vocab_layer_norm']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['activation_13', 'vocab_transform', 'vocab_projector', 'vocab_layer_norm']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating Deep Encoder...\n",
            "Compiling...\n",
            "Testing on some data...\n",
            "Model created!\n"
          ]
        }
      ],
      "source": [
        "dpr_model_name = f'dpr_{BERT_DIMENSIONALITY}_hard'\n",
        "dpr_checkpoint_path = os.path.join(checkpoint_dir, dpr_model_name + \".ckpt\")\n",
        "local_device_option = tf.train.CheckpointOptions(\n",
        "    experimental_io_device=\"/job:localhost\")\n",
        "\n",
        "if using_TPU:\n",
        "    # TPU requires to create the model within the scope of the distributed strategy\n",
        "    # we're using.\n",
        "    with strategy.scope():\n",
        "        dpr_model = create_dpr(sample=next(dataset_train.take(1).as_numpy_iterator()),\n",
        "                             freeze_layers_up_to=3)\n",
        "else:\n",
        "    # On TPU we cannot use tensorboard, but on GPU we can\n",
        "    log_dir = os.path.join(ROOT_PATH, \"data\", \"logs\", \n",
        "        f\"training_dpr_{BERT_DIMENSIONALITY}_hard\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "    \n",
        "    dpr_model = create_dpr(sample=next(dataset_train.take(1).as_numpy_iterator()),\n",
        "                             freeze_layers_up_to=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6ZeAv_0zCKBJ",
        "outputId": "629c47ac-9107-46e2-c146-f00f3ad60e15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f339a6f2dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Load the obtained weights\n",
        "dpr_model.load_weights(dpr_checkpoint_path, options=local_device_option)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPG2DHje99it"
      },
      "source": [
        "## Question Answering model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGzumB9nAVYd"
      },
      "source": [
        "We pre-tokenize the paragraphs so that we have easy access to them inside the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDK42osrAlsX",
        "outputId": "41746f76-c8b5-4e9c-9ae2-7c831d695c32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13975/13975 [00:09<00:00, 1532.56it/s]\n",
            "100%|██████████| 4921/4921 [00:03<00:00, 1517.66it/s]\n"
          ]
        }
      ],
      "source": [
        "pretokenized_paragraphs = {\n",
        "    'train': {\n",
        "        'input_ids': [],\n",
        "        'attention_mask': [],\n",
        "        'offset_mapping': []\n",
        "    },\n",
        "    'val': {\n",
        "        'input_ids': [],\n",
        "        'attention_mask': [],\n",
        "        'offset_mapping': []\n",
        "    }\n",
        "}\n",
        "\n",
        "for i in tqdm(range(len(train_paragraphs))):\n",
        "    token_p = dict(tokenizer_distilbert(\n",
        "        train_paragraphs[i]['context'], max_length = MAX_SEQ_LEN, \n",
        "        return_tensors='tf', truncation = True, \n",
        "        padding = 'max_length', return_offsets_mapping = True\n",
        "    ))\n",
        "    pretokenized_paragraphs['train']['input_ids'].append(token_p['input_ids'])\n",
        "    pretokenized_paragraphs['train']['attention_mask'].append(token_p['attention_mask'])\n",
        "    pretokenized_paragraphs['train']['offset_mapping'].append(token_p['offset_mapping'])\n",
        "\n",
        "for i in tqdm(range(len(val_paragraphs))):\n",
        "    token_p = dict(tokenizer_distilbert(\n",
        "        train_paragraphs[i]['context'], max_length = MAX_SEQ_LEN, \n",
        "        return_tensors='tf', truncation = True, \n",
        "        padding = 'max_length', return_offsets_mapping = True\n",
        "    ))\n",
        "    pretokenized_paragraphs['val']['input_ids'].append(token_p['input_ids'])\n",
        "    pretokenized_paragraphs['val']['attention_mask'].append(token_p['attention_mask'])\n",
        "    pretokenized_paragraphs['val']['offset_mapping'].append(token_p['offset_mapping'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOcyq9GtN7i-"
      },
      "source": [
        "Then, we define a function to create the model. The model should accept the top paragraphs encodings collected using the DPR and return their start, end and selection probabilities.\n",
        "\n",
        "Note that at training time, this is the only part that learns. We assume that the rest is fixed. We use FAISS to index the best paragraph for each encoded question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "R_v3r3DcBeKz"
      },
      "outputs": [],
      "source": [
        "class BestScoringCollector(keras.layers.Layer):\n",
        "    '''\n",
        "    Custom layer to collect the start and end probabilities from the best scoring\n",
        "    paragraph\n",
        "    '''\n",
        "    def __init__(self, **kwargs):\n",
        "        super(BestScoringCollector, self).__init__(trainable=False, **kwargs)\n",
        "\n",
        "    def call(self, probs_s, probs_e, probs_sel):\n",
        "        # Selection of best scoring paragraphs\n",
        "        best_scoring_paragraphs = tf.squeeze(tf.argmax(probs_sel, axis=1, output_type=tf.int32))\n",
        "        # Selection of related start-end probabilities\n",
        "        probs_s = tf.squeeze(tf.gather(probs_s, indices=tf.expand_dims(best_scoring_paragraphs, -1), batch_dims=1))\n",
        "        probs_e = tf.squeeze(tf.gather(probs_e, indices=tf.expand_dims(best_scoring_paragraphs, -1), batch_dims=1))\n",
        "        return probs_s, probs_e\n",
        "\n",
        "def create_QA_model(m):\n",
        "    # Receives in input the top paragraph full and search encodings collected using the DPR.\n",
        "    paragraphs_full_encodings = keras.Input(shape=(m, MAX_SEQ_LEN, BERT_DIMENSIONALITY), \n",
        "        dtype='float32', name=\"topm_full_encodings\")\n",
        "    paragraphs_search_encodings = keras.Input(shape=(m, BERT_DIMENSIONALITY), \n",
        "        dtype='float32', name=\"topm_search_encodings\")\n",
        "\n",
        "    # Compute probabilities for the start token\n",
        "    out_S = keras.layers.TimeDistributed(keras.layers.Dense(1), name=\"start_token_logits\")(paragraphs_full_encodings)\n",
        "    out_S = keras.layers.Reshape((m, MAX_SEQ_LEN))(out_S)\n",
        "    out_S = keras.layers.Softmax(name=\"start_probs\", axis=1, dtype='float32')(out_S)\n",
        "\n",
        "    # The same is done for the end tokens.\n",
        "    out_E = keras.layers.TimeDistributed(keras.layers.Dense(1), name=\"end_token_logits\")(paragraphs_full_encodings)\n",
        "    out_E = keras.layers.Reshape((m, MAX_SEQ_LEN))(out_E)\n",
        "    out_E = keras.layers.Softmax(name=\"end_probs\", axis=1, dtype='float32')(out_E)\n",
        "\n",
        "    # Also, we compute paragraph selection probabilities\n",
        "    out_SEL = keras.layers.Dense(1, name=\"selection_logits\")(paragraphs_search_encodings)\n",
        "    out_SEL = keras.layers.Flatten('channels_first')(out_SEL)\n",
        "    out_SEL = keras.layers.Softmax(name=\"selection_probs\", dtype='float32')(out_SEL)\n",
        "\n",
        "    out_S, out_E = BestScoringCollector(name='best_scoring_collector')(out_S, out_E, out_SEL)\n",
        "\n",
        "    # We return the keras model\n",
        "    model = keras.Model(\n",
        "        inputs = [paragraphs_full_encodings, paragraphs_search_encodings],\n",
        "        outputs = [out_S, out_E, out_SEL]\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR-Jr45AObut"
      },
      "source": [
        "We analyze the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Cvu8NLQGtSbJ"
      },
      "outputs": [],
      "source": [
        "M = 24              # Number of paragraphs to be collected by the DPR (24 in the paper)\n",
        "\n",
        "model_qa = create_QA_model(M)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkdbnPt_v-G8",
        "outputId": "f5bd6bff-b054-441e-c624-4cff28e0161a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " topm_full_encodings (InputLaye  [(None, 24, 512, 76  0          []                               \n",
            " r)                             8)]                                                               \n",
            "                                                                                                  \n",
            " topm_search_encodings (InputLa  [(None, 24, 768)]   0           []                               \n",
            " yer)                                                                                             \n",
            "                                                                                                  \n",
            " start_token_logits (TimeDistri  (None, 24, 512, 1)  769         ['topm_full_encodings[0][0]']    \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            " end_token_logits (TimeDistribu  (None, 24, 512, 1)  769         ['topm_full_encodings[0][0]']    \n",
            " ted)                                                                                             \n",
            "                                                                                                  \n",
            " selection_logits (Dense)       (None, 24, 1)        769         ['topm_search_encodings[0][0]']  \n",
            "                                                                                                  \n",
            " reshape (Reshape)              (None, 24, 512)      0           ['start_token_logits[0][0]']     \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)            (None, 24, 512)      0           ['end_token_logits[0][0]']       \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 24)           0           ['selection_logits[0][0]']       \n",
            "                                                                                                  \n",
            " start_probs (Softmax)          (None, 24, 512)      0           ['reshape[0][0]']                \n",
            "                                                                                                  \n",
            " end_probs (Softmax)            (None, 24, 512)      0           ['reshape_1[0][0]']              \n",
            "                                                                                                  \n",
            " selection_probs (Softmax)      (None, 24)           0           ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " best_scoring_collector (BestSc  (None, None)        0           ['start_probs[0][0]',            \n",
            " oringCollector)                                                  'end_probs[0][0]',              \n",
            "                                                                  'selection_probs[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,307\n",
            "Trainable params: 2,307\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_qa.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1Etf4vYO5OB"
      },
      "source": [
        "The outputs are of the expected shape. We also use an utility to see the model visually."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "q8KH_VJSL8VN",
        "outputId": "cfa73bae-b9d7-490c-c0f9-c9e085e235e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "keras.utils.plot_model(model_qa, \"multi_input_and_output_model.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrzBIEVvR0Dg"
      },
      "source": [
        "### Model input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMS0DrokCKBU"
      },
      "source": [
        "The input to the model are pre-encoded paragraph encodings. The encoding happens with the pre-trained `model_q` that we previously trained in the `dense_passage_retriever` notebook. We don't use a neural model anymore to retrieve the best scoring paragraphs: instead we have created a \"pre-trained\" FAISS index on the encodings of `model_p` for all paragraphs. In this way we can efficiently collect the best paragraphs given one or a sequence of queries (`model_q` encodings)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "10u4Fq6ZCKBU"
      },
      "outputs": [],
      "source": [
        "train_index = faiss.read_index(os.path.join(datasets_dir, 'indices', 'train_index'))\n",
        "val_index   = faiss.read_index(os.path.join(datasets_dir, 'indices', 'val_index'))\n",
        "test_index  = faiss.read_index(os.path.join(datasets_dir, 'indices', 'test_index'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgKwMq0yCKBV"
      },
      "source": [
        "We try out our method. First of all we build a function to map `context_ids` to paragraph indices in the matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "NXpyJTqxCKBV"
      },
      "outputs": [],
      "source": [
        "# Map context ids to ground truth paragraph indexes\n",
        "def get_paragraph_encoding_index(questions, dataset):\n",
        "    art_ids, par_ids = questions['context_ids']\n",
        "    idxs = deque([])\n",
        "    for i in range(len(art_ids)):\n",
        "        idxs.append(sum([len(dataset[j]['paragraphs']) for j in range(art_ids[i])]) + par_ids[i])\n",
        "    return idxs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we take a batch of training data and test our method on it."
      ],
      "metadata": {
        "id": "xCakbrfJUfWS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "1ysFvHIqCKBW"
      },
      "outputs": [],
      "source": [
        "input_data = next(dataset_train.take(1).as_numpy_iterator())\n",
        "qs = input_data['questions']\n",
        "qs_representations = dpr_model.enc.model_q({\n",
        "        'input_ids': qs['input_ids'], \n",
        "        'attention_mask': qs['attention_mask']\n",
        "    })[:,0,:].numpy()\n",
        "qs_representations.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Search using the index:"
      ],
      "metadata": {
        "id": "EVS0gqTbUsM_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "dAUXxy7lR0Dg",
        "outputId": "d6215d52-9829-4215-ae88-73e53499e671",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((128, 100), (128, 100))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "distances, best_indices = train_index.search(qs_representations, 100)\n",
        "distances.shape, best_indices.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wj5l9zDWCKBY"
      },
      "source": [
        "The search is quite fast! Let's see if it's also accurate..."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gt_paragraphs = get_paragraph_encoding_index(input_data, train_paragraphs_and_questions)\n",
        "list(gt_paragraphs)[:5] # Show the first 5 ground truth paragraph IDs"
      ],
      "metadata": {
        "id": "sYUpFWzqRB96",
        "outputId": "7a52ba29-b9ec-4fad-bc39-568dc6bdb37c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[178, 345, 48, 675, 423]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We check where is the ground truth paragraph in the collection of best indices returned by our index."
      ],
      "metadata": {
        "id": "gWqNlIS_VGF7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "8CltiIoQCKBZ",
        "outputId": "db93f256-216e-4611-8dac-ab34f39e63ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 48 indices, while 80 were not found.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "count_found = 0\n",
        "count_not_found = 0\n",
        "found_where = []\n",
        "for i in range(len(gt_paragraphs)):\n",
        "    index = np.where(best_indices[i] == gt_paragraphs[i])[0]\n",
        "    if len(index) > 0:\n",
        "        # Element was found in those returned by the index\n",
        "        count_found += 1\n",
        "        found_where.append(index[0])\n",
        "    else:\n",
        "        count_not_found += 1\n",
        "\n",
        "print(f\"Found {count_found} indices, while {count_not_found} were not found.\")\n",
        "plt.hist(found_where, bins=range(0,105,5));"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results for this batch are not particularly good, but the search is quite efficient."
      ],
      "metadata": {
        "id": "G4hzqrPAZhv8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0Csd2VaCKBb"
      },
      "source": [
        "# The rest of it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_O1KsF7MR0Dg"
      },
      "source": [
        "The Dense Passage retriever returns indices of paragraphs, which we can collect using this function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVuywyVKR0Dh"
      },
      "outputs": [],
      "source": [
        "def collect_paragraphs_from_dpr(pretokenized_paragraphs, paragraphs_encodings, indices):\n",
        "    # Collect paragraphs. Inputs is the batch of paragraph indexes to gather\n",
        "    paragraphs = {\n",
        "        'input_ids': tf.squeeze(tf.gather(pretokenized_paragraphs['input_ids'], indices), axis=2),\n",
        "        'attention_mask': tf.squeeze(tf.gather(pretokenized_paragraphs['attention_mask'], indices), axis=2),\n",
        "        'offset_mapping': tf.squeeze(tf.gather(pretokenized_paragraphs['offset_mapping'], indices), axis=2),\n",
        "        'indexes': indices\n",
        "    }\n",
        "    # Collect paragraph representations and their search encodings\n",
        "    paragraphs_full_encodings = np.take(paragraphs_encodings, indices, axis=0)\n",
        "    paragraphs_search_encodings = paragraphs_full_encodings[:,:,0,:]\n",
        "    return paragraphs, paragraphs_full_encodings, paragraphs_search_encodings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwtBPPqvR0Dh"
      },
      "outputs": [],
      "source": [
        "ps, full_enc, search_enc = \\\n",
        "    collect_paragraphs_from_dpr(pretokenized_paragraphs, paragraphs_encoding, top_m_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niPmBhTmR0Dh"
      },
      "source": [
        "So we can create a dataset like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ibpoyrCR0Dh",
        "outputId": "a93f610c-1416-4351-a970-f893c65dceaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pre-tokenizing data...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████████████████████████████████████████████████████████████████████| 65064/65064 [00:10<00:00, 6277.52it/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████████| 65064/65064 [00:32<00:00, 2019.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing answers...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████████████████████████████████████████| 65064/65064 [00:01<00:00, 43289.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving dataset on disk...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|                                                                           | 54/65064 [13:57<492:30:07, 27.27s/it]"
          ]
        }
      ],
      "source": [
        "def create_qa_dataset(questions, fn, model_q, paragraphs_encodings, pretokenized_paragraphs):\n",
        "    # Instantiate DPR\n",
        "    dpr = DensePassageRetriever(model_q, paragraphs_encodings)\n",
        "    # Read dataset from cloud disk\n",
        "    filename = f'{fn}_v3_{BERT_DIMENSIONALITY}.proto'\n",
        "    fn_type = filename.split(os.sep)[-1].replace('.proto','')\n",
        "    gcs_filename = f'gs://volpepe-nlp-project-squad-datasets/{fn_type}.proto'\n",
        "    \n",
        "    if OVERWRITE_DATASETS_QA:\n",
        "        print(\"Pre-tokenizing data...\")\n",
        "        tok_questions, tok_paragraphs = pre_tokenize_data(questions, full_dict, tokenizer_distilbert)\n",
        "        assert len(tok_questions) == len(tok_paragraphs), \"Error while pre-tokenizing dataset\"\n",
        "        print(\"Preprocessing answers...\")\n",
        "        answer_tokens = [find_start_end_token_one_hot_encoded(\n",
        "            questions[i]['qas']['answers'], tok_paragraphs[i]['offset_mapping'])\n",
        "        for i in tqdm(range(len(questions)))]\n",
        "        print(\"Saving dataset on disk...\")\n",
        "        with tf.io.TFRecordWriter(filename) as file_writer:\n",
        "            for i in tqdm(range(len(tok_questions))):\n",
        "                question_ids = tok_questions[i][\"input_ids\"]\n",
        "                question_attention_mask = tok_questions[i][\"attention_mask\"]\n",
        "                # Create the DPR inputs\n",
        "                dpr_inputs = {\n",
        "                    'questions': { \n",
        "                        'input_ids': np.array(question_ids),\n",
        "                        'attention_mask': np.array(question_attention_mask)\n",
        "                    }\n",
        "                }\n",
        "                # Retrieve scores and top indices by calling the DPR\n",
        "                scores, top_m_indices = dpr(dpr_inputs)\n",
        "                # Obtain the paragraphs and their encodings by calling the collect function\n",
        "                ps, full_enc, search_enc = \\\n",
        "                    collect_paragraphs_from_dpr(pretokenized_paragraphs, paragraphs_encodings, top_m_indices)\n",
        "                \n",
        "                record_bytes = tf.train.Example(features=tf.train.Features(feature={\n",
        "                    \"question__input_ids\": tf.train.Feature(int64_list=tf.train.Int64List(\n",
        "                            value=question_ids)),\n",
        "                    \"question__attention_mask\": tf.train.Feature(int64_list=tf.train.Int64List(\n",
        "                            value=question_attention_mask)),\n",
        "                    \"answer__out_s\": tf.train.Feature(int64_list=tf.train.Int64List(\n",
        "                        value=answer_tokens[i][\"out_S\"])),\n",
        "                    \"answer__out_e\": tf.train.Feature(int64_list=tf.train.Int64List(\n",
        "                        value=answer_tokens[i][\"out_E\"])),\n",
        "                    \"paragraph__index\": tf.train.Feature(int64_list=tf.train.Int64List(\n",
        "                        value=[get_paragraph_global_id_from_question(questions[i], paragraphs)])),\n",
        "                    \"paragraph__full_enc\": tf.train.Feature(bytes_list=tf.train.BytesList(\n",
        "                        value=[tf.io.serialize_tensor(np.asarray(full_enc)).numpy()])),\n",
        "                    \"paragraph__tokens_s\": tf.train.Feature(int64_list=tf.train.Int64List(\n",
        "                            value=[x[0] for x in tok_paragraphs[i][\"offset_mapping\"]])),\n",
        "                    \"paragraph__tokens_e\": tf.train.Feature(int64_list=tf.train.Int64List(\n",
        "                            value=[x[1] for x in tok_paragraphs[i][\"offset_mapping\"]])),\n",
        "                    \"dpr__top_m_indices\": tf.train.Feature(int64_list=tf.train.Int64List(\n",
        "                        value=list(tf.squeeze(top_m_indices)))),\n",
        "                    })).SerializeToString()\n",
        "                file_writer.write(record_bytes)\n",
        "        print(\"Upload the dataset on Google Cloud and re-run the function\")\n",
        "        return None\n",
        "    \n",
        "    def decode_qa_fn(record_bytes):\n",
        "        # Read example from bytes dataset\n",
        "        example = tf.io.parse_single_example(\n",
        "            # Data\n",
        "            record_bytes,\n",
        "            # Schema\n",
        "            {\"question__input_ids\": tf.io.FixedLenFeature(shape=(MAX_SEQ_LEN,), dtype=tf.int64),\n",
        "            \"question__attention_mask\": tf.io.FixedLenFeature(shape=(MAX_SEQ_LEN,), dtype=tf.int64),\n",
        "            \"answer__out_s\": tf.io.FixedLenFeature(shape=(MAX_SEQ_LEN,), dtype=tf.int64),\n",
        "            \"answer__out_e\": tf.io.FixedLenFeature(shape=(MAX_SEQ_LEN,), dtype=tf.int64),\n",
        "            \"paragraph__index\": tf.io.FixedLenFeature(shape=(), dtype=tf.int64),\n",
        "            \"paragraph__full_enc\": tf.io.FixedLenFeature([], dtype=tf.string),\n",
        "            \"paragraph__tokens_s\": tf.io.FixedLenFeature(shape=(MAX_SEQ_LEN,), dtype=tf.int64),\n",
        "            \"paragraph__tokens_e\": tf.io.FixedLenFeature(shape=(MAX_SEQ_LEN,), dtype=tf.int64),\n",
        "            \"dpr__top_100_indices\": tf.io.FixedLenFeature(shape=(100, ), dtype=tf.int64)\n",
        "           })\n",
        "        \n",
        "        # Yield the final dictionary structured however we need\n",
        "        return {\n",
        "            'questions': {\n",
        "                'input_ids': example['question__input_ids'],\n",
        "                'attention_mask': example['question__attention_mask']\n",
        "            },\n",
        "            'answers': {\n",
        "                'out_s': example['answer__out_s'],\n",
        "                'out_e': example['answer__out_e']\n",
        "            },\n",
        "            'paragraphs': {\n",
        "                'index': example['paragraph__index'],\n",
        "                'full_enc': tf.io.parse_tensor(example['paragraph__full_enc'], out_type=tf.float32),\n",
        "                'search_enc': tf.io.parse_tensor(example['paragraph__search_enc'], out_type=tf.float32),\n",
        "                'tokens_s': example['paragraph__tokens_s'],\n",
        "                'tokens_e': example['paragraph__tokens_e']\n",
        "            },\n",
        "            'dpr': {\n",
        "                'top_100_indices': example['dpr__top_100_indices']\n",
        "            }\n",
        "        }\n",
        "    \n",
        "    print(f\"Loading {fn_type} dataset from GCS ({gcs_filename}).\")\n",
        "    # Return it as processed dataset\n",
        "    dataset = tf.data.TFRecordDataset([gcs_filename]).map(decode_qa_fn)\n",
        "    dataset = dataset.cache()\n",
        "    dataset = dataset.shuffle(10000)\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "    dataset = dataset.apply(tf.data.experimental.assert_cardinality(len(questions)))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset\n",
        "\n",
        "dataset_train_qa = create_qa_dataset(train_questions, os.path.join(datasets_dir, 'train_qa'), \n",
        "                                    model.enc.model_q, paragraphs_encoding, pretokenized_paragraphs)\n",
        "dataset_val_qa = create_qa_dataset(val_questions, os.path.join(datasets_dir, 'val_qa'), \n",
        "                                  model.enc.model_q, paragraphs_encoding, pretokenized_paragraphs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suAR_76XR0Dh",
        "outputId": "806bd0a0-62aa-46fc-e791-611782a66d56"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<BatchDataset element_spec={'questions': {'input_ids': TensorSpec(shape=(None, 400), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(None, 400), dtype=tf.int64, name=None), 'index': TensorSpec(shape=(None,), dtype=tf.int64, name=None)}, 'answers': {'out_s': TensorSpec(shape=(None, 400), dtype=tf.int64, name=None), 'out_e': TensorSpec(shape=(None, 400), dtype=tf.int64, name=None)}, 'paragraphs': {'input_ids': TensorSpec(shape=(None, 400), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(None, 400), dtype=tf.int64, name=None), 'tokens_s': TensorSpec(shape=(None, 400), dtype=tf.int64, name=None), 'tokens_e': TensorSpec(shape=(None, 400), dtype=tf.int64, name=None), 'index': TensorSpec(shape=(None,), dtype=tf.int64, name=None)}}>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_train_qa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uha4NPnpR0Di"
      },
      "outputs": [],
      "source": [
        "def create_qa_datasets(, model_q, paragraphs_encodings, pretokenized_paragraphs):\n",
        "\n",
        "    def qa_dataset_generator(dataset):\n",
        "        # Instantiate DPR\n",
        "        dpr = DensePassageRetriever(model_q, paragraphs_encodings)\n",
        "        # Instantiate dataset iterator\n",
        "        dataset = dataset.as_numpy_iterator()\n",
        "        # Iterator over regular dataset\n",
        "        for el in dataset:\n",
        "            # Retrieve scores and top indices by calling the DPR\n",
        "            scores, top_m_indices = dpr(el)\n",
        "            # Obtain the paragraphs and their encodings by calling the collect function\n",
        "            paragraphs, full_enc, search_enc = \\\n",
        "                collect_paragraphs_from_dpr(pretokenized_paragraphs, paragraphs_encodings, top_m_indices)\n",
        "            # Yield the collected elements\n",
        "            gt_indices = el['paragraphs']['index']\n",
        "            gt_start = el['answers']['out_s']\n",
        "            gt_end = el['answers']['out_e']\n",
        "            yield {\n",
        "                'gt_indices': gt_indices, \n",
        "                'gt_start': gt_start,\n",
        "                'gt_end': gt_end,\n",
        "                'top_m_indices': top_m_indices,\n",
        "                'full_enc': full_enc, \n",
        "                'search_enc': search_enc\n",
        "            }\n",
        "\n",
        "    signature = {\n",
        "        'gt_indices': tf.TensorSpec(shape=(BATCH_SIZE, ), dtype=tf.int32), \n",
        "        'gt_start': tf.TensorSpec(shape=(BATCH_SIZE, MAX_SEQ_LEN), dtype=tf.int32),\n",
        "        'gt_end': tf.TensorSpec(shape=(BATCH_SIZE, MAX_SEQ_LEN), dtype=tf.int32),\n",
        "        'top_m_indices': tf.TensorSpec(shape=(BATCH_SIZE, 100, ), dtype=tf.int32),\n",
        "        'full_enc': tf.TensorSpec(shape=(BATCH_SIZE, 100, MAX_SEQ_LEN, BERT_DIMENSIONALITY), dtype=tf.float32), \n",
        "        'search_enc': tf.TensorSpec(shape=(BATCH_SIZE, 100, BERT_DIMENSIONALITY), dtype=tf.float32)\n",
        "    }\n",
        "\n",
        "    qa_dataset_train = tf.data.Dataset.from_generator(partial(\n",
        "            qa_dataset_generator, dataset_train), \n",
        "        output_signature=signature)\n",
        "    qa_dataset_val = tf.data.Dataset.from_generator(partial(\n",
        "            qa_dataset_generator, dataset_val), \n",
        "        output_signature=signature)\n",
        "    \n",
        "    qa_dataset_train.apply(tf.data.experimental.assert_cardinality(len(dataset_train)))\n",
        "    qa_dataset_val.apply(tf.data.experimental.assert_cardinality(len(dataset_val)))\n",
        "\n",
        "    # No need to batch the dataset, it's already batched.\n",
        "    qa_dataset_train = qa_dataset_train.cache()\n",
        "    qa_dataset_train = qa_dataset_train.shuffle(10000)\n",
        "    qa_dataset_train = qa_dataset_train.prefetch(tf.data.AUTOTUNE)\n",
        "    \n",
        "    qa_dataset_val = qa_dataset_val.cache()\n",
        "    qa_dataset_val = qa_dataset_val.shuffle(10000)\n",
        "    qa_dataset_val = qa_dataset_val.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    return qa_dataset_train, qa_dataset_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvPEufKAR0Di"
      },
      "outputs": [],
      "source": [
        "qa_dataset_train, qa_dataset_val = create_qa_datasets(\n",
        "    dataset_train, dataset_val, model.enc.model_q, paragraphs_encoding, pretokenized_paragraphs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31v6I4RsR0Di"
      },
      "outputs": [],
      "source": [
        "next(qa_dataset_train.take(1).as_numpy_iterator())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNhAi3lsPUOZ"
      },
      "source": [
        "### Training\n",
        "\n",
        "To train the model we need to:\n",
        "\n",
        "- Compile it defining the losses and optimizer.\n",
        "- Create a ground truth batch that we use for comparing the model's output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leUruObriIep"
      },
      "source": [
        "We define custom training and testing functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iWkkQK8zhv-"
      },
      "outputs": [],
      "source": [
        "# Metrics (create under the strategy scope if using TPU)\n",
        "if using_TPU:\n",
        "    with strategy.scope():\n",
        "        loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
        "        start_acc_metric = keras.metrics.CategoricalAccuracy(name=\"start_token_accuracy\")\n",
        "        end_acc_metric = keras.metrics.CategoricalAccuracy(name=\"end_token_accuracy\")\n",
        "        sel_acc_metric = keras.metrics.CategoricalAccuracy(name=\"par_selection_accuracy\")\n",
        "else:\n",
        "    loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
        "    start_acc_metric = keras.metrics.CategoricalAccuracy(name=\"start_token_accuracy\")\n",
        "    end_acc_metric = keras.metrics.CategoricalAccuracy(name=\"end_token_accuracy\")\n",
        "    sel_acc_metric = keras.metrics.CategoricalAccuracy(name=\"par_selection_accuracy\")\n",
        "\n",
        "class QuestionAnsweringModel(keras.Model):\n",
        "    def __init__(self, m=M):\n",
        "        super(QuestionAnsweringModel, self).__init__()\n",
        "        self.model_qa = create_QA_model(m)\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        return inputs['top_m_indices'], self.model_qa({\n",
        "            'topm_full_encodings': inputs['full_enc'],\n",
        "            'topm_search_encodings': inputs['search_enc']\n",
        "        })\n",
        "\n",
        "    @tf.function\n",
        "    def tf_shuffle_on_columns(self, value):\n",
        "        '''\n",
        "        Utility function that shuffles a tensor randomly on each of its rows.\n",
        "        '''\n",
        "        # Create a tensor of random numbers, argsort it and use them as indices to gather\n",
        "        # values from the original tensor\n",
        "        return tf.gather(value, tf.argsort(tf.random.uniform(tf.shape(value))), batch_dims=1)\n",
        "\n",
        "    @tf.function\n",
        "    def obtain_training_info(self, indexes, topm_indexes):\n",
        "        '''\n",
        "        Obtains a batch of data and the ground truth mask to be used while training the model\n",
        "        '''\n",
        "        # Collect ground truth indexes\n",
        "        gt_paragraphs = tf.expand_dims(tf.cast(indexes, tf.int32), -1)\n",
        "        # A training sample is formed by the positive and m-1 negative examples\n",
        "        # obtained from the top-100 for each of the questions in the batch.\n",
        "        # We create a data batch by sampling m-1 examples from the masked 100 paragraphs\n",
        "        negative_masks = tf.math.not_equal(topm_indexes, gt_paragraphs)\n",
        "        # To keep the graph working with the correct sizes, we create a tensor of negatives \n",
        "        # by random shuffling the large tensor of topm and taking the first train_m elements.\n",
        "        # The positive examples are replaced by randomly sampling from the same tensor.\n",
        "        # It could happen that the positive example is replaced by itself, or that a \n",
        "        # negative sample appears twice in the batch, but it's a non-deterministic\n",
        "        # process.\n",
        "        negatives = self.tf_shuffle_on_columns(tf.where(\n",
        "            negative_masks, topm_indexes, self.tf_shuffle_on_columns(topm_indexes))\n",
        "        )[:,:M-1]\n",
        "        # We concatenate the positive paragraph index to the selected negatives and shuffle\n",
        "        # so that the positive is not always the last element\n",
        "        data_batch = self.tf_shuffle_on_columns(\n",
        "            tf.concat([negatives, gt_paragraphs], axis=1))\n",
        "        # When we have a data batch, we create the ground truth mask, which represents the position\n",
        "        # of the positive sample in the data batch in a one-hot encoded fashion.\n",
        "        gt_mask = tf.cast(data_batch == gt_paragraphs, tf.int32)\n",
        "        return data_batch, gt_mask\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # Obtain the training batch and the ground truth mask\n",
        "        data_batch, gt_mask = self.obtain_training_info(\n",
        "            data['gt_indices'], data['top_m_indices'])\n",
        "        # Open the gradient tape, obtain predictions and compute the loss\n",
        "        with tf.GradientTape() as tape:\n",
        "            _, out_S, out_E, out_SEL = self(data_batch, training=True)\n",
        "            loss_start = self.compiled_loss(data['gt_start'], out_S)\n",
        "            loss_end = self.compiled_loss(data['gt_end'], out_E)\n",
        "            loss_sel = self.compiled_loss(gt_mask, out_SEL)\n",
        "            loss_value = sum([loss_start, loss_end, loss_sel])\n",
        "        # Compute the gradients and apply them on the variables\n",
        "        grads = tape.gradient(loss_value, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        # Update the metrics\n",
        "        loss_tracker.update_state(loss_value)\n",
        "        start_acc_metric.update_state(data['gt_start'], out_S)\n",
        "        end_acc_metric.update_state(data['gt_end'], out_E)\n",
        "        sel_acc_metric.update_state(gt_mask, out_SEL)\n",
        "        return {\"loss\": loss_tracker.result(), \n",
        "                \"start_accuracy\": start_acc_metric.result(),\n",
        "                \"end_accuracy\": end_acc_metric.result(),\n",
        "                \"sel_accuracy\": sel_acc_metric.result()}\n",
        "\n",
        "    def test_step(self, data):\n",
        "        # Obtain the training batch and the ground truth mask to compute metrics\n",
        "        data_batch, gt_mask = self.obtain_training_info(\n",
        "            data['gt_indices'], data['top_m_indices'])\n",
        "        # Compute predictions\n",
        "        _, out_S, out_E, out_SEL = self(data_batch, training=False)\n",
        "        # Compute the loss to update its metric\n",
        "        loss_start = self.compiled_loss(data['gt_start'], out_S)\n",
        "        loss_end = self.compiled_loss(data['gt_end'], out_E)\n",
        "        loss_sel = self.compiled_loss(gt_mask, out_SEL)\n",
        "        loss_value = sum([loss_start, loss_end, loss_sel])\n",
        "        loss_tracker.update_state(loss_value)\n",
        "        # Updates the metrics\n",
        "        start_acc_metric.update_state(data['gt_start'], out_S)\n",
        "        end_acc_metric.update_state(data['gt_end'], out_E)\n",
        "        sel_acc_metric.update_state(gt_mask, out_SEL)\n",
        "        # Return a dict mapping metric names to current value.\n",
        "        return {\"loss\": loss_tracker.result(), \n",
        "                \"start_accuracy\": start_acc_metric.result(),\n",
        "                \"end_accuracy\": end_acc_metric.result(),\n",
        "                \"sel_accuracy\": sel_acc_metric.result()}\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        # We list our `Metric` objects here so that `reset_states()` can be\n",
        "        # called automatically at the start of each epoch\n",
        "        # or at the start of `evaluate()`.\n",
        "        return [loss_tracker, start_acc_metric, end_acc_metric, sel_acc_metric]\n",
        "\n",
        "def create_trainable_QA_model(model_q):\n",
        "    print(\"Creating Question Answering model...\")\n",
        "    model = QuestionAnsweringModel(model_q)\n",
        "\n",
        "    print(\"Compiling...\")\n",
        "    # Compile the model (metrics are defined into the model)\n",
        "    model.compile(\n",
        "        optimizer = keras.optimizers.Adam(learning_rate=3e-6),\n",
        "        loss = keras.losses.CategoricalCrossentropy()\n",
        "    )\n",
        "\n",
        "    print(\"Testing on some data...\")\n",
        "    # Pass one batch of test data to build the model\n",
        "    inputs = next(qa_dataset_train.take(1).as_numpy_iterator())\n",
        "    top_m_indices, probs_sel, probs_s, probs_e = model(inputs)\n",
        "    \n",
        "    print(\"Output shapes:\")\n",
        "    print(f\"\\tparagraphs: {top_m_indices.shape}\")\n",
        "    print(f\"\\tprobs_sel: {probs_sel.shape}\")\n",
        "    print(f\"\\tprobs_s: {probs_s.shape}\")\n",
        "    print(f\"\\tprobs_e: {probs_e.shape}\")\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5RLqioFsIon",
        "outputId": "dd938727-727a-4ef2-f2c3-6babf79550db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating Question Answering model...\n",
            "Compiling...\n",
            "Testing on some data...\n"
          ]
        },
        {
          "ename": "InternalError",
          "evalue": "Exception encountered when calling layer \"dense_passage_retriever_2\" (type DensePassageRetriever).\n\nFailed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.\n\nCall arguments received:\n  • inputs={'questions': {'input_ids': 'tf.Tensor(shape=(4, 400), dtype=int64)', 'attention_mask': 'tf.Tensor(shape=(4, 400), dtype=int64)', 'index': 'tf.Tensor(shape=(4,), dtype=int64)'}, 'answers': {'out_s': 'tf.Tensor(shape=(4, 400), dtype=int64)', 'out_e': 'tf.Tensor(shape=(4, 400), dtype=int64)'}, 'paragraphs': {'input_ids': 'tf.Tensor(shape=(4, 400), dtype=int64)', 'attention_mask': 'tf.Tensor(shape=(4, 400), dtype=int64)', 'tokens_s': 'tf.Tensor(shape=(4, 400), dtype=int64)', 'tokens_e': 'tf.Tensor(shape=(4, 400), dtype=int64)', 'index': 'tf.Tensor(shape=(4,), dtype=int64)'}}",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22196/787245389.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \"training_qa_dpr\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mmodel_QA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_trainable_QA_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_q\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpretokenized_paragraphs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparagraphs_encoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22196/3641427625.py\u001b[0m in \u001b[0;36mcreate_trainable_QA_model\u001b[1;34m(model_q, pretokenized_paragraphs, paragraphs_encodings)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;31m# Pass one batch of test data to build the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_numpy_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopm_indexes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdpr_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m     \u001b[0mparagraphs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_scoring_paragraphs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobs_sel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobs_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobs_e\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopm_indexes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Volpe\\anaconda3\\envs\\nlp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22196/613652970.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mq_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_q\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m                                                     \u001b[1;31m# batch_size x encoding_dim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;31m# 2) Selection of paragraphs using search encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq_repr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparagraphs_encodings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m             \u001b[1;31m# batch_size x num_parag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0mtopm_indexes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'DESCENDING'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m        \u001b[1;31m# batch_size x m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopm_indexes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mInternalError\u001b[0m: Exception encountered when calling layer \"dense_passage_retriever_2\" (type DensePassageRetriever).\n\nFailed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.\n\nCall arguments received:\n  • inputs={'questions': {'input_ids': 'tf.Tensor(shape=(4, 400), dtype=int64)', 'attention_mask': 'tf.Tensor(shape=(4, 400), dtype=int64)', 'index': 'tf.Tensor(shape=(4,), dtype=int64)'}, 'answers': {'out_s': 'tf.Tensor(shape=(4, 400), dtype=int64)', 'out_e': 'tf.Tensor(shape=(4, 400), dtype=int64)'}, 'paragraphs': {'input_ids': 'tf.Tensor(shape=(4, 400), dtype=int64)', 'attention_mask': 'tf.Tensor(shape=(4, 400), dtype=int64)', 'tokens_s': 'tf.Tensor(shape=(4, 400), dtype=int64)', 'tokens_e': 'tf.Tensor(shape=(4, 400), dtype=int64)', 'index': 'tf.Tensor(shape=(4,), dtype=int64)'}}"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "\n",
        "if using_TPU:\n",
        "    # TPU requires to create the model within the scope of the distributed strategy\n",
        "    # we're using.\n",
        "    with strategy.scope():\n",
        "        model_QA = create_trainable_QA_model(model.enc.model_q, pretokenized_paragraphs, paragraphs_encoding)\n",
        "\n",
        "    # Workaraound for saving locally when using cloud TPUs\n",
        "    local_device_option = tf.train.CheckpointOptions(\n",
        "        experimental_io_device=\"/job:localhost\")\n",
        "else:\n",
        "    # GPUs and local systems don't need the above specifications. We simply\n",
        "    # create a pattern for the filename and let the callbacks deal with it.\n",
        "    checkpoint_path = os.path.join(checkpoint_dir, \"model_qa_cp-{epoch:04d}.ckpt\")\n",
        "    # Also, on TPU we cannot use tensorboard, but on GPU we can\n",
        "    log_dir = os.path.join(ROOT_PATH, \"data\", \"logs\", \n",
        "        \"training_qa_dpr\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "    \n",
        "    model_QA = create_trainable_QA_model(model.enc.model_q, pretokenized_paragraphs, paragraphs_encoding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffh1nGX0I9FT"
      },
      "source": [
        "Train the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmsAi9v63eia"
      },
      "outputs": [],
      "source": [
        "QA_BATCH_SIZE = 4 if not using_TPU else 32\n",
        "\n",
        "dataset_train = create_dataset_from_records(train_questions, paragraphs, train_dict, tokenizer_distilbert, \n",
        "                                            os.path.join(datasets_dir, 'train'), batch_size=QA_BATCH_SIZE)\n",
        "dataset_val = create_dataset_from_records(val_questions, paragraphs, val_dict, tokenizer_distilbert,\n",
        "                                            os.path.join(datasets_dir, 'val'), training=False, batch_size=QA_BATCH_SIZE)\n",
        "\n",
        "if DO_QA_TRAINING:\n",
        "    # Early stopping can be used by both hardware\n",
        "    es_callback = tf.keras.callbacks.EarlyStopping(\n",
        "        patience = PATIENCE,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "    callbacks = [es_callback]\n",
        "    if not using_TPU:\n",
        "        # ModelCheckpoint callback is only available when not using TPU\n",
        "        cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "            filepath = checkpoint_path,\n",
        "            verbose=1,\n",
        "            save_weights_only = True,\n",
        "            save_best_only = False\n",
        "        )\n",
        "        # Same for tensorboard callback\n",
        "        tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "            log_dir=log_dir,\n",
        "            histogram_freq=1\n",
        "        )\n",
        "        # Save the first weights using the pattern from before\n",
        "        model_QA.save_weights(checkpoint_path.format(epoch=0))\n",
        "        # These callback imply saving stuff on local disk, which cannot be \n",
        "        # done automatically using TPUs.\n",
        "        # Therefore, they are only active when using GPUs and local systems\n",
        "        callbacks.extend([cp_callback, tensorboard_callback])\n",
        "    else:\n",
        "        # Save first weights in a h5 file (it's the most stable way)\n",
        "        model_QA.save_weights(os.path.join(\n",
        "            checkpoint_dir, 'training_qa_tpu_0.h5'), overwrite=True)        \n",
        "\n",
        "    # We fit the model\n",
        "    history = model_QA.fit(\n",
        "        dataset_train, \n",
        "        y=None,\n",
        "        validation_data=dataset_val,\n",
        "        epochs=EPOCHS, \n",
        "        callbacks=callbacks,\n",
        "        shuffle=True,\n",
        "        use_multiprocessing=True,\n",
        "        initial_epoch=0,\n",
        "        verbose=1 # Show progress bar\n",
        "    )\n",
        "\n",
        "    if using_TPU:\n",
        "        # Save last weights\n",
        "        model_qa.save_weights(os.path.join(\n",
        "            checkpoint_dir, 'training_qa_tpu_last.h5'), overwrite=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-I79iOHjGbE-"
      },
      "source": [
        "### Obtaining an answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWUaL844hyf6"
      },
      "outputs": [],
      "source": [
        "def start_end_token_from_probabilities(\n",
        "    pstartv: np.array, \n",
        "    pendv: np.array, \n",
        "    dim:int=512) -> List[List[int]]:\n",
        "    '''\n",
        "    Returns a List of [StartToken, EndToken] elements computed from the batch outputs.\n",
        "    '''\n",
        "    idxs = []\n",
        "    for i in range(pstartv.shape[0]):\n",
        "        # For each element in the batch, transform the vectors into matrices\n",
        "        # by repeating them dim times:\n",
        "        # - Vectors of starting probabilities are stacked on the columns\n",
        "        pstart = np.stack([pstartv[i,:]]*dim, axis=1)\n",
        "        # - Vectors of ending probabilities are repeated on the rows\n",
        "        pend = np.stack([pendv[i,:]]*dim, axis=0)\n",
        "        # Once we have the two matrices, we sum them (element-wise operation)\n",
        "        # to obtain the scores of each combination\n",
        "        sums = pstart + pend\n",
        "        # We only care about the scores in the upper triangular part of the matrix\n",
        "        # (where the ending index is greater than the starting index)\n",
        "        # therefore we zero out the diagonal and the lower triangular area\n",
        "        sums = np.triu(sums, k=1)\n",
        "        # The most probable set of tokens is the one with highest score in the\n",
        "        # remaining matrix. Through argmax we obtain its position.\n",
        "        val = np.argmax(sums)\n",
        "        # Since the starting probabilities are repeated on the columns, each element\n",
        "        # is identified by the row. Ending probabilities are instead repeated on rows,\n",
        "        # so each element is identified by the column.\n",
        "        row = val // dim\n",
        "        col = val - dim*row\n",
        "        idxs.append([row,col])\n",
        "    return idxs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CUVf45Cj0oI"
      },
      "outputs": [],
      "source": [
        "answers_start_end = start_end_token_from_probabilities(probs_s, probs_e)\n",
        "print(answers_start_end)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVfgDsb_GHIE"
      },
      "source": [
        "Finally, we can obtain the answers to the questions we have given the network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcpI3LVz2vKY"
      },
      "outputs": [],
      "source": [
        "best_indices = tf.squeeze(tf.gather(paragraphs['indexes'], tf.expand_dims(best_scoring_paragraphs, -1), batch_dims=1))\n",
        "best_offsets = tf.squeeze(tf.gather(pretokenized_val_paragraphs['offset_mapping'], best_indices))\n",
        "best_offsets.shape, best_indices.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuWtARzUITEV"
      },
      "outputs": [],
      "source": [
        "char_start_end = [(best_offsets[i][answers_start_end[i][0]][0].numpy(),\n",
        "                   best_offsets[i][answers_start_end[i][1]][1].numpy())\n",
        "                 for i in range(BATCH_SIZE)]\n",
        "char_start_end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktvdpz52fxOc"
      },
      "outputs": [],
      "source": [
        "# Correction for answers arriving to the end of the sequence\n",
        "for i in range(BATCH_SIZE):\n",
        "    c = char_start_end[i]\n",
        "    if c[1] >= c[0]:\n",
        "        char_start_end[i] = (c[0], c[1])\n",
        "    else:\n",
        "        char_start_end[i] = (c[0], 1000000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6edjxYTw4k-t"
      },
      "outputs": [],
      "source": [
        "for i, p in enumerate(best_indices.numpy()):\n",
        "    print(val_paragraphs[p]['context'][char_start_end[i][0]:char_start_end[i][1]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_B5U-_tKR6v"
      },
      "source": [
        "Of course, answers are extremely bad because we need to train the Dense layers selecting the start and end tokens, as well as the paragraph selector."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "QA_DPR.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.13",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "68bcab510961ee730b63c1a3ea5fc4f15a05e7cdf00d3442986724f8b958dcdf"
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "499774584a42420fa6c90c0272352269": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d16d761751c474f90265b2abb657356",
              "IPY_MODEL_564263977cc549548340b16564b07f24",
              "IPY_MODEL_716b067107b3430b958a552c9e841585"
            ],
            "layout": "IPY_MODEL_f53b30f62ff34d7a9fd8cd308fe3feac"
          }
        },
        "8d16d761751c474f90265b2abb657356": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdd1599a67c6449db4b135aefffc666d",
            "placeholder": "​",
            "style": "IPY_MODEL_718d4125937e43d8816c157964e141eb",
            "value": "Downloading tokenizer_config.json: 100%"
          }
        },
        "564263977cc549548340b16564b07f24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4b053ec158f40749985bf3a12f44fe0",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_740166cceef04af7bc13633e248c258b",
            "value": 28
          }
        },
        "716b067107b3430b958a552c9e841585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae1425950d974937aef7c5d5fba5dd92",
            "placeholder": "​",
            "style": "IPY_MODEL_85573b898be3491da10466c1a5221215",
            "value": " 28.0/28.0 [00:00&lt;00:00, 746B/s]"
          }
        },
        "f53b30f62ff34d7a9fd8cd308fe3feac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdd1599a67c6449db4b135aefffc666d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "718d4125937e43d8816c157964e141eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4b053ec158f40749985bf3a12f44fe0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "740166cceef04af7bc13633e248c258b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae1425950d974937aef7c5d5fba5dd92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85573b898be3491da10466c1a5221215": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3dfda2c30d3146b4a5e375799752bf91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8fafebcff95e4ff2abf17b967a93ca57",
              "IPY_MODEL_077a6b40d911430682f8054c04ecb277",
              "IPY_MODEL_4b0e7db773534e228e638961982fef18"
            ],
            "layout": "IPY_MODEL_decbe4d74d2346229536dfed40e7fca8"
          }
        },
        "8fafebcff95e4ff2abf17b967a93ca57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c62d9ff39f847fe8ed3e1809295be05",
            "placeholder": "​",
            "style": "IPY_MODEL_2c7fcc1bab67468289ef83236d87d0a9",
            "value": "Downloading vocab.txt: 100%"
          }
        },
        "077a6b40d911430682f8054c04ecb277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_217af8f08170470a92770fb6bad3e3b3",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5167ef976c3a4c1fb087e6b2adc6f49f",
            "value": 231508
          }
        },
        "4b0e7db773534e228e638961982fef18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d08b5b2168554fdbb008101acf3bd382",
            "placeholder": "​",
            "style": "IPY_MODEL_812e1b35867a4336adea94b012639889",
            "value": " 226k/226k [00:00&lt;00:00, 267kB/s]"
          }
        },
        "decbe4d74d2346229536dfed40e7fca8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c62d9ff39f847fe8ed3e1809295be05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c7fcc1bab67468289ef83236d87d0a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "217af8f08170470a92770fb6bad3e3b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5167ef976c3a4c1fb087e6b2adc6f49f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d08b5b2168554fdbb008101acf3bd382": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "812e1b35867a4336adea94b012639889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d406963504e4b7b8f28647ef48d5079": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a73d0f56bf4b4c4b8d6b241852a405c0",
              "IPY_MODEL_773b328fabb04948887ed8ec46d4f30d",
              "IPY_MODEL_cab759daebdf4dcab33276ab0d6e7362"
            ],
            "layout": "IPY_MODEL_47727ca7448e4afa8e0df786f681e135"
          }
        },
        "a73d0f56bf4b4c4b8d6b241852a405c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60e23af1fd724237a939eed260c80700",
            "placeholder": "​",
            "style": "IPY_MODEL_5ad7951170e44318885698fc49461f77",
            "value": "Downloading tokenizer.json: 100%"
          }
        },
        "773b328fabb04948887ed8ec46d4f30d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e340216a8af45f48e145eea1601117d",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d444dabeeb5547d1b8a04ec19cadaef8",
            "value": 466062
          }
        },
        "cab759daebdf4dcab33276ab0d6e7362": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5199194388d94209a38714b927472cf9",
            "placeholder": "​",
            "style": "IPY_MODEL_cd5a98e3b2824afe90dcb18bab98e4b5",
            "value": " 455k/455k [00:01&lt;00:00, 525kB/s]"
          }
        },
        "47727ca7448e4afa8e0df786f681e135": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60e23af1fd724237a939eed260c80700": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ad7951170e44318885698fc49461f77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e340216a8af45f48e145eea1601117d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d444dabeeb5547d1b8a04ec19cadaef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5199194388d94209a38714b927472cf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd5a98e3b2824afe90dcb18bab98e4b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c61a401378b7493b9905434f6e83ef56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4733b5aaf9e2411c93aa208353901311",
              "IPY_MODEL_b13306fe6d204416bc1844dce531c48c",
              "IPY_MODEL_08d9864e1dbd428687b931f7e28c414e"
            ],
            "layout": "IPY_MODEL_4bd4b04481a3415dacdd0dc165e4f007"
          }
        },
        "4733b5aaf9e2411c93aa208353901311": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84dcf6e0a02640d3ae3106135c488f72",
            "placeholder": "​",
            "style": "IPY_MODEL_f5b72206db5145b4b540c294cae16c0b",
            "value": "Downloading config.json: 100%"
          }
        },
        "b13306fe6d204416bc1844dce531c48c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_089a1f3576634245b06d3b8cd036da1e",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_585e75aac58543b48036d556fe07a7f2",
            "value": 483
          }
        },
        "08d9864e1dbd428687b931f7e28c414e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ee7d442e10548208dbdee3177ea3585",
            "placeholder": "​",
            "style": "IPY_MODEL_bf2a62f3d3a54174985903544134c43d",
            "value": " 483/483 [00:00&lt;00:00, 14.8kB/s]"
          }
        },
        "4bd4b04481a3415dacdd0dc165e4f007": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84dcf6e0a02640d3ae3106135c488f72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5b72206db5145b4b540c294cae16c0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "089a1f3576634245b06d3b8cd036da1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "585e75aac58543b48036d556fe07a7f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ee7d442e10548208dbdee3177ea3585": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf2a62f3d3a54174985903544134c43d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b669fc1fdb2d46be8e36873af2effc8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_867a387a09bb472eb76f479e14c7aee5",
              "IPY_MODEL_1a21ea5c7e0b4a6d92a6493d85b7b3f6",
              "IPY_MODEL_8f01a1ead72f452f8e5fb6a9c2387a21"
            ],
            "layout": "IPY_MODEL_24330ad68e7d4f41851136dc97e4f5cf"
          }
        },
        "867a387a09bb472eb76f479e14c7aee5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aef7955f08a2439d8298bea0c83decf3",
            "placeholder": "​",
            "style": "IPY_MODEL_292939448b704499a20d074d40e6c9dc",
            "value": "Downloading tf_model.h5: 100%"
          }
        },
        "1a21ea5c7e0b4a6d92a6493d85b7b3f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e544d4b5720b43a4a46112058242b1d1",
            "max": 363423424,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_189ce92c11cf49c994f7b38250d4e791",
            "value": 363423424
          }
        },
        "8f01a1ead72f452f8e5fb6a9c2387a21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43253fcb174f4af28c6c4f6061b40043",
            "placeholder": "​",
            "style": "IPY_MODEL_408c3c629da84625bd35f5b752e65cba",
            "value": " 347M/347M [00:07&lt;00:00, 56.9MB/s]"
          }
        },
        "24330ad68e7d4f41851136dc97e4f5cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aef7955f08a2439d8298bea0c83decf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "292939448b704499a20d074d40e6c9dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e544d4b5720b43a4a46112058242b1d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "189ce92c11cf49c994f7b38250d4e791": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "43253fcb174f4af28c6c4f6061b40043": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "408c3c629da84625bd35f5b752e65cba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}