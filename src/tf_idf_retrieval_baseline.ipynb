{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_O8H6y5b5yZT",
        "outputId": "bea5ea59-c686-4f36-de9d-0d1e3ab51db4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 8.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 50.3 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 53.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 6.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 56.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n",
            "Mon Apr  4 23:27:44 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Cloning into 'QuestionAnswering'...\n",
            "warning: redirecting to https://github.com/MarcelloCeresini/QuestionAnswering.git/\n",
            "remote: Enumerating objects: 818, done.\u001b[K\n",
            "remote: Counting objects: 100% (779/779), done.\u001b[K\n",
            "remote: Compressing objects: 100% (468/468), done.\u001b[K\n",
            "remote: Total 818 (delta 466), reused 589 (delta 282), pack-reused 39\u001b[K\n",
            "Receiving objects: 100% (818/818), 28.17 MiB | 12.50 MiB/s, done.\n",
            "Resolving deltas: 100% (470/470), done.\n",
            "Mounted at /content/drive/\n",
            "/content/QuestionAnswering/src\n"
          ]
        }
      ],
      "source": [
        "username = 'MarcelloCeresini'\n",
        "repository = 'QuestionAnswering'\n",
        "\n",
        "# COLAB ONLY CELLS\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    !pip3 install transformers\n",
        "    !nvidia-smi             # Check which GPU has been chosen for us\n",
        "    !git clone https://www.github.com/{username}/{repository}.git\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive/')\n",
        "    %cd /content/QuestionAnswering/src\n",
        "except:\n",
        "    IN_COLAB = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g84UMFvU5yZW"
      },
      "source": [
        "# Tf-Idf retrieval baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GLWZShI5yZY"
      },
      "source": [
        "In this notebook, we implement a simple baseline for paragraph retrieval using Tf-Idf weighted sparse representations of documents and query questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "cc0520c9e1f142279da89e756ffa8719",
            "3dfe8c70815c4de7b4cbea4ad3c15179",
            "d61854a4cca0423e97f2a2b96a22df00",
            "efb028580ed7444f887205ed15ff2e97",
            "f295fcfc5b1043368caba3f396e6a09d",
            "387e179f6222418aab0e60e1932f491f",
            "8887e6cc6ffb4f0d932f56b6150b9703",
            "4d2d4f30d5c04f06a3216a3fdb18611b",
            "1c3c157d39874f96a791ce8c6f6cb5ef",
            "f2250866910345f3b2c487754e006a63",
            "c26c38b160c9493db467c7d7588c0160",
            "e94e647c88e74bed9be9ada22e6f8f09",
            "02baf1f55a604381bcad09904199116a",
            "bfe73b96dabf410388cc24a99318d4f2",
            "4dbb78af646e4fd684a47759043900e6",
            "a0477e7e7f1e48deb1d1afc4cc446c1b",
            "07fc8b6e6503432ca43b74f36d5e412b",
            "b83564049fc44e1bac2ece53c9b4bdc6",
            "fadbed34502c450481001a0434009fb6",
            "ad0fefa52cce40aea76e4546ba759358",
            "fa3e4712c08847499aab1a2f018e1e60",
            "b330089eea5e4baeb4d10091e93db7d3",
            "c7ab10277d5d4e84a3331613228f3d13",
            "650f26b9d70742e1ad9ec64a661a2069",
            "9bafe78ef71543aeacb2d0bb991553c1",
            "e03eebb69670448a81398e5139cbfdaa",
            "09ef6a4be16d47018539f305400f1adc",
            "9294ac51bcb1427c82f77db61a034de8",
            "9a51ed4b68ef41bd860e2ae346ed5e73",
            "3337b6b5c218485db30084fdd50d6db7",
            "78a1b99e696040c59d16764744cc079e",
            "4edf5c46c9ea455a8318766cbef27078",
            "b113ae2e41d44c58b0390e2a7836dd09",
            "851454ad885a4e0bb651020c598d3f18",
            "5f5530b94c0b43f3ba118eb446e4678f",
            "98b08db5f15e4248bdc5a064bc7e0ed3",
            "869bb224a2f34af3a71283e6c48e8c57",
            "959627a3e1964476a2ccee945a2602f7",
            "b1b7cdae729042ac8157806a21268a66",
            "917ca47975df4d1d8473d496fc1b2085",
            "2c60bf5f80ea40ad9ffc123989c7d966",
            "7f776f79d569431f9c5e6d5710cf4873",
            "c99c64818c2d44f1b048292f9857592b",
            "ca9d2494788a46c78b6710c1239bbed7"
          ]
        },
        "id": "wSMzmIlZ5yZZ",
        "outputId": "53575263-fbcf-4e32-f132-e51a9a3d8a47"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc0520c9e1f142279da89e756ffa8719"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e94e647c88e74bed9be9ada22e6f8f09"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7ab10277d5d4e84a3331613228f3d13"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "851454ad885a4e0bb651020c598d3f18"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from functools import partial\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from config import Config\n",
        "config = Config()\n",
        "import utils\n",
        "\n",
        "# Fix random seed for reproducibility\n",
        "np.random.seed(config.RANDOM_SEED)\n",
        "random.seed(config.RANDOM_SEED)\n",
        "tf.random.set_seed(config.RANDOM_SEED)\n",
        "\n",
        "from typing import List, Dict\n",
        "#os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_thUdCdU5yZZ"
      },
      "outputs": [],
      "source": [
        "ROOT_PATH = os.path.dirname(os.getcwd())\n",
        "TRAINING_FILE = os.path.join(ROOT_PATH, 'data', 'training_set.json')\n",
        "paragraphs_and_questions = utils.read_question_set(TRAINING_FILE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuChVKjW5yZa"
      },
      "source": [
        "First of all, we separate questions from their paragraphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-Kzmnxv5yZa",
        "outputId": "4ea03995-5e9c-4359-ebb8-8d99a1d1c923"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of questions: 87599\n",
            "Number of paragraphs: 18896\n"
          ]
        }
      ],
      "source": [
        "questions = [{\n",
        "        'qas': qas,\n",
        "        'context_id': (i,j)    # We also track the question's original context and paragraph indices so to have a ground truth\n",
        "    }\n",
        "    for i in range(len(paragraphs_and_questions['data']))\n",
        "    for j, para in enumerate(paragraphs_and_questions['data'][i]['paragraphs'])\n",
        "    for qas in para['qas']\n",
        "]\n",
        "\n",
        "paragraphs = [{\n",
        "        'context': para['context'],\n",
        "        'context_id': i\n",
        "    }\n",
        "    for i in range(len(paragraphs_and_questions['data']))\n",
        "    for para in paragraphs_and_questions['data'][i]['paragraphs']\n",
        "]\n",
        "\n",
        "print(f\"Number of questions: {len(questions)}\")\n",
        "print(f\"Number of paragraphs: {len(paragraphs)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFoe0wTg5yZc"
      },
      "source": [
        "We build a function to obtain the paragraph given our context indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GrYOzf4X5yZc"
      },
      "outputs": [],
      "source": [
        "def get_paragraph_from_question(qas, dataset):\n",
        "    i,j = qas['context_id']\n",
        "    return dataset['data'][i]['paragraphs'][j]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNTJ9JHH5yZd",
        "outputId": "aee95ab6-4ec7-4361-9d44-2586ed542429"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What poet wrote a long poem describing Roman religious holidays?\n",
            "\n",
            "Ground truth context: 'The meaning and origin of many archaic festivals baffled even Rome's intellectual elite, but the more obscure they were, the greater the opportunity for reinvention and reinterpretation — a fact lost neither on Augustus in his program of religious reform, which often cloaked autocratic innovation, nor on his only rival as mythmaker of the era, Ovid. In his Fasti, a long-form poem covering Roman holidays from January to June, Ovid presents a unique look at Roman antiquarian lore, popular customs, and religious practice that is by turns imaginative, entertaining, high-minded, and scurrilous; not a priestly account, despite the speaker's pose as a vates or inspired poet-prophet, but a work of description, imagination and poetic etymology that reflects the broad humor and burlesque spirit of such venerable festivals as the Saturnalia, Consualia, and feast of Anna Perenna on the Ides of March, where Ovid treats the assassination of the newly deified Julius Caesar as utterly incidental to the festivities among the Roman people. But official calendars preserved from different times and places also show a flexibility in omitting or expanding events, indicating that there was no single static and authoritative calendar of required observances. In the later Empire under Christian rule, the new Christian festivals were incorporated into the existing framework of the Roman calendar, alongside at least some of the traditional festivals.'\n"
          ]
        }
      ],
      "source": [
        "x = random.randint(0, len(questions)-1)\n",
        "print(f\"Question: {questions[x]['qas']['question']}\")\n",
        "print()\n",
        "print(f\"Ground truth context: '{get_paragraph_from_question(questions[x], paragraphs_and_questions)['context']}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nomrUS_g5yZe"
      },
      "source": [
        "Now, given a question (query) we would like to obtain the paragraph that most probably contains the answer in order to pass it into the BERT QA model. One way to do that is by using tf-idf on the large set of paragraphs. In reality we will use more complex methods and this should be considered a baseline. We will use a `TdIdfVectorizer` from Scikit Learn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "46T1i7J95yZf"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(strip_accents='unicode', \n",
        "    lowercase=True, \n",
        "    max_df=0.8,     # Filter out common words that appear in more than 80% of the paragraphs\n",
        "    norm='l2') # The vectorizer also l2 normalizes the vectors it produces, so that the cosine similarity operation between vectors simply becomes a dot product.\n",
        "docs = vectorizer.fit_transform([paragraphs[i]['context'] for i in range(len(paragraphs))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBbhOcrr5yZg",
        "outputId": "d8bb711e-8c87-4493-dd5f-0579a9e23049"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18896, 77747)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "docs.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_t7Prb_F5yZg"
      },
      "source": [
        "Now, in order to compute scores between a query question and the set of document, we use **cosine similarity**.\n",
        "\n",
        "$$\n",
        "S_C (A,B) = \\frac{A \\cdot B}{\\lVert A\\rVert  \\lVert B\\rVert }\n",
        "$$\n",
        "\n",
        "Note: the `TfIdfVectorizer` we use already L2-normalizes all vectors it produces, so in the actual implementation we only compute a dot product."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlbBSHE75yZh",
        "outputId": "bf1d58fe-b4d4-480e-8d67-845248504718"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-5 paragraphs: [    0  6929  6937  6944 12250]\n",
            "Question: To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n",
            "Paragraphs:\n",
            "0 (score: 0.27): Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n",
            "\n",
            "1 (score: 0.26):  In Methodism, Mary is honored as the Mother of God. Methodists do not have any additional teachings on the Virgin Mary except from what is mentioned in Scripture and the ecumenical Creeds. As such, Methodists believe that Mary was conceived in her womb through the Holy Ghost and accept the doctrine of the Virgin Birth, although they, along with Orthodox Christians and other Protestant Christians, reject the doctrine of the Immaculate Conception. John Wesley, the principal founder of the Methodist movement within the Church of England, believed that Mary \"continued a pure and unspotted virgin\", thus upholding the doctrine of the perpetual virginity of Mary. Contemporary Methodism does hold that Mary was a virgin before, during, and immediately after the birth of Christ. In addition, some Methodists also hold the doctrine of the Assumption of Mary as a pious opinion.\n",
            "\n",
            "2 (score: 0.23): Mary's special position within God's purpose of salvation as \"God-bearer\" (Theotokos) is recognised in a number of ways by some Anglican Christians. All the member churches of the Anglican Communion affirm in the historic creeds that Jesus was born of the Virgin Mary, and celebrates the feast days of the Presentation of Christ in the Temple. This feast is called in older prayer books the Purification of the Blessed Virgin Mary on February 2. The Annunciation of our Lord to the Blessed Virgin on March 25 was from before the time of Bede until the 18th century New Year's Day in England. The Annunciation is called the \"Annunciation of our Lady\" in the 1662 Book of Common Prayer. Anglicans also celebrate in the Visitation of the Blessed Virgin on 31 May, though in some provinces the traditional date of July 2 is kept. The feast of the St. Mary the Virgin is observed on the traditional day of the Assumption, August 15. The Nativity of the Blessed Virgin is kept on September 8.\n",
            "\n",
            "3 (score: 0.22): The Protoevangelium of James, an extra-canonical book, has been the source of many Orthodox beliefs on Mary. The account of Mary's life presented includes her consecration as a virgin at the temple at age three. The High Priest Zachariah blessed Mary and informed her that God had magnified her name among many generations. Zachariah placed Mary on the third step of the altar, whereby God gave her grace. While in the temple, Mary was miraculously fed by an angel, until she was twelve years old. At that point an angel told Zachariah to betroth Mary to a widower in Israel, who would be indicated. This story provides the theme of many hymns for the Feast of Presentation of Mary, and icons of the feast depict the story. The Orthodox believe that Mary was instrumental in the growth of Christianity during the life of Jesus, and after his Crucifixion, and Orthodox Theologian Sergei Bulgakov wrote: \"The Virgin Mary is the center, invisible, but real, of the Apostolic Church.\"\n",
            "\n",
            "4 (score: 0.21): The presence of the Virgin Mary under the cross[Jn. 19:26-27] has in itself been the subject of Marian art, and well known Catholic symbolism such as the Miraculous Medal and Pope John Paul II's Coat of Arms bearing a Marian Cross. And a number of Marian devotions also involve the presence of the Virgin Mary in Calvary, e.g., Pope John Paul II stated that \"Mary was united to Jesus on the Cross\". Well known works of Christian art by masters such as Raphael (e.g., the Mond Crucifixion), and Caravaggio (e.g., his Entombment) depict the Virgin Mary as part of the crucifixion scene.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def score_documents(vectorizer, query, docs):\n",
        "    q = query['qas']['question']\n",
        "    q = vectorizer.transform([q]) # q will be a (sparse) matrix with dimensionality 1 x vocab_dim\n",
        "    # We can compute a vector of all dot products scores and transform it from dense matrix to numpy array like this:\n",
        "    return np.asarray(np.dot(docs, q.T).todense()).flatten()\n",
        "\n",
        "def top_5_for_question(vectorizer, query, docs):\n",
        "    scores = score_documents(vectorizer, query, docs)\n",
        "    sorted_scores = np.argsort(-scores) # Negated for descending order\n",
        "    return [paragraphs[i] for i in sorted_scores[:5]], scores[sorted_scores[:5]], sorted_scores[:5]\n",
        "\n",
        "def print_top_5(query, top_5_para, top_5_scores, top_5_indices):\n",
        "    print(f\"Top-5 paragraphs: {top_5_indices}\")\n",
        "    print(f\"Question: {query['qas']['question']}\")\n",
        "    print(f\"Paragraphs:\")\n",
        "    for i in range(5):\n",
        "        print(f\"{i} (score: {top_5_scores[i]:.2f}): {top_5_para[i]['context']}\\n\")\n",
        "\n",
        "QUERY = questions[0]\n",
        "top5_para, top5_scores, top5_indices = top_5_for_question(vectorizer, QUERY, docs)\n",
        "print_top_5(QUERY, top5_para, top5_scores, top5_indices)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_PVSuvt5yZh"
      },
      "source": [
        "We can measure how many times this simple baseline retrieves the correct paragraph (top-1 and top-5 accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEQ3Jm8j5yZi",
        "outputId": "668a7791-7cbf-4688-e6c3-ff961041c14a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 1 score: 72.01%,\n",
            "Top 5 score: 87.82%\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "count_top1 = 0\n",
        "count_top5 = 0\n",
        "count_total = len(questions)\n",
        "\n",
        "for q in tqdm(questions):\n",
        "    top5_para, top5_scores, top5_indices = top_5_for_question(q)\n",
        "    top5_context_ids = [top5_para[i]['context_id'] for i in range(len(top5_para))]\n",
        "    gt_context_id = q['context_id'][0]\n",
        "    if gt_context_id == top5_context_ids[0]:\n",
        "        count_top1 += 1\n",
        "    if gt_context_id in top5_context_ids:\n",
        "        count_top5 += 1\n",
        "\n",
        "top1_score = count_top1 / count_total * 100\n",
        "top5_score = count_top5 / count_total * 100\n",
        "\n",
        "print(f\"\\nTop 1 score: {top1_score:.2f}%,\\nTop 5 score: {top5_score:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5pMXBe-5yZj"
      },
      "source": [
        "The results are quite good already, but we'll investigate whether using a dense representation (eg. vectors computed by Bert) can further improve these scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhJKwAFO5yZj"
      },
      "source": [
        "## Answer computation\n",
        "\n",
        "Here we check how good are the answers of our usual model which selects the first document retrieved by Tf-Idf. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPneohNI5yZj"
      },
      "source": [
        "Firstly, we define a new kind of dataset containing everything we need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "q6NBvZ4Q5yZk"
      },
      "outputs": [],
      "source": [
        "# First of all, we create a function that instantiates a TensorFlow dataset\n",
        "# matching the best scoring paragraph for each question using the provided \n",
        "# Vectorizer\n",
        "def tf_idf_dataset_generator(\n",
        "    questions: List[Dict], paragraphs: List[Dict], \n",
        "    vectorizer:TfidfVectorizer, config: Config,\n",
        "    return_labels:bool=False, return_NER_attention:bool=False,\n",
        "    return_question_id:bool=False, NER_value:float=0):\n",
        "\n",
        "    for question_and_answer in questions:\n",
        "        # Use the vectorizer to obtain the best scoring paragraph from the question\n",
        "        top5_para, _, _ = top_5_for_question(vectorizer, question_and_answer, paragraphs)\n",
        "        question_and_answer = question_and_answer['qas']\n",
        "        paragraph = top5_para[0]\n",
        "        # Then encode the input using Bert's tokenizer\n",
        "        encoded_inputs = config.tokenizer(\n",
        "            question_and_answer[\"question\"],    # First we pass the question\n",
        "            paragraph['context'],            # Then the best scoring context\n",
        "\n",
        "            max_length = config.INPUT_LEN,      # We want to pad and truncate to this length\n",
        "            truncation = True,\n",
        "            padding = 'max_length',             # Pads all sequences to 512.\n",
        "\n",
        "            return_token_type_ids = config.bert,# Return if the token is from sentence \n",
        "                                                # 0 or sentence 1\n",
        "            return_attention_mask = True,       # Return if it's a pad token or not\n",
        "\n",
        "            return_offsets_mapping = True       # Returns each token's first and last char \n",
        "                                                # positions in the original sentence\n",
        "                                                # (we will use it to match answers starting \n",
        "                                                # and ending points to tokens)\n",
        "        )\n",
        "\n",
        "        if return_labels:\n",
        "            ### MAPPING OF THE START OF THE ANSWER BETWEEN CHARS AND TOKENS ###\n",
        "            # We want to pass from the starting position in chars to the starting position in tokens\n",
        "            label = utils.find_start_end_token_one_hot_encoded(\n",
        "                # We pass the list of answers (usually there is still one per question,\n",
        "                #   but we mustn't assume anything)\n",
        "                answers = question_and_answer[\"answers\"],\n",
        "                # And also the inputs offset mapping just recieved from the tokenizer\n",
        "                offsets = encoded_inputs[\"offset_mapping\"]\n",
        "            )\n",
        "\n",
        "        if return_NER_attention:\n",
        "            encoded_inputs['NER_attention'] = utils.create_NER_attention_vector(\n",
        "                context=paragraph[\"context\"], \n",
        "                offsets=encoded_inputs[\"offset_mapping\"],\n",
        "                spacy_instance=config.ner_extractor,\n",
        "                config=config, \n",
        "                non_ne_weight=1-NER_value,\n",
        "                ne_weight=1+NER_value\n",
        "            )\n",
        "\n",
        "        encoded_inputs.pop(\"offset_mapping\", None) # Removes the offset mapping, not useful anymore \n",
        "                                                    # (\"None\" is used because otherwise KeyError \n",
        "                                                    # could be raised if the key wasn't present)\n",
        "\n",
        "        if return_question_id and return_labels:  \n",
        "            yield dict(encoded_inputs), question_and_answer['id'], {\n",
        "                'out_S': label['out_S'],\n",
        "                'out_E': label['out_E']\n",
        "            }\n",
        "        elif return_labels:\n",
        "            yield dict(encoded_inputs), {\n",
        "                'out_S': label['out_S'],\n",
        "                'out_E': label['out_E']\n",
        "            }\n",
        "        elif return_question_id:\n",
        "            yield dict(encoded_inputs), question_and_answer['id']\n",
        "        else:\n",
        "            yield dict(encoded_inputs)\n",
        "\n",
        "def create_original_dataset_with_tf_idf(questions, paragraphs, vectorizer, config: Config):\n",
        "    features = []\n",
        "    for question_and_answer in questions:\n",
        "        # Use the vectorizer to obtain the best scoring paragraph from the question\n",
        "        top5_para, _, _ = top_5_for_question(vectorizer, question_and_answer, paragraphs)\n",
        "        question_and_answer = question_and_answer['qas']\n",
        "        paragraph = top5_para[0]\n",
        "        inputs={}\n",
        "        ### QUESTION AND CONTEXT TOKENIZATION ###\n",
        "        # For question answering with DistilBERT we need to encode both \n",
        "        # question and context, and this is the way in which \n",
        "        # HuggingFace's DistilBertTokenizer does it.\n",
        "        # The tokenizer returns a dictionary containing all the information we need\n",
        "        encoded_inputs = config.tokenizer(\n",
        "            question_and_answer[\"question\"],    # First we pass the question\n",
        "            paragraph[\"context\"],               # Then the context\n",
        "\n",
        "            max_length = config.INPUT_LEN,      # We want to pad and truncate to this length\n",
        "            truncation = True,\n",
        "            padding = 'max_length',             # Pads all sequences to 512.\n",
        "\n",
        "            return_token_type_ids = False,      # Return if the token is from sentence \n",
        "                                                # 0 or sentence 1\n",
        "            return_attention_mask = False,      # Return if it's a pad token or not\n",
        "\n",
        "            return_offsets_mapping = True       # Returns each token's first and last char \n",
        "                                                # positions in the original sentence\n",
        "                                                # (we will use it to match answers starting \n",
        "                                                # and ending points to tokens)\n",
        "        )\n",
        "        inputs[\"context\"] = paragraph[\"context\"]\n",
        "        inputs[\"offset_mapping\"] = encoded_inputs[\"offset_mapping\"]\n",
        "        features.append(inputs)\n",
        "\n",
        "    return tf.data.Dataset.from_tensor_slices(\n",
        "        pd.DataFrame.from_dict(features).to_dict(orient=\"list\"))\n",
        "\n",
        "\n",
        "def create_dataset_using_tf_idf_vectorizer(\n",
        "        questions: List[Dict],\n",
        "        paragraphs: List[Dict],\n",
        "        vectorizer: TfidfVectorizer,\n",
        "        config: Config,\n",
        "        for_training: bool=True,\n",
        "        use_NER_attention:bool=False,\n",
        "        NER_value:float=0\n",
        "    ) -> tf.data.Dataset:\n",
        "    # Labels are only returned in training, while question IDs only when not training\n",
        "    return_labels = for_training\n",
        "    return_question_id = not for_training\n",
        "    # Create expected signature for the generator output\n",
        "    if config.bert:\n",
        "        features = {\n",
        "            'input_ids': tf.TensorSpec(shape=(512,), dtype=tf.int32), \n",
        "            'attention_mask': tf.TensorSpec(shape=(512,), dtype=tf.int32),\n",
        "            'token_type_ids': tf.TensorSpec(shape=(512,), dtype=tf.int32)\n",
        "        }\n",
        "    else:\n",
        "        features = {\n",
        "            'input_ids': tf.TensorSpec(shape=(512,), dtype=tf.int32), \n",
        "            'attention_mask': tf.TensorSpec(shape=(512,), dtype=tf.int32)\n",
        "        }\n",
        "    if use_NER_attention:\n",
        "        features['NER_attention'] = tf.TensorSpec(shape=(512,), dtype=tf.float64)\n",
        "    if for_training:\n",
        "        # The dataset contains the features and the labels\n",
        "        signature = (features, {\n",
        "            'out_S': tf.TensorSpec(shape=(512,), dtype=tf.float64), \n",
        "            'out_E': tf.TensorSpec(shape=(512,), dtype=tf.float64)\n",
        "        })\n",
        "    else:\n",
        "        # The dataset contains the features and the question IDs (strings)\n",
        "        signature = (features, tf.TensorSpec(shape=(), dtype=tf.string))\n",
        "    # Instantiates a partial generator\n",
        "    data_gen = partial(tf_idf_dataset_generator, questions,\n",
        "        paragraphs, vectorizer, config, \n",
        "        return_labels=return_labels, \n",
        "        return_question_id=return_question_id,\n",
        "        return_NER_attention=use_NER_attention,\n",
        "        NER_value=NER_value)\n",
        "    # Creates the dataset with the computed signature\n",
        "    dataset = tf.data.Dataset.from_generator(data_gen,\n",
        "        output_signature=signature)\n",
        "    # Compute dataset length, to be used by tensorflow internals\n",
        "    dataset = dataset.apply(tf.data.experimental.assert_cardinality(len(questions)))\n",
        "    # Return the dataset\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jmYhDgr05yZo"
      },
      "outputs": [],
      "source": [
        "### Prediction and evaluation function ###\n",
        "def predict_and_evaluate(\n",
        "                         DATASET_PATH:str, \n",
        "                         BEST_WEIGHTS_PATH:str, \n",
        "                         PATH_TO_PREDICTIONS_JSON:str,\n",
        "                         hidden_state_list:List[int]=[3,4,5,6],\n",
        "                         use_NER_attention=False, NER_value=0,\n",
        "                         bert=False):\n",
        "    '''\n",
        "    Uses the standard model to predict the answers to the dataset provided in \n",
        "    `DATASET_PATH` using the selected weights (`BEST_WEIGHTS_PATH`), \n",
        "    saves the predictions into `PATH_TO_PREDICTIONS_JSON` and executes SQuAD's\n",
        "    evaluation script to get the exact match accuracy and F1 score.\n",
        "    '''\n",
        "    '''\n",
        "    Uses a TfIdf vectorizer to gather the best scoring document for a question (query),\n",
        "    then uses the standard model to predict the answers to the dataset provided in \n",
        "    `DATASET_PATH` using the selected weights (`BEST_WEIGHTS_PATH`), \n",
        "    saves the predictions into `PATH_TO_PREDICTIONS_JSON` and executes SQuAD's\n",
        "    evaluation script to get the exact match accuracy and F1 score.\n",
        "    '''\n",
        "    data = utils.read_question_set(DATASET_PATH)\n",
        "    questions = [{\n",
        "            'qas': qas,\n",
        "            'context_id': (i,j)    # We also track the question's original context \n",
        "                                   # and paragraph indices so to have a ground truth\n",
        "        }\n",
        "        for i in range(len(data['data']))\n",
        "        for j, para in enumerate(data['data'][i]['paragraphs'])\n",
        "        for qas in para['qas']\n",
        "    ]\n",
        "    paragraphs = [{\n",
        "            'context': para['context'],\n",
        "            'context_id': i\n",
        "        }\n",
        "        for i in range(len(data['data']))\n",
        "        for para in data['data'][i]['paragraphs']\n",
        "    ]\n",
        "    vectorizer = TfidfVectorizer(\n",
        "        strip_accents='unicode',    # Text is normalized into unicode characters\n",
        "        lowercase=True, # Then, we transform all text to lowercase\n",
        "        max_df=0.8,     # Filter out common words that appear in more \n",
        "                        # than 80% of the paragraphs\n",
        "        norm='l2'       # The vectorizer also l2 normalizes the vectors it produces, \n",
        "                        # so that the cosine similarity operation between \n",
        "                        # vectors simply becomes a dot product.\n",
        "    )      \n",
        "    docs = vectorizer.fit_transform(\n",
        "        [paragraphs[i]['context'] for i in range(len(paragraphs))] # Transform the paragraphs and fit the vectorizer\n",
        "    )\n",
        "    config = Config(bert=bert)\n",
        "    # Read dataset (JSON file)\n",
        "    data = utils.read_question_set(DATASET_PATH)\n",
        "    # Process questions\n",
        "    dataset = create_dataset_using_tf_idf_vectorizer(questions, \n",
        "        docs, vectorizer, config, for_training=False, \n",
        "        use_NER_attention=use_NER_attention, \n",
        "        NER_value=NER_value\n",
        "    )\n",
        "    print(\"Number of samples: \", len(dataset))\n",
        "    # Generate the original dataset that contains the original context and token-char mapping\n",
        "    original_dataset = create_original_dataset_with_tf_idf(questions, docs, vectorizer, config)\n",
        "    original_dataset = original_dataset.batch(config.BATCH_SIZE)\n",
        "    dataset = dataset.batch(config.BATCH_SIZE)\n",
        "    # Load model\n",
        "    if not use_NER_attention:\n",
        "        model = config.create_standard_model(hidden_state_list=hidden_state_list)\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "    # Load best model weights\n",
        "    model.load_weights(BEST_WEIGHTS_PATH)\n",
        "    # Predict the answers to the questions in the dataset\n",
        "    predictions = utils.compute_predictions(dataset, original_dataset, model)\n",
        "    # Create a prediction file formatted like the one that is expected\n",
        "    with open(PATH_TO_PREDICTIONS_JSON, 'w') as f:\n",
        "        json.dump(predictions, f)\n",
        "    \n",
        "    !python eval/evaluate.py $DATASET_PATH $PATH_TO_PREDICTIONS_JSON"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/QuestionAnswering/data/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqkTBRoH8Ckk",
        "outputId": "20870ee6-81f5-4d41-8ee9-f335c07a0f06"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev_set.json   logs\ttiny_training_set.json\tvalidation_set.json\n",
            "dev-v2.0.json  results\ttraining_set.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c_oeEGD5yZr",
        "outputId": "d64b42b0-512d-4c65-b4b6-0fd616dceffa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples:  10570\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'vocab_transform', 'vocab_projector', 'activation_13']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
            "100%|██████████| 661/661 [04:43<00:00,  2.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"exact\": 0.01892147587511826,\n",
            "  \"f1\": 1.1653256545487614,\n",
            "  \"total\": 10570,\n",
            "  \"HasAns_exact\": 0.01892147587511826,\n",
            "  \"HasAns_f1\": 1.1653256545487614,\n",
            "  \"HasAns_total\": 10570\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/QuestionAnswering/data/dev_set.json\"\n",
        "BEST_WEIGHTS_PATH = \"/content/drive/MyDrive/Uni/Magistrale/NLP/Project/weights/normal_100_tpu_h5_cval/normal.h5\"\n",
        "PATH_TO_PREDICTIONS_JSON = '/content/drive/MyDrive/Uni/Magistrale/NLP/Project/results/tf_idf_predictions_tpu_normal.txt'\n",
        "\n",
        "predict_and_evaluate(DATASET_PATH, BEST_WEIGHTS_PATH, PATH_TO_PREDICTIONS_JSON)"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "a14da18fde4627af59ca3997bb360c715b4bbf307bb79161e5597cfc4d9940a7"
    },
    "kernelspec": {
      "display_name": "Python 3.7.11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "tf_idf_retrieval_baseline.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cc0520c9e1f142279da89e756ffa8719": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3dfe8c70815c4de7b4cbea4ad3c15179",
              "IPY_MODEL_d61854a4cca0423e97f2a2b96a22df00",
              "IPY_MODEL_efb028580ed7444f887205ed15ff2e97"
            ],
            "layout": "IPY_MODEL_f295fcfc5b1043368caba3f396e6a09d"
          }
        },
        "3dfe8c70815c4de7b4cbea4ad3c15179": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_387e179f6222418aab0e60e1932f491f",
            "placeholder": "​",
            "style": "IPY_MODEL_8887e6cc6ffb4f0d932f56b6150b9703",
            "value": "Downloading: 100%"
          }
        },
        "d61854a4cca0423e97f2a2b96a22df00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d2d4f30d5c04f06a3216a3fdb18611b",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c3c157d39874f96a791ce8c6f6cb5ef",
            "value": 28
          }
        },
        "efb028580ed7444f887205ed15ff2e97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2250866910345f3b2c487754e006a63",
            "placeholder": "​",
            "style": "IPY_MODEL_c26c38b160c9493db467c7d7588c0160",
            "value": " 28.0/28.0 [00:00&lt;00:00, 172B/s]"
          }
        },
        "f295fcfc5b1043368caba3f396e6a09d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "387e179f6222418aab0e60e1932f491f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8887e6cc6ffb4f0d932f56b6150b9703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d2d4f30d5c04f06a3216a3fdb18611b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c3c157d39874f96a791ce8c6f6cb5ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f2250866910345f3b2c487754e006a63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c26c38b160c9493db467c7d7588c0160": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e94e647c88e74bed9be9ada22e6f8f09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02baf1f55a604381bcad09904199116a",
              "IPY_MODEL_bfe73b96dabf410388cc24a99318d4f2",
              "IPY_MODEL_4dbb78af646e4fd684a47759043900e6"
            ],
            "layout": "IPY_MODEL_a0477e7e7f1e48deb1d1afc4cc446c1b"
          }
        },
        "02baf1f55a604381bcad09904199116a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07fc8b6e6503432ca43b74f36d5e412b",
            "placeholder": "​",
            "style": "IPY_MODEL_b83564049fc44e1bac2ece53c9b4bdc6",
            "value": "Downloading: 100%"
          }
        },
        "bfe73b96dabf410388cc24a99318d4f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fadbed34502c450481001a0434009fb6",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad0fefa52cce40aea76e4546ba759358",
            "value": 231508
          }
        },
        "4dbb78af646e4fd684a47759043900e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa3e4712c08847499aab1a2f018e1e60",
            "placeholder": "​",
            "style": "IPY_MODEL_b330089eea5e4baeb4d10091e93db7d3",
            "value": " 226k/226k [00:00&lt;00:00, 593kB/s]"
          }
        },
        "a0477e7e7f1e48deb1d1afc4cc446c1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07fc8b6e6503432ca43b74f36d5e412b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b83564049fc44e1bac2ece53c9b4bdc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fadbed34502c450481001a0434009fb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad0fefa52cce40aea76e4546ba759358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa3e4712c08847499aab1a2f018e1e60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b330089eea5e4baeb4d10091e93db7d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7ab10277d5d4e84a3331613228f3d13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_650f26b9d70742e1ad9ec64a661a2069",
              "IPY_MODEL_9bafe78ef71543aeacb2d0bb991553c1",
              "IPY_MODEL_e03eebb69670448a81398e5139cbfdaa"
            ],
            "layout": "IPY_MODEL_09ef6a4be16d47018539f305400f1adc"
          }
        },
        "650f26b9d70742e1ad9ec64a661a2069": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9294ac51bcb1427c82f77db61a034de8",
            "placeholder": "​",
            "style": "IPY_MODEL_9a51ed4b68ef41bd860e2ae346ed5e73",
            "value": "Downloading: 100%"
          }
        },
        "9bafe78ef71543aeacb2d0bb991553c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3337b6b5c218485db30084fdd50d6db7",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_78a1b99e696040c59d16764744cc079e",
            "value": 466062
          }
        },
        "e03eebb69670448a81398e5139cbfdaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4edf5c46c9ea455a8318766cbef27078",
            "placeholder": "​",
            "style": "IPY_MODEL_b113ae2e41d44c58b0390e2a7836dd09",
            "value": " 455k/455k [00:00&lt;00:00, 1.47MB/s]"
          }
        },
        "09ef6a4be16d47018539f305400f1adc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9294ac51bcb1427c82f77db61a034de8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a51ed4b68ef41bd860e2ae346ed5e73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3337b6b5c218485db30084fdd50d6db7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78a1b99e696040c59d16764744cc079e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4edf5c46c9ea455a8318766cbef27078": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b113ae2e41d44c58b0390e2a7836dd09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "851454ad885a4e0bb651020c598d3f18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f5530b94c0b43f3ba118eb446e4678f",
              "IPY_MODEL_98b08db5f15e4248bdc5a064bc7e0ed3",
              "IPY_MODEL_869bb224a2f34af3a71283e6c48e8c57"
            ],
            "layout": "IPY_MODEL_959627a3e1964476a2ccee945a2602f7"
          }
        },
        "5f5530b94c0b43f3ba118eb446e4678f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1b7cdae729042ac8157806a21268a66",
            "placeholder": "​",
            "style": "IPY_MODEL_917ca47975df4d1d8473d496fc1b2085",
            "value": "Downloading: 100%"
          }
        },
        "98b08db5f15e4248bdc5a064bc7e0ed3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c60bf5f80ea40ad9ffc123989c7d966",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f776f79d569431f9c5e6d5710cf4873",
            "value": 483
          }
        },
        "869bb224a2f34af3a71283e6c48e8c57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c99c64818c2d44f1b048292f9857592b",
            "placeholder": "​",
            "style": "IPY_MODEL_ca9d2494788a46c78b6710c1239bbed7",
            "value": " 483/483 [00:00&lt;00:00, 5.23kB/s]"
          }
        },
        "959627a3e1964476a2ccee945a2602f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1b7cdae729042ac8157806a21268a66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "917ca47975df4d1d8473d496fc1b2085": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c60bf5f80ea40ad9ffc123989c7d966": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f776f79d569431f9c5e6d5710cf4873": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c99c64818c2d44f1b048292f9857592b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca9d2494788a46c78b6710c1239bbed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}