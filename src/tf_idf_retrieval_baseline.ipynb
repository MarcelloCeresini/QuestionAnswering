{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tf-Idf retrieval baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we implement a simple baseline for paragraph retrieval using Tf-Idf weighted sparse representations of documents and query questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from config import Config\n",
    "config = Config()\n",
    "import utils\n",
    "\n",
    "# Fix random seed for reproducibility\n",
    "np.random.seed(config.RANDOM_SEED)\n",
    "random.seed(config.RANDOM_SEED)\n",
    "tf.random.set_seed(config.RANDOM_SEED)\n",
    "\n",
    "from typing import List, Dict\n",
    "#os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = os.path.dirname(os.getcwd())\n",
    "TRAINING_FILE = os.path.join(ROOT_PATH, 'data', 'training_set.json')\n",
    "paragraphs_and_questions = utils.read_question_set(TRAINING_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we separate questions from their paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of questions: 87599\n",
      "Number of paragraphs: 18896\n"
     ]
    }
   ],
   "source": [
    "questions = [{\n",
    "        'qas': qas,\n",
    "        'context_id': (i,j)    # We also track the question's original context and paragraph indices so to have a ground truth\n",
    "    }\n",
    "    for i in range(len(paragraphs_and_questions['data']))\n",
    "    for j, para in enumerate(paragraphs_and_questions['data'][i]['paragraphs'])\n",
    "    for qas in para['qas']\n",
    "]\n",
    "\n",
    "paragraphs = [{\n",
    "        'context': para['context'],\n",
    "        'context_id': i\n",
    "    }\n",
    "    for i in range(len(paragraphs_and_questions['data']))\n",
    "    for para in paragraphs_and_questions['data'][i]['paragraphs']\n",
    "]\n",
    "\n",
    "print(f\"Number of questions: {len(questions)}\")\n",
    "print(f\"Number of paragraphs: {len(paragraphs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a function to obtain the paragraph given our context indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paragraph_from_question(qas):\n",
    "    i,j = qas['context_id']\n",
    "    return paragraphs_and_questions['data'][i]['paragraphs'][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What adjective did Lawrence Toppman use to describe Craig's portrayal of James Bond?\n",
      "\n",
      "Ground truth context: 'Christopher Orr, writing in The Atlantic, also criticised the film, saying that Spectre \"backslides on virtually every [aspect]\". Lawrence Toppman of The Charlotte Observer called Craig's performance \"Bored, James Bored.\" Alyssa Rosenberg, writing for The Washington Post, stated that the film turned into \"a disappointingly conventional Bond film.\"'\n"
     ]
    }
   ],
   "source": [
    "x = random.randint(0, len(questions)-1)\n",
    "print(f\"Question: {questions[x]['qas']['question']}\")\n",
    "print()\n",
    "print(f\"Ground truth context: '{get_paragraph_from_question(questions[x])['context']}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, given a question (query) we would like to obtain the paragraph that most probably contains the answer in order to pass it into the BERT QA model. One way to do that is by using tf-idf on the large set of paragraphs. In reality we will use more complex methods and this should be considered a baseline. We will use a `TdIdfVectorizer` from Scikit Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(strip_accents='unicode', \n",
    "    lowercase=True, \n",
    "    max_df=0.8,     # Filter out common words that appear in more than 80% of the paragraphs\n",
    "    norm='l2') # The vectorizer also l2 normalizes the vectors it produces, so that the cosine similarity operation between vectors simply becomes a dot product.\n",
    "docs = vectorizer.fit_transform([paragraphs[i]['context'] for i in range(len(paragraphs))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18896, 77747)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in order to compute scores between a query question and the set of document, we use **cosine similarity**.\n",
    "\n",
    "$$\n",
    "S_C (A,B) = \\frac{A \\cdot B}{\\lVert A\\rVert  \\lVert B\\rVert }\n",
    "$$\n",
    "\n",
    "Note: the `TfIdfVectorizer` we use already L2-normalizes all vectors it produces, so in the actual implementation we only compute a dot product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 paragraphs: [    0  6929  6937  6944 12250]\n",
      "Question: To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n",
      "Paragraphs:\n",
      "0 (score: 0.27): Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n",
      "\n",
      "1 (score: 0.26):  In Methodism, Mary is honored as the Mother of God. Methodists do not have any additional teachings on the Virgin Mary except from what is mentioned in Scripture and the ecumenical Creeds. As such, Methodists believe that Mary was conceived in her womb through the Holy Ghost and accept the doctrine of the Virgin Birth, although they, along with Orthodox Christians and other Protestant Christians, reject the doctrine of the Immaculate Conception. John Wesley, the principal founder of the Methodist movement within the Church of England, believed that Mary \"continued a pure and unspotted virgin\", thus upholding the doctrine of the perpetual virginity of Mary. Contemporary Methodism does hold that Mary was a virgin before, during, and immediately after the birth of Christ. In addition, some Methodists also hold the doctrine of the Assumption of Mary as a pious opinion.\n",
      "\n",
      "2 (score: 0.23): Mary's special position within God's purpose of salvation as \"God-bearer\" (Theotokos) is recognised in a number of ways by some Anglican Christians. All the member churches of the Anglican Communion affirm in the historic creeds that Jesus was born of the Virgin Mary, and celebrates the feast days of the Presentation of Christ in the Temple. This feast is called in older prayer books the Purification of the Blessed Virgin Mary on February 2. The Annunciation of our Lord to the Blessed Virgin on March 25 was from before the time of Bede until the 18th century New Year's Day in England. The Annunciation is called the \"Annunciation of our Lady\" in the 1662 Book of Common Prayer. Anglicans also celebrate in the Visitation of the Blessed Virgin on 31 May, though in some provinces the traditional date of July 2 is kept. The feast of the St. Mary the Virgin is observed on the traditional day of the Assumption, August 15. The Nativity of the Blessed Virgin is kept on September 8.\n",
      "\n",
      "3 (score: 0.22): The Protoevangelium of James, an extra-canonical book, has been the source of many Orthodox beliefs on Mary. The account of Mary's life presented includes her consecration as a virgin at the temple at age three. The High Priest Zachariah blessed Mary and informed her that God had magnified her name among many generations. Zachariah placed Mary on the third step of the altar, whereby God gave her grace. While in the temple, Mary was miraculously fed by an angel, until she was twelve years old. At that point an angel told Zachariah to betroth Mary to a widower in Israel, who would be indicated. This story provides the theme of many hymns for the Feast of Presentation of Mary, and icons of the feast depict the story. The Orthodox believe that Mary was instrumental in the growth of Christianity during the life of Jesus, and after his Crucifixion, and Orthodox Theologian Sergei Bulgakov wrote: \"The Virgin Mary is the center, invisible, but real, of the Apostolic Church.\"\n",
      "\n",
      "4 (score: 0.21): The presence of the Virgin Mary under the cross[Jn. 19:26-27] has in itself been the subject of Marian art, and well known Catholic symbolism such as the Miraculous Medal and Pope John Paul II's Coat of Arms bearing a Marian Cross. And a number of Marian devotions also involve the presence of the Virgin Mary in Calvary, e.g., Pope John Paul II stated that \"Mary was united to Jesus on the Cross\". Well known works of Christian art by masters such as Raphael (e.g., the Mond Crucifixion), and Caravaggio (e.g., his Entombment) depict the Virgin Mary as part of the crucifixion scene.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def score_documents(query):\n",
    "    q = query['qas']['question']\n",
    "    q = vectorizer.transform([q]) # q will be a (sparse) matrix with dimensionality 1 x vocab_dim\n",
    "    # We can compute a vector of all dot products scores and transform it from dense matrix to numpy array like this:\n",
    "    return np.asarray(np.dot(docs, q.T).todense()).flatten()\n",
    "\n",
    "def top_5_for_question(query):\n",
    "    scores = score_documents(query)\n",
    "    sorted_scores = np.argsort(-scores) # Negated for descending order\n",
    "    return [paragraphs[i] for i in sorted_scores[:5]], scores[sorted_scores[:5]], sorted_scores[:5]\n",
    "\n",
    "def print_top_5(query, top_5_para, top_5_scores, top_5_indices):\n",
    "    print(f\"Top-5 paragraphs: {top_5_indices}\")\n",
    "    print(f\"Question: {query['qas']['question']}\")\n",
    "    print(f\"Paragraphs:\")\n",
    "    for i in range(5):\n",
    "        print(f\"{i} (score: {top_5_scores[i]:.2f}): {top_5_para[i]['context']}\\n\")\n",
    "\n",
    "QUERY = questions[0]\n",
    "top5_para, top5_scores, top5_indices = top_5_for_question(QUERY)\n",
    "print_top_5(QUERY, top5_para, top5_scores, top5_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can measure how many times this simple baseline retrieves the correct paragraph (top-1 and top-5 accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 score: 72.01%,\n",
      "Top 5 score: 87.82%\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "count_top1 = 0\n",
    "count_top5 = 0\n",
    "count_total = len(questions)\n",
    "\n",
    "for q in questions:\n",
    "    top5_para, top5_scores, top5_indices = top_5_for_question(q)\n",
    "    top5_context_ids = [top5_para[i]['context_id'] for i in range(len(top5_para))]\n",
    "    gt_context_id = q['context_id'][0]\n",
    "    if gt_context_id == top5_context_ids[0]:\n",
    "        count_top1 += 1\n",
    "    if gt_context_id in top5_context_ids:\n",
    "        count_top5 += 1\n",
    "\n",
    "top1_score = count_top1 / count_total * 100\n",
    "top5_score = count_top5 / count_total * 100\n",
    "\n",
    "print(f\"Top 1 score: {top1_score:.2f}%,\\nTop 5 score: {top5_score:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are quite good already, but we'll investigate whether using a dense representation (eg. vectors computed by Bert) can further improve these scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Use the paragraphs collected with tf-idf to compute the possible answer and see the actual QA score."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a14da18fde4627af59ca3997bb360c715b4bbf307bb79161e5597cfc4d9940a7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
