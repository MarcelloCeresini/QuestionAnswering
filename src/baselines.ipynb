{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we explore some baselines for the problem of question answering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import spacy\n",
    "import benepar\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import utils\n",
    "\n",
    "# Download spacy corpora of text in case it's needed\n",
    "!python -m spacy download en_core_web_sm\n",
    "# Download the benepar neural constituency parser\n",
    "benepar.download('benepar_en3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training dataset and create a DataFrame containing:\n",
    "- The paragraph's text\n",
    "- The question's text\n",
    "- The questions's ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = utils.read_question_set(os.path.join('..','data','training_set.json'))\n",
    "\n",
    "# Create a more useful data structure using list comprehensions\n",
    "questions = pd.DataFrame([{\n",
    "        'context': paragraph['context'],\n",
    "        'question': qa['question'],\n",
    "        'questionID': qa['id'],\n",
    "    }   for article in dataset['data']\n",
    "        for paragraph in article['paragraphs']\n",
    "        for qa in paragraph['qas'] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87599\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>questionID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>5733be284776f4190066117f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>5733be284776f41900661180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>5733be284776f41900661181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>5733be284776f4190066117e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  Architecturally, the school has a Catholic cha...   \n",
       "1  Architecturally, the school has a Catholic cha...   \n",
       "2  Architecturally, the school has a Catholic cha...   \n",
       "3  Architecturally, the school has a Catholic cha...   \n",
       "4  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                            question                questionID  \n",
       "0  To whom did the Virgin Mary allegedly appear i...  5733be284776f41900661182  \n",
       "1  What is in front of the Notre Dame Main Building?  5733be284776f4190066117f  \n",
       "2  The Basilica of the Sacred heart at Notre Dame...  5733be284776f41900661180  \n",
       "3                  What is the Grotto at Notre Dame?  5733be284776f41900661181  \n",
       "4  What sits on top of the Main Building at Notre...  5733be284776f4190066117e  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(questions))\n",
    "display(questions.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a method that, given the question's ID and the start and end probabilities generated by the baselines, returns the span of text containing the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(baseline, limit=None):\n",
    "    predictions = {}\n",
    "\n",
    "    limit = range(limit) if limit is not None else range(len(questions))\n",
    "\n",
    "    for q in tqdm(limit):\n",
    "        # Obtain start and end probabilities from the baseline function\n",
    "        pstartv, pendv = baseline(\n",
    "           questions.iloc[q,:]\n",
    "        )\n",
    "        # Obtain the indices of the best answer\n",
    "        start, end = utils.start_end_token_from_probabilities(\n",
    "            pstartv, pendv, dim=pstartv.shape[1]\n",
    "        )[0]\n",
    "        # Add the ID-answer pair in the predictions dictionary\n",
    "        id = questions['questionID'].iloc[q]\n",
    "        text = questions['context'].iloc[q]\n",
    "        predictions[id] = text[start:end]\n",
    "    \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Random prediction baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement a predictor that returns random start and end probabilities. Then, we use the function `start_end_token_from_probabilities` to obtain the max-scoring randomly generated span of text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_baseline_predict(data):\n",
    "    '''\n",
    "    Creates random prediction vectors.\n",
    "    '''\n",
    "    pstartv = np.random.random((1, len(data['context'])))\n",
    "    pendv = np.random.random((1, len(data['context'])))\n",
    "    return pstartv, pendv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('eval','random_predictions.txt'), 'w') as f:\n",
    "    json.dump(get_predictions(random_baseline_predict), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sliding window baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sliding window baseline is implemented in the same way it was presented in the\n",
    "SQuAD v1 paper and in the [MCTest paper](https://aclanthology.org/D13-1020.pdf) by Richardson et al.\n",
    "which originally proposed it.\n",
    "\n",
    "Apart from the paragraph and the question, the implementation also needs a set of candidate answers.\n",
    "SQuAD's paper proposes to \"*only use spans which are constituents in the constituency parse generated by\n",
    "Stanford CoreNLP*\". In our case, we use a neural parser: **Berkeley Neural Parser**, which is the option\n",
    "proposed by the `spacy` library, which we are already using as a named entity extractor in the original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def C(w, P):\n",
    "    # Sum of all words in the sentence where the word is equal to w\n",
    "    return sum([1 for p in P if w == p])\n",
    "\n",
    "def IC(w, P):\n",
    "    # A scoring function based on inverse word frequency\n",
    "    return math.log(1 + (1/C(w, P)))\n",
    "\n",
    "def sliding_window_baseline_predict(data):\n",
    "    # Initialize spacy's pipeline which we'll use for analysis\n",
    "    spacy_pipeline = spacy.load(\"en_core_web_sm\")\n",
    "    # Step 1: Create a set of words present in the question (always ignore punctuation)\n",
    "    Q = set([token for token in spacy_pipeline(data['question']) if not token.is_punct])\n",
    "    # Step 2: use benepar to produce a constituency tree\n",
    "    spacy_pipeline.add_pipe('benepar', config={'model': 'benepar_en3'})\n",
    "    # Process the text using Spacy's pipeline\n",
    "    doc = spacy_pipeline(data['context'])\n",
    "    # Obtain a list of tokens in the paragraph\n",
    "    paragraph_tokens = [token for token in doc]\n",
    "    P = [token for token in paragraph_tokens if not token.is_punct]\n",
    "    # From the processed text we can also obtain the list of constituents,\n",
    "    # which will be the proposed answers to each question. We also create\n",
    "    # a set of words of the question.\n",
    "    proposed_answers = [ {\n",
    "            'answer': answer,\n",
    "            'start': answer.start_char,\n",
    "            'end': answer.end_char,\n",
    "            'token_set': set(tok for tok in answer if not tok.is_punct)\n",
    "        }\n",
    "        for sentence in list(doc.sents)         # Iterate over sentences\n",
    "        for answer in list(sentence._.children) # Iterate over constitents\n",
    "        if not len(set(tok for tok in answer if not tok.is_punct)) == 0     # Ignore span if it only contains punctuation\n",
    "    ]\n",
    "\n",
    "    # Step 3: Now that we have the question's text, the proposed answers and the context,\n",
    "    # we can apply the sliding window algorithm, which computes a score based on the n-gram\n",
    "    # overlap between the question's words and the proposed spans of text.\n",
    "    scores = []\n",
    "    for i in range(len(proposed_answers)):     # Iterate over all possible answers\n",
    "        S = set([str(s) for s in proposed_answers[i]['token_set'].union(Q)])  # Unite the question and the answer words\n",
    "        sj = []                         # Prepare a list for the scores\n",
    "        for j in range(len(P)):         # For each word in the passage\n",
    "            sx = 0  \n",
    "            for w in range(len(S)):     # For each word in question/answer set\n",
    "                try:\n",
    "                    if str(P[j+w]) in S:     # Try to compute the score of this span\n",
    "                        sx += IC(str(P[j+w]), [str(p) for p in P])    # And add it to the sum\n",
    "                except IndexError:\n",
    "                    pass\n",
    "            sj.append(sx)\n",
    "        sw = max(sj)                   # Eventually, select the max scoring  \n",
    "        scores.append(sw)\n",
    "\n",
    "    pstartv = np.zeros((1, len(data['context'])))\n",
    "    pendv = np.zeros((1, len(data['context'])))\n",
    "    best_scoring_answer = proposed_answers[np.argmax(scores)]\n",
    "    pstartv[0, best_scoring_answer['start']] = 1\n",
    "    pendv[0, best_scoring_answer['end']] = 1\n",
    "\n",
    "    return pstartv, pendv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Volpe\\Anaconda3\\envs\\NLP\\lib\\site-packages\\torch\\distributions\\distribution.py:44: UserWarning: <class 'torch_struct.distributions.TreeCRF'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n",
      "  warnings.warn(f'{self.__class__} does not define `arg_constraints`. ' +\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join('eval','sliding_predictions.txt'), 'w') as f:\n",
    "    json.dump(get_predictions(sliding_window_baseline_predict), f)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c90f87e5ee49fb7af5481158977e62ba01ae4f54defb58032c9ba197b530ea3c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('NLP': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
